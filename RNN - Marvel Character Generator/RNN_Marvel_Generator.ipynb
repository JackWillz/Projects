{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Marvel_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggUwY8AgaHqE",
        "colab_type": "code",
        "outputId": "5ff35c03-3c85-405f-bfbe-814b5ee89ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLfWWhWpatZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from collections import Counter\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIrhuYIaazUx",
        "colab_type": "code",
        "outputId": "7bffd353-61a5-4a9e-aa10-a54099e42435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read data and check length\n",
        "text = open('marvel_data.txt', encoding=\"utf8\").read().lower()\n",
        "print('text length', len(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text length 28213380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7H6YIGeFscJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce (stop memory crashes - may be worth looking into memory reduction techniques instead)\n",
        "reduced_text = text[:1000000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqTbcbasa7Is",
        "colab_type": "code",
        "outputId": "2e345eff-679a-4664-cf57-b435611f9051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Random line\n",
        "print(text[20086:20480])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " she then tied him up until the police arrived on the scene and showed them images of chord and the dealings of the ten rings which led to his arrest. midnight's fire has very subtle abilities, due to the energies of the well of all things. his physical attributes are at the peak of human possibility. he has enhanced speed, strength, agility, and sensory perception on par with black panther.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdjB_ACI79rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Required cleans\n",
        "def clean_doc(doc):\n",
        "\t# replace '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens\n",
        "\n",
        "\t\n",
        "tokens = clean_doc(reduced_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqu3YMYA9YzC",
        "colab_type": "code",
        "outputId": "f0931034-340f-4277-9794-4f2d14a2c9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Example of tokens\n",
        "print(tokens[:200])\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "print('Unique Tokens: %d' % len(set(tokens)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['unnamed', 'cousin', 'due', 'to', 'false', 'accusation', 'spread', 'by', 'afari', 'against', 'him', 'and', 'the', 'black', 'spears', 'commander', 'amboola', 'they', 'were', 'both', 'suspected', 'by', 'queen', 'tananda', 'of', 'plotting', 'against', 'her', 'and', 'were', 'arrested', 'amboola', 'was', 'killed', 'by', 'a', 'demon', 'released', 'by', 'the', 'sorcerer', 'muru', 'agent', 'of', 'the', 'actual', 'plotter', 'tuthmes', 'but', 'aahmes', 'fate', 'remained', 'unknown', 'aaidan', 'blomfield', 'was', 'the', 'third', 'man', 'to', 'call', 'himself', 'the', 'unicorn', 'he', 'was', 'an', 'agent', 'of', 'stockpile', 'attempting', 'to', 'raid', 'stark', 'enterprises', 'for', 'morgan', 'stark', 'after', 'the', 'apparent', 'death', 'of', 'tony', 'stark', 'he', 'claimed', 'to', 'be', 'an', 'old', 'foe', 'of', 'iron', 'mans', 'but', 'it', 'is', 'unknown', 'if', 'he', 'really', 'was', 'or', 'was', 'just', 'riding', 'on', 'the', 'reputation', 'of', 'the', 'original', 'unicorn', 'he', 'displayed', 'superhuman', 'strength', 'and', 'toughness', 'enough', 'to', 'resist', 'iron', 'mans', 'repulsors', 'and', 'war', 'blasts', 'aala', 'was', 'the', 'sea', 'goddess', 'of', 'balsagoth', 'kyrie', 'was', 'worshiped', 'as', 'aala', 'and', 'learn', 'to', 'use', 'that', 'belief', 'until', 'high', 'priest', 'gothan', 'had', 'her', 'exiled', 'and', 'those', 'faithful', 'to', 'her', 'slaughtered', 'unborn', 'child', 'aala', 'was', 'the', 'wife', 'of', 'galan', 'in', 'the', 'sixth', 'iteration', 'of', 'she', 'was', 'pregnant', 'at', 'the', 'time', 'of', 'the', 'end', 'of', 'the', 'universe', 'aalbort', 'was', 'accountant', 'for', 'the', 'starship', 'principle', 'of', 'reasonable', 'interest', 'and', 'had', 'been', 'working', 'for']\n",
            "Total Tokens: 167600\n",
            "Unique Tokens: 15115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW7Fl7QD_08F",
        "colab_type": "code",
        "outputId": "66966bd5-480e-45c6-f070-652a90d5e304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Count the tokens\n",
        "Counter(tokens).most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 11274),\n",
              " ('to', 6773),\n",
              " ('and', 5352),\n",
              " ('of', 4666),\n",
              " ('a', 3580),\n",
              " ('was', 3255),\n",
              " ('his', 2787),\n",
              " ('in', 2429),\n",
              " ('he', 2349),\n",
              " ('by', 1586)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX7R2Vs391nT",
        "colab_type": "code",
        "outputId": "c2cb95dd-7d8b-49ca-9ed7-ef229ccb0f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Organise into sequences\n",
        "length = 41\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = tokens[i-length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences.append(line)\n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 167559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znUAJGSWedzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "sequences = tokenizer.texts_to_sequences(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg3ueeQOAmGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the size of the vocab\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DW0e5k8bKsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into the input text and the output text\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ8hWf5pHeZK",
        "colab_type": "code",
        "outputId": "b249ded9-6f84-4351-84cf-d61bfb66eaa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Create an RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 50)            755800    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 40, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15116)             1526716   \n",
            "=================================================================\n",
            "Total params: 2,433,416\n",
            "Trainable params: 2,433,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyqtm-MyHk6w",
        "colab_type": "code",
        "outputId": "d4269baf-87c2-45a3-d868-d48d8e7e0dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compile & Fit\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=128, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "167559/167559 [==============================] - 215s 1ms/step - loss: 7.1368 - acc: 0.0711\n",
            "Epoch 2/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 6.6924 - acc: 0.0886\n",
            "Epoch 3/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 6.4756 - acc: 0.1114\n",
            "Epoch 4/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 6.2979 - acc: 0.1272\n",
            "Epoch 5/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 6.1424 - acc: 0.1353\n",
            "Epoch 6/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 6.0633 - acc: 0.1382\n",
            "Epoch 7/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 5.9131 - acc: 0.1457\n",
            "Epoch 8/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 5.7953 - acc: 0.1525\n",
            "Epoch 9/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 5.6751 - acc: 0.1578\n",
            "Epoch 10/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 5.5536 - acc: 0.1646\n",
            "Epoch 11/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 5.6142 - acc: 0.1557\n",
            "Epoch 12/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 5.4753 - acc: 0.1643\n",
            "Epoch 13/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 5.3795 - acc: 0.1707\n",
            "Epoch 14/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 5.2967 - acc: 0.1750\n",
            "Epoch 15/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 5.2149 - acc: 0.1783\n",
            "Epoch 16/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 5.1418 - acc: 0.1816\n",
            "Epoch 17/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 5.0752 - acc: 0.1849\n",
            "Epoch 18/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 5.0045 - acc: 0.1884\n",
            "Epoch 19/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 4.9423 - acc: 0.1915\n",
            "Epoch 20/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 4.8819 - acc: 0.1944\n",
            "Epoch 21/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 4.8225 - acc: 0.1974\n",
            "Epoch 22/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 4.7677 - acc: 0.1999\n",
            "Epoch 23/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 4.7145 - acc: 0.2037\n",
            "Epoch 24/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 4.6622 - acc: 0.2070\n",
            "Epoch 25/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 4.6136 - acc: 0.2103\n",
            "Epoch 26/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 4.5589 - acc: 0.2145\n",
            "Epoch 27/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 4.5107 - acc: 0.2183\n",
            "Epoch 28/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 4.4760 - acc: 0.2213\n",
            "Epoch 29/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 4.4323 - acc: 0.2242\n",
            "Epoch 30/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 4.3693 - acc: 0.2294\n",
            "Epoch 31/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 4.3243 - acc: 0.2338\n",
            "Epoch 32/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 4.2787 - acc: 0.2367\n",
            "Epoch 33/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 4.2361 - acc: 0.2409\n",
            "Epoch 34/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 4.1923 - acc: 0.2452\n",
            "Epoch 35/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 4.1540 - acc: 0.2497\n",
            "Epoch 36/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 4.1097 - acc: 0.2530\n",
            "Epoch 37/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 4.0662 - acc: 0.2577\n",
            "Epoch 38/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 4.0269 - acc: 0.2614\n",
            "Epoch 39/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 3.9873 - acc: 0.2666\n",
            "Epoch 40/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.9478 - acc: 0.2698\n",
            "Epoch 41/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.9111 - acc: 0.2736\n",
            "Epoch 42/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.8727 - acc: 0.2778\n",
            "Epoch 43/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 3.8360 - acc: 0.2814\n",
            "Epoch 44/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 3.7987 - acc: 0.2858\n",
            "Epoch 45/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 3.7646 - acc: 0.2903\n",
            "Epoch 46/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.7287 - acc: 0.2940\n",
            "Epoch 47/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.6968 - acc: 0.2981\n",
            "Epoch 48/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 3.6597 - acc: 0.3019\n",
            "Epoch 49/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.6270 - acc: 0.3057\n",
            "Epoch 50/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.5942 - acc: 0.3099\n",
            "Epoch 51/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.5606 - acc: 0.3133\n",
            "Epoch 52/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 3.5287 - acc: 0.3182\n",
            "Epoch 53/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.4990 - acc: 0.3214\n",
            "Epoch 54/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 3.4684 - acc: 0.3265\n",
            "Epoch 55/100\n",
            "167559/167559 [==============================] - 199s 1ms/step - loss: 3.4368 - acc: 0.3304\n",
            "Epoch 56/100\n",
            "167559/167559 [==============================] - 201s 1ms/step - loss: 3.4096 - acc: 0.3340\n",
            "Epoch 57/100\n",
            "167559/167559 [==============================] - 201s 1ms/step - loss: 3.3778 - acc: 0.3384\n",
            "Epoch 58/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.3517 - acc: 0.3415\n",
            "Epoch 59/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.3187 - acc: 0.3451\n",
            "Epoch 60/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.2917 - acc: 0.3506\n",
            "Epoch 61/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.2603 - acc: 0.3540\n",
            "Epoch 62/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.2377 - acc: 0.3573\n",
            "Epoch 63/100\n",
            "167559/167559 [==============================] - 202s 1ms/step - loss: 3.2076 - acc: 0.3611\n",
            "Epoch 64/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 3.1829 - acc: 0.3649\n",
            "Epoch 65/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.1530 - acc: 0.3687\n",
            "Epoch 66/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.1248 - acc: 0.3732\n",
            "Epoch 67/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 3.0994 - acc: 0.3762\n",
            "Epoch 68/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 3.0788 - acc: 0.3789\n",
            "Epoch 69/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 3.0460 - acc: 0.3842\n",
            "Epoch 70/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 3.0242 - acc: 0.3869\n",
            "Epoch 71/100\n",
            "167559/167559 [==============================] - 201s 1ms/step - loss: 3.0044 - acc: 0.3893\n",
            "Epoch 72/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 2.9720 - acc: 0.3943\n",
            "Epoch 73/100\n",
            "167559/167559 [==============================] - 203s 1ms/step - loss: 2.9492 - acc: 0.3987\n",
            "Epoch 74/100\n",
            "167559/167559 [==============================] - 204s 1ms/step - loss: 2.9266 - acc: 0.4012\n",
            "Epoch 75/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 2.9071 - acc: 0.4049\n",
            "Epoch 76/100\n",
            "167559/167559 [==============================] - 205s 1ms/step - loss: 2.8845 - acc: 0.4083\n",
            "Epoch 77/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.8655 - acc: 0.4113\n",
            "Epoch 78/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 2.8333 - acc: 0.4165\n",
            "Epoch 79/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 2.8169 - acc: 0.4183\n",
            "Epoch 80/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.7922 - acc: 0.4223\n",
            "Epoch 81/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.7705 - acc: 0.4260\n",
            "Epoch 82/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 2.7572 - acc: 0.4271\n",
            "Epoch 83/100\n",
            "167559/167559 [==============================] - 206s 1ms/step - loss: 2.7332 - acc: 0.4323\n",
            "Epoch 84/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.7124 - acc: 0.4355\n",
            "Epoch 85/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.6912 - acc: 0.4375\n",
            "Epoch 86/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.6701 - acc: 0.4412\n",
            "Epoch 87/100\n",
            "167559/167559 [==============================] - 208s 1ms/step - loss: 2.6540 - acc: 0.4431\n",
            "Epoch 88/100\n",
            "167559/167559 [==============================] - 208s 1ms/step - loss: 2.6384 - acc: 0.4449\n",
            "Epoch 89/100\n",
            "167559/167559 [==============================] - 208s 1ms/step - loss: 2.6155 - acc: 0.4498\n",
            "Epoch 90/100\n",
            "167559/167559 [==============================] - 208s 1ms/step - loss: 2.5999 - acc: 0.4524\n",
            "Epoch 91/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.5810 - acc: 0.4551\n",
            "Epoch 92/100\n",
            "167559/167559 [==============================] - 212s 1ms/step - loss: 2.5627 - acc: 0.4588\n",
            "Epoch 93/100\n",
            "167559/167559 [==============================] - 211s 1ms/step - loss: 2.5443 - acc: 0.4624\n",
            "Epoch 94/100\n",
            "167559/167559 [==============================] - 209s 1ms/step - loss: 2.5269 - acc: 0.4650\n",
            "Epoch 95/100\n",
            "167559/167559 [==============================] - 207s 1ms/step - loss: 2.5104 - acc: 0.4673\n",
            "Epoch 96/100\n",
            "167559/167559 [==============================] - 208s 1ms/step - loss: 2.4977 - acc: 0.4709\n",
            "Epoch 97/100\n",
            "167559/167559 [==============================] - 209s 1ms/step - loss: 2.4763 - acc: 0.4743\n",
            "Epoch 98/100\n",
            "167559/167559 [==============================] - 210s 1ms/step - loss: 2.4588 - acc: 0.4768\n",
            "Epoch 99/100\n",
            "167559/167559 [==============================] - 210s 1ms/step - loss: 2.4403 - acc: 0.4798\n",
            "Epoch 100/100\n",
            "167559/167559 [==============================] - 211s 1ms/step - loss: 2.4310 - acc: 0.4802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36ecadf6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuMik4xeH268",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model output\n",
        "from pickle import dump\n",
        "model.save('marvel_model1.h5')\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXhkiQ8UZeT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ask Martyn to write me a 40 word opening sentence\n",
        "seed_text = 'Born in 1993, bullied in school for having small feet Martyn grew up on a local wheat farm. Lifting bails made him a strong man, far stronger than the average human. One day during a solar eclipse something odd happened'\n",
        "encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "encoded_array = np.array([encoded])\n",
        "encoded_array.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfZKpKSqaN3S",
        "colab_type": "code",
        "outputId": "d33ef5a2-17c0-47ad-acb2-0a3e7797b014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Predict the output\n",
        "predicted = model.predict_classes(encoded_array, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-6ff0b94914d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have shape (40,) but got array with shape (36,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ2igHzKaSo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a sequence\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5SMunCrj5Ri",
        "colab_type": "code",
        "outputId": "e588bbc8-0726-49b0-b399-b09e1f0e9213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print(generated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to the rigellians and nick fury will triggered his colorblindness and exchanging their japanese timeline grumlin was to combat fields hurani is a urgent detector radiate the wicked arno stark were being controlled by terror in the surface cap fell together facing shiv as part owner anubis fought for leaking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CCh3-QYj9BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Full sentence, with a few improvements (capital letters / commas)\n",
        "\n",
        "\"[HUMAN MADE:] Born in 1993, bullied in school for having small feet Martyn grew up on a local wheat farm. Lifting bails made him a strong man, far stronger than the average human. \\n\n",
        "One day during a solar eclipse something odd happened [MODEL MADE:] to the Rigellians and Nick Fury's will triggered his colorblindness and exchanging their Japanese timeline, \\n\n",
        "Grumlin was to combat fields. Hurani is an urgent detector, radiate the wicked Arno Stark were being controlled by terror in the surface. Cap fell together facing Shiv as part owner Anubis fought for leaking\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxdNEIpBjYjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We're not there yet!"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}