{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-YR7m1P36UN",
        "colab_type": "text"
      },
      "source": [
        "## Imports & File Change (more efficient than uploading to Google Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJx72WfG3yoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('drive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2VulKNP8oLE",
        "colab_type": "code",
        "outputId": "ca401dbe-3aaa-4aeb-da86-ffc61688a50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "# importing of modules for LeNet CNN \n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Dropout, SpatialDropout2D\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "# importing of service libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import random\n",
        "import matplotlib.ticker as mtick\n",
        "import time as t\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "print('Libraries imported.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Libraries imported.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cptQUdkn4KUl",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nij5lW5AqDh",
        "colab_type": "code",
        "outputId": "151bb85b-1dc7-410e-cf30-8071a839115e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load data and split \n",
        "X = np.load('X.npy')\n",
        "y = np.load('y.npy')\n",
        "\n",
        "# Set-up input/output sizes\n",
        "img_rows, img_cols = 128, 1290 # input  dimensions of each image\n",
        "n_classes = 5  # number of outputs = number of digits\n",
        "input_shape = (1, img_rows, img_cols)\n",
        "\n",
        "print('Main variables initialised.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Main variables initialised.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JL5YMw84Ofm",
        "colab_type": "text"
      },
      "source": [
        "## Define Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuowClS1oBxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def std_interval(data):\n",
        "  means = []\n",
        "  for i in data:\n",
        "    means.append(np.mean(i))\n",
        "  std = np.std(means)\n",
        "  std_int = 1.96 * std\n",
        "  return std_int\n",
        "\n",
        "def ci_intervals(means, std_int):\n",
        "  lower = []\n",
        "  upper = []\n",
        "  for i in means:\n",
        "    lower.append(i - std_int)\n",
        "    upper.append(i + std_int)\n",
        "  return lower, upper\n",
        "\n",
        "def plots(train_accuracy, val_accuracy):\n",
        "  train_std = std_interval(train_accuracy)\n",
        "  val_std = std_interval(val_accuracy)\n",
        "\n",
        "  train_mean = list_averages(train_accuracy)\n",
        "  val_mean = list_averages(val_accuracy)\n",
        "\n",
        "  train_lower, train_upper = ci_intervals(train_mean, train_std)\n",
        "  val_lower, val_upper = ci_intervals(val_mean, val_std)\n",
        "\n",
        "  epochs = range(1, len(train_mean)+1)\n",
        "\n",
        "  f, ax = plt.subplots(figsize=(8, 6))\n",
        "  ax.grid(False)\n",
        "  ax.plot(epochs, train_mean, color='green')\n",
        "  ax.plot(epochs, val_mean, color='blue')\n",
        "  ax.plot(epochs, train_lower,color='grey',linewidth=.1)\n",
        "  ax.plot(epochs, train_upper,color='grey',linewidth=.1)\n",
        "  ax.plot(epochs, val_lower,color='grey',linewidth=.1)\n",
        "  ax.plot(epochs, val_upper,color='grey',linewidth=.1)\n",
        "\n",
        "  ax.fill_between(epochs, train_lower,train_upper,alpha=.1,color='grey',interpolate=True)\n",
        "  ax.fill_between(epochs, val_lower,val_upper,alpha=.1,color='grey',interpolate=True)\n",
        "  \n",
        "  ax.set_xticks(range(1, len(train_mean)+1, 2))\n",
        "  \n",
        "  return ax\n",
        "\n",
        "def plot_results(train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy):\n",
        "  # Print summary statistic\n",
        "  avg_test_loss = np.mean(test_loss)\n",
        "  avg_test_acc = np.mean(test_accuracy)\n",
        "  print(\"The test loss is: \"+str(avg_test_loss))\n",
        "  print(\"The test accuracy is: \"+str(avg_test_acc))\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  acc_ax = plots(train_accuracy, val_accuracy)\n",
        "  acc_ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "  acc_ax.legend([\"Average Train Accuracy\", \"Average Validation Accuracy\",\"95% probability interval\"],prop={'size': 10})\n",
        "  acc_ax.set_xlabel('Number of Epochs', fontweight='bold')\n",
        "  acc_ax.set_ylabel('Classification Accuracy', fontweight='bold')\n",
        "  acc_ax.set_title('Model Accuracy at each Epoch', fontweight='bold')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  loss_ax = plots(train_loss, val_loss)\n",
        "  loss_ax.legend([\"Average Train Loss\", \"Average Validation Loss\",\"95% probability interval\"],prop={'size': 10})\n",
        "  loss_ax.set_xlabel('Number of Epochs', fontweight='bold')\n",
        "  loss_ax.set_ylabel('Loss', fontweight='bold')\n",
        "  loss_ax.set_title('Model Loss at each Epoch', fontweight='bold')\n",
        "  plt.show()\n",
        "\n",
        "def list_averages(scores):\n",
        "  full_avg_scores = []\n",
        "  for i in range(len(scores[0])):\n",
        "    avg_scores = []\n",
        "    for j in range(len(scores)):\n",
        "      avg_scores.append(scores[j][i])\n",
        "    full_avg_scores.append(np.mean(avg_scores))\n",
        "  return full_avg_scores\n",
        "\n",
        "def draw_conf_matrix(X_test, y_test):\n",
        "  predict = model.predict_classes(X_test)\n",
        "  conf_mat = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
        "  sns.set(rc={'figure.figsize':(8,6)})\n",
        "  ax = sns.heatmap(conf_mat, annot=True, cmap='Blues', cbar=False, fmt='g', annot_kws={\"size\":13})\n",
        "  ax.set_xlabel('Predicted Genre', fontweight='bold')\n",
        "  ax.set_ylabel('Actual Genre', fontweight='bold')\n",
        "  ax.xaxis.set_ticklabels(['Blues', 'Classical', 'Hiphop', 'Metal', 'Disco'], ha='center')\n",
        "  ax.yaxis.set_ticklabels(['Blues', 'Classical', 'Hiphop', 'Metal', 'Disco'], va='center')\n",
        "  ax.set_title('Confusion Matrix of Genre Classification', fontweight='bold')\n",
        "  plt.show(ax)\n",
        "  return ax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hR4q-If4U2Y",
        "colab_type": "text"
      },
      "source": [
        "## Define model fit and base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mH3Sib9zbDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense):\n",
        "  model = Model(input_shape, n_classes, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
        "  print(model.summary())\n",
        "  model.save_weights('model.h5')\n",
        "  # seed for reproducibility\n",
        "  test_accuracy, test_loss = [], []\n",
        "  train_accuracy, train_loss = [], []\n",
        "  val_accuracy, val_loss = [], []\n",
        "  for i in range(1,10):\n",
        "    model.load_weights('model.h5')\n",
        "    seed = random.randint(1,500)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = seed, test_size = 0.2, shuffle = True)\n",
        "    fit_model = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_split = 0.2)\n",
        "    score = model.evaluate(X_test, y_test, verbose=1)\n",
        "    train_accuracy.append(fit_model.history['acc'])\n",
        "    train_loss.append(fit_model.history['loss'])\n",
        "    val_accuracy.append(fit_model.history['val_acc'])\n",
        "    val_loss.append(fit_model.history['val_loss'])\n",
        "    test_loss.append(score[0])\n",
        "    test_accuracy.append(score[1])\n",
        "\n",
        "\n",
        "  return train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy\n",
        "\n",
        "def LeNet(input_shape, classes, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense):\n",
        "  model = Sequential()\n",
        "\n",
        "  # CONV => RELU => POOL\n",
        "  model.add(Conv2D(batch1, kernel_size=k_size, strides = conv_stride,  padding=\"same\", input_shape=input_shape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=p_size, strides= pool_stride, dim_ordering=\"th\"))\n",
        "\n",
        "  # CONV => RELU => POOL\n",
        "  model.add(Conv2D(batch2, kernel_size=k_size, strides = conv_stride,  padding=\"same\", input_shape=input_shape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=p_size, strides= pool_stride, dim_ordering=\"th\"))\n",
        "\n",
        "  # Flatten => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(dense))\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  # a softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  return model\n",
        "\n",
        "  print('LeNet class defined.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_rMZhdL4eDn",
        "colab_type": "text"
      },
      "source": [
        "## Create & Evaluate Base Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcoTHi6p9N7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epoch = 20\n",
        "batch_size = 25\n",
        "Model = LeNet\n",
        "lr = 0.001\n",
        "optimizer = Adam(lr)\n",
        "batch1 = 32\n",
        "batch2 = 32\n",
        "k_size = (3, 3)\n",
        "conv_stride = (3, 3) \n",
        "p_size = (3, 3)\n",
        "pool_stride = (3, 3) \n",
        "dense =  128\n",
        "\n",
        "train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "plot_results(train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIrzyPg_4jiZ",
        "colab_type": "text"
      },
      "source": [
        "## Parameter Tuning\n",
        "### Note that this method iteratively improves each parameter, which is far less effective than grid search.\n",
        "### However, it is by far less computationally costly and results are still acceptable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWvp0F_M-gJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_df = pd.DataFrame(columns = ['Parameter', 'Accuracy', 'Loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYvb-5p9W6W9",
        "colab_type": "code",
        "outputId": "e35bdc4e-9d4e-42ab-ed33-ff13f52adbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "parameter = 'Kernel Size: '\n",
        "k_sizes = [(3, 3), (5, 5), (7, 7), (1, 5), (5, 1), (1, 7), (7, 1)]\n",
        "\n",
        "for k_size in k_sizes:\n",
        "  train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "  parameter_name = parameter+str(k_size)\n",
        "  parameter_acc = np.mean(test_accuracy)\n",
        "  parameter_loss = np.mean(test_loss)\n",
        "  score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 1, 43, 32)         371552    \n",
            "_________________________________________________________________\n",
            "activation_71 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 1, 5, 32)          2912      \n",
            "_________________________________________________________________\n",
            "activation_72 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_73 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_74 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 376,517\n",
            "Trainable params: 376,517\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.7817 - acc: 0.2500 - val_loss: 1.6005 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3111 - acc: 0.4656 - val_loss: 1.4859 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0500 - acc: 0.5750 - val_loss: 1.4603 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7888 - acc: 0.7031 - val_loss: 1.2438 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4770 - acc: 0.8531 - val_loss: 1.5617 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2630 - acc: 0.9219 - val_loss: 1.7665 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1752 - acc: 0.9469 - val_loss: 1.8395 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1070 - acc: 0.9687 - val_loss: 2.0344 - val_acc: 0.4750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0669 - acc: 0.9812 - val_loss: 1.9958 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0424 - acc: 0.9906 - val_loss: 2.1680 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 960us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7033 - acc: 0.2562 - val_loss: 1.4881 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4120 - acc: 0.3875 - val_loss: 1.3836 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1797 - acc: 0.5062 - val_loss: 1.4413 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9539 - acc: 0.6094 - val_loss: 1.3648 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7610 - acc: 0.7313 - val_loss: 1.3842 - val_acc: 0.4625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5765 - acc: 0.7906 - val_loss: 1.7189 - val_acc: 0.4125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4909 - acc: 0.8531 - val_loss: 1.6373 - val_acc: 0.4625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3719 - acc: 0.9031 - val_loss: 1.5320 - val_acc: 0.4500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2413 - acc: 0.9250 - val_loss: 1.5736 - val_acc: 0.4750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1574 - acc: 0.9562 - val_loss: 1.6105 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 793us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6907 - acc: 0.1906 - val_loss: 1.6440 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4742 - acc: 0.3156 - val_loss: 1.4953 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2382 - acc: 0.4969 - val_loss: 1.4358 - val_acc: 0.3000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9270 - acc: 0.6625 - val_loss: 1.3492 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6444 - acc: 0.7812 - val_loss: 1.3563 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4089 - acc: 0.8875 - val_loss: 1.6946 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2781 - acc: 0.9281 - val_loss: 1.9053 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1592 - acc: 0.9625 - val_loss: 1.8455 - val_acc: 0.4750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1040 - acc: 0.9781 - val_loss: 2.5335 - val_acc: 0.4000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0570 - acc: 0.9937 - val_loss: 2.6087 - val_acc: 0.4375\n",
            "100/100 [==============================] - 0s 814us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6938 - acc: 0.2437 - val_loss: 1.6316 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5835 - acc: 0.2875 - val_loss: 1.4592 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3647 - acc: 0.4125 - val_loss: 1.3646 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1527 - acc: 0.5375 - val_loss: 1.3262 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9324 - acc: 0.6687 - val_loss: 1.1649 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7027 - acc: 0.7812 - val_loss: 1.1913 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4839 - acc: 0.8656 - val_loss: 1.3115 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3313 - acc: 0.9156 - val_loss: 1.4125 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1825 - acc: 0.9656 - val_loss: 1.4810 - val_acc: 0.4500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1193 - acc: 0.9781 - val_loss: 1.5843 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 788us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7587 - acc: 0.2156 - val_loss: 1.5883 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5277 - acc: 0.3531 - val_loss: 1.5182 - val_acc: 0.2625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3627 - acc: 0.4188 - val_loss: 1.4389 - val_acc: 0.3125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1706 - acc: 0.5094 - val_loss: 1.4316 - val_acc: 0.3250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9631 - acc: 0.6656 - val_loss: 1.3666 - val_acc: 0.3500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7589 - acc: 0.8187 - val_loss: 1.3670 - val_acc: 0.4000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5526 - acc: 0.9031 - val_loss: 1.4089 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3674 - acc: 0.9250 - val_loss: 1.5981 - val_acc: 0.4375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2322 - acc: 0.9719 - val_loss: 1.7501 - val_acc: 0.4750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1537 - acc: 0.9719 - val_loss: 1.7584 - val_acc: 0.4625\n",
            "100/100 [==============================] - 0s 780us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7117 - acc: 0.2469 - val_loss: 1.7154 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5251 - acc: 0.3437 - val_loss: 1.4603 - val_acc: 0.3000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2622 - acc: 0.4812 - val_loss: 1.3631 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0257 - acc: 0.6094 - val_loss: 1.2789 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8230 - acc: 0.6875 - val_loss: 1.3963 - val_acc: 0.4250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7717 - acc: 0.7125 - val_loss: 1.2134 - val_acc: 0.4500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6588 - acc: 0.7313 - val_loss: 1.4152 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4951 - acc: 0.8406 - val_loss: 1.5253 - val_acc: 0.4500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3678 - acc: 0.8844 - val_loss: 1.5233 - val_acc: 0.4500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2484 - acc: 0.9500 - val_loss: 1.6967 - val_acc: 0.4625\n",
            "100/100 [==============================] - 0s 796us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7348 - acc: 0.1906 - val_loss: 1.5914 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5532 - acc: 0.3063 - val_loss: 1.5393 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3876 - acc: 0.3813 - val_loss: 1.4445 - val_acc: 0.3250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1765 - acc: 0.5375 - val_loss: 1.2886 - val_acc: 0.3625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9896 - acc: 0.6344 - val_loss: 1.2053 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7450 - acc: 0.7750 - val_loss: 1.1670 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5160 - acc: 0.8562 - val_loss: 1.1968 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3518 - acc: 0.8906 - val_loss: 1.2033 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2035 - acc: 0.9469 - val_loss: 1.2776 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1143 - acc: 0.9937 - val_loss: 1.3806 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 762us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6726 - acc: 0.2094 - val_loss: 1.6710 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5248 - acc: 0.2875 - val_loss: 1.5646 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3542 - acc: 0.4406 - val_loss: 1.5415 - val_acc: 0.3000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1822 - acc: 0.5531 - val_loss: 1.5238 - val_acc: 0.3250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9604 - acc: 0.7094 - val_loss: 1.5672 - val_acc: 0.3250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7528 - acc: 0.8156 - val_loss: 1.6568 - val_acc: 0.3250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5262 - acc: 0.9125 - val_loss: 1.9471 - val_acc: 0.3125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3297 - acc: 0.9531 - val_loss: 2.1423 - val_acc: 0.2875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1805 - acc: 0.9875 - val_loss: 2.3268 - val_acc: 0.2500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0966 - acc: 1.0000 - val_loss: 2.6208 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 783us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6896 - acc: 0.2000 - val_loss: 1.6536 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5786 - acc: 0.2781 - val_loss: 1.5890 - val_acc: 0.3250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4190 - acc: 0.4156 - val_loss: 1.4447 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2065 - acc: 0.5438 - val_loss: 1.3312 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9585 - acc: 0.6063 - val_loss: 1.3397 - val_acc: 0.4125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8043 - acc: 0.6844 - val_loss: 1.3437 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5790 - acc: 0.8156 - val_loss: 1.2576 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4283 - acc: 0.8656 - val_loss: 1.4070 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3181 - acc: 0.9187 - val_loss: 1.5467 - val_acc: 0.4625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2332 - acc: 0.9500 - val_loss: 1.4770 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 822us/step\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_39 (Conv2D)           (None, 1, 43, 32)         1032032   \n",
            "_________________________________________________________________\n",
            "activation_75 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 5, 32)          8032      \n",
            "_________________________________________________________________\n",
            "activation_76 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_77 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_78 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 1,042,117\n",
            "Trainable params: 1,042,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.8043 - acc: 0.2375 - val_loss: 1.3049 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2209 - acc: 0.5062 - val_loss: 1.2206 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9586 - acc: 0.5844 - val_loss: 1.3417 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6509 - acc: 0.7531 - val_loss: 1.2609 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3982 - acc: 0.8875 - val_loss: 1.3714 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2433 - acc: 0.9312 - val_loss: 1.6384 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1467 - acc: 0.9687 - val_loss: 1.6891 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0720 - acc: 0.9812 - val_loss: 1.8722 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0637 - acc: 0.9812 - val_loss: 1.9747 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0308 - acc: 0.9875 - val_loss: 2.2128 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6129 - acc: 0.2625 - val_loss: 1.4560 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2280 - acc: 0.4500 - val_loss: 1.3469 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9120 - acc: 0.6312 - val_loss: 1.2423 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5185 - acc: 0.8094 - val_loss: 1.3178 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2663 - acc: 0.9156 - val_loss: 1.6392 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1430 - acc: 0.9656 - val_loss: 1.8833 - val_acc: 0.4750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0755 - acc: 0.9812 - val_loss: 1.6921 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0319 - acc: 0.9969 - val_loss: 1.7648 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 1.9707 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.8133 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 912us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6465 - acc: 0.2812 - val_loss: 1.4060 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3126 - acc: 0.4469 - val_loss: 1.1961 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1013 - acc: 0.5563 - val_loss: 1.1371 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7273 - acc: 0.7375 - val_loss: 1.2664 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5016 - acc: 0.8250 - val_loss: 1.1932 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2968 - acc: 0.9031 - val_loss: 1.3157 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2007 - acc: 0.9406 - val_loss: 1.5970 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0876 - acc: 0.9812 - val_loss: 1.5983 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0437 - acc: 0.9937 - val_loss: 1.4838 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.6494 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 915us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6711 - acc: 0.1719 - val_loss: 1.6020 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4682 - acc: 0.3187 - val_loss: 1.4299 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1021 - acc: 0.5625 - val_loss: 1.4383 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7675 - acc: 0.7188 - val_loss: 1.3069 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4473 - acc: 0.8312 - val_loss: 1.3015 - val_acc: 0.4500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2699 - acc: 0.9219 - val_loss: 1.2891 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1338 - acc: 0.9812 - val_loss: 1.4473 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0756 - acc: 0.9906 - val_loss: 1.5557 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0442 - acc: 0.9969 - val_loss: 1.8700 - val_acc: 0.4375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0285 - acc: 0.9969 - val_loss: 1.8310 - val_acc: 0.4875\n",
            "100/100 [==============================] - 0s 923us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6421 - acc: 0.2094 - val_loss: 1.4956 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3556 - acc: 0.3906 - val_loss: 1.4750 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0808 - acc: 0.6188 - val_loss: 1.1340 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7514 - acc: 0.7125 - val_loss: 1.0952 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5385 - acc: 0.8094 - val_loss: 1.2912 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4083 - acc: 0.8562 - val_loss: 1.2740 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2306 - acc: 0.9406 - val_loss: 1.2095 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0999 - acc: 0.9812 - val_loss: 1.2503 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0452 - acc: 1.0000 - val_loss: 1.2664 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0284 - acc: 0.9969 - val_loss: 1.2791 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 890us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6225 - acc: 0.2469 - val_loss: 1.5825 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3614 - acc: 0.4312 - val_loss: 1.3192 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1157 - acc: 0.5344 - val_loss: 1.1468 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8286 - acc: 0.6719 - val_loss: 1.0035 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5679 - acc: 0.8156 - val_loss: 1.0115 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3465 - acc: 0.8906 - val_loss: 1.0863 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1909 - acc: 0.9531 - val_loss: 1.3101 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1212 - acc: 0.9719 - val_loss: 1.1080 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0688 - acc: 0.9906 - val_loss: 1.1963 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0263 - acc: 0.9969 - val_loss: 1.1237 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 903us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6549 - acc: 0.2000 - val_loss: 1.6019 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4484 - acc: 0.3906 - val_loss: 1.2858 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1084 - acc: 0.5531 - val_loss: 1.3196 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8606 - acc: 0.6531 - val_loss: 1.1400 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6242 - acc: 0.7375 - val_loss: 1.1761 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4210 - acc: 0.8719 - val_loss: 1.2835 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2058 - acc: 0.9656 - val_loss: 1.3120 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9875 - val_loss: 1.3020 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0506 - acc: 0.9937 - val_loss: 1.3474 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.4920 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 899us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6245 - acc: 0.2438 - val_loss: 1.6442 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5121 - acc: 0.3250 - val_loss: 1.4157 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2335 - acc: 0.5281 - val_loss: 1.2199 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8904 - acc: 0.6813 - val_loss: 1.1153 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6338 - acc: 0.7906 - val_loss: 1.2261 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4087 - acc: 0.8781 - val_loss: 1.2359 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2652 - acc: 0.9375 - val_loss: 1.2818 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1543 - acc: 0.9625 - val_loss: 1.4115 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0733 - acc: 0.9906 - val_loss: 1.5252 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0452 - acc: 1.0000 - val_loss: 1.5187 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 935us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6319 - acc: 0.2469 - val_loss: 1.5983 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3665 - acc: 0.4187 - val_loss: 1.3009 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1486 - acc: 0.5094 - val_loss: 1.5376 - val_acc: 0.3875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9565 - acc: 0.6219 - val_loss: 1.2283 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7413 - acc: 0.6875 - val_loss: 1.3809 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5095 - acc: 0.8312 - val_loss: 1.2076 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3312 - acc: 0.8875 - val_loss: 1.2489 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1745 - acc: 0.9563 - val_loss: 1.3643 - val_acc: 0.4375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1339 - acc: 0.9781 - val_loss: 1.3749 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0667 - acc: 0.9937 - val_loss: 1.6165 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 881us/step\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 1, 43, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 1, 5, 32)          15712     \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_81 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_82 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,040,517\n",
            "Trainable params: 2,040,517\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.6994 - acc: 0.2875 - val_loss: 1.6729 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3829 - acc: 0.4531 - val_loss: 1.3178 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9872 - acc: 0.6187 - val_loss: 1.0709 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6688 - acc: 0.7625 - val_loss: 1.1170 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3468 - acc: 0.8687 - val_loss: 1.1525 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2012 - acc: 0.9312 - val_loss: 1.3162 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0850 - acc: 0.9719 - val_loss: 1.3557 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0432 - acc: 0.9906 - val_loss: 1.3970 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0431 - acc: 0.9875 - val_loss: 1.5181 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0460 - acc: 0.9875 - val_loss: 1.4423 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5657 - acc: 0.2938 - val_loss: 1.5350 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2019 - acc: 0.5094 - val_loss: 1.4325 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0317 - acc: 0.6094 - val_loss: 1.3726 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9044 - acc: 0.6250 - val_loss: 1.6995 - val_acc: 0.3875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6034 - acc: 0.7656 - val_loss: 1.3691 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3775 - acc: 0.8469 - val_loss: 1.5456 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2016 - acc: 0.9250 - val_loss: 1.6555 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1446 - acc: 0.9500 - val_loss: 1.7862 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 0.9844 - val_loss: 2.0057 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0363 - acc: 0.9937 - val_loss: 2.1776 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5759 - acc: 0.3000 - val_loss: 1.4448 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2797 - acc: 0.4656 - val_loss: 1.1352 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8045 - acc: 0.6812 - val_loss: 1.3242 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5247 - acc: 0.7781 - val_loss: 1.3777 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3712 - acc: 0.8812 - val_loss: 1.4993 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2056 - acc: 0.9375 - val_loss: 1.8312 - val_acc: 0.4250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0900 - acc: 0.9594 - val_loss: 1.9244 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0291 - acc: 0.9937 - val_loss: 1.9799 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 2.0129 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.0655 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5935 - acc: 0.2687 - val_loss: 1.4671 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2158 - acc: 0.4969 - val_loss: 1.2864 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8858 - acc: 0.6656 - val_loss: 1.2656 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6511 - acc: 0.7375 - val_loss: 1.1927 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4042 - acc: 0.8344 - val_loss: 1.2493 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2292 - acc: 0.9250 - val_loss: 1.6435 - val_acc: 0.4750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1361 - acc: 0.9562 - val_loss: 1.5572 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0548 - acc: 0.9906 - val_loss: 2.0166 - val_acc: 0.4750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0277 - acc: 0.9969 - val_loss: 1.6418 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.7078 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6070 - acc: 0.2625 - val_loss: 1.4442 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2852 - acc: 0.4250 - val_loss: 1.4469 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0865 - acc: 0.5437 - val_loss: 1.2098 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7414 - acc: 0.7281 - val_loss: 1.4741 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4905 - acc: 0.8281 - val_loss: 1.2672 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2348 - acc: 0.9375 - val_loss: 1.3659 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1068 - acc: 0.9844 - val_loss: 1.6750 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0689 - acc: 0.9875 - val_loss: 1.8760 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0422 - acc: 0.9937 - val_loss: 1.8334 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 2.0672 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5900 - acc: 0.2656 - val_loss: 1.4586 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2650 - acc: 0.4875 - val_loss: 1.1881 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9726 - acc: 0.5938 - val_loss: 1.1199 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7003 - acc: 0.7406 - val_loss: 1.1424 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5775 - acc: 0.7688 - val_loss: 1.2875 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3218 - acc: 0.8906 - val_loss: 1.4641 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1559 - acc: 0.9656 - val_loss: 1.5225 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0712 - acc: 0.9875 - val_loss: 1.4300 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0386 - acc: 0.9969 - val_loss: 1.7434 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 1.7824 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6033 - acc: 0.2500 - val_loss: 1.6002 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3135 - acc: 0.4437 - val_loss: 1.3474 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9471 - acc: 0.6438 - val_loss: 1.2747 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6657 - acc: 0.7375 - val_loss: 1.3947 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4689 - acc: 0.8719 - val_loss: 1.4210 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2688 - acc: 0.9187 - val_loss: 1.3770 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1290 - acc: 0.9781 - val_loss: 1.4979 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0607 - acc: 0.9906 - val_loss: 1.6877 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.5588 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.6452 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5896 - acc: 0.2625 - val_loss: 1.5941 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3106 - acc: 0.4594 - val_loss: 1.2571 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9802 - acc: 0.5875 - val_loss: 1.1648 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6152 - acc: 0.7969 - val_loss: 1.1992 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4089 - acc: 0.8750 - val_loss: 1.5667 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1794 - acc: 0.9625 - val_loss: 1.5300 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0847 - acc: 0.9937 - val_loss: 1.5506 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.7610 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.7103 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.8013 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6110 - acc: 0.2719 - val_loss: 1.6318 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4034 - acc: 0.4125 - val_loss: 1.4080 - val_acc: 0.3125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0314 - acc: 0.6625 - val_loss: 1.2541 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6048 - acc: 0.8063 - val_loss: 1.1574 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3359 - acc: 0.9031 - val_loss: 1.2643 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1618 - acc: 0.9625 - val_loss: 1.3651 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0872 - acc: 0.9906 - val_loss: 1.3789 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 1.7018 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 1.6794 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.6716 - val_acc: 0.4875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_43 (Conv2D)           (None, 1, 43, 32)         206432    \n",
            "_________________________________________________________________\n",
            "activation_83 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 1, 5, 32)          1632      \n",
            "_________________________________________________________________\n",
            "activation_84 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_85 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_86 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 210,117\n",
            "Trainable params: 210,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 2.9915 - acc: 0.2563 - val_loss: 2.1824 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6185 - acc: 0.4500 - val_loss: 1.2888 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0231 - acc: 0.6312 - val_loss: 1.3958 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6963 - acc: 0.7281 - val_loss: 1.0691 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4137 - acc: 0.8719 - val_loss: 1.2279 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2283 - acc: 0.9406 - val_loss: 1.1549 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1540 - acc: 0.9687 - val_loss: 1.2430 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0645 - acc: 0.9906 - val_loss: 1.3170 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0390 - acc: 0.9969 - val_loss: 1.3858 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0232 - acc: 0.9969 - val_loss: 1.3628 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 994us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 2.2845 - acc: 0.2563 - val_loss: 2.2597 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.9893 - acc: 0.3844 - val_loss: 2.1943 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2953 - acc: 0.4906 - val_loss: 2.2380 - val_acc: 0.3750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9308 - acc: 0.6656 - val_loss: 1.5100 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5883 - acc: 0.8031 - val_loss: 1.6273 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4036 - acc: 0.8812 - val_loss: 1.8395 - val_acc: 0.4125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2829 - acc: 0.9219 - val_loss: 1.7301 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1809 - acc: 0.9656 - val_loss: 1.8562 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1123 - acc: 0.9812 - val_loss: 2.0418 - val_acc: 0.4500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0746 - acc: 0.9875 - val_loss: 2.0744 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 794us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7359 - acc: 0.2250 - val_loss: 1.5897 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2499 - acc: 0.4625 - val_loss: 1.0886 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8154 - acc: 0.6969 - val_loss: 1.2004 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5308 - acc: 0.8125 - val_loss: 1.0648 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3436 - acc: 0.9031 - val_loss: 1.3869 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2347 - acc: 0.9406 - val_loss: 1.1777 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1683 - acc: 0.9562 - val_loss: 1.0813 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0792 - acc: 0.9906 - val_loss: 1.3708 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0476 - acc: 0.9969 - val_loss: 1.3288 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 1.4195 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 799us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.8050 - acc: 0.2937 - val_loss: 1.6926 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5759 - acc: 0.3469 - val_loss: 1.5837 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1169 - acc: 0.5563 - val_loss: 1.2432 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7010 - acc: 0.7625 - val_loss: 1.1159 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5038 - acc: 0.8219 - val_loss: 1.0751 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3109 - acc: 0.9312 - val_loss: 1.1223 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1947 - acc: 0.9562 - val_loss: 1.4614 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1325 - acc: 0.9750 - val_loss: 1.3374 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0720 - acc: 1.0000 - val_loss: 1.2379 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0449 - acc: 1.0000 - val_loss: 1.2723 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 830us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6343 - acc: 0.2656 - val_loss: 1.5441 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3142 - acc: 0.4406 - val_loss: 1.4332 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9889 - acc: 0.6156 - val_loss: 1.2356 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6029 - acc: 0.7687 - val_loss: 1.2241 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4083 - acc: 0.8562 - val_loss: 1.1542 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2396 - acc: 0.9375 - val_loss: 1.2091 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1499 - acc: 0.9750 - val_loss: 1.3515 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1045 - acc: 0.9844 - val_loss: 1.5780 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0521 - acc: 0.9969 - val_loss: 1.5836 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 1.4810 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 785us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.8331 - acc: 0.2594 - val_loss: 1.6011 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4031 - acc: 0.5000 - val_loss: 1.3896 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9195 - acc: 0.6531 - val_loss: 1.5657 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7549 - acc: 0.7000 - val_loss: 1.7738 - val_acc: 0.4125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5811 - acc: 0.7969 - val_loss: 1.5862 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4046 - acc: 0.8719 - val_loss: 1.6127 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1938 - acc: 0.9625 - val_loss: 1.6060 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0999 - acc: 0.9875 - val_loss: 1.7289 - val_acc: 0.4500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0565 - acc: 1.0000 - val_loss: 1.6871 - val_acc: 0.4875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0377 - acc: 0.9969 - val_loss: 1.7576 - val_acc: 0.4750\n",
            "100/100 [==============================] - 0s 797us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6933 - acc: 0.2094 - val_loss: 1.6616 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2728 - acc: 0.4750 - val_loss: 1.6636 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0077 - acc: 0.5906 - val_loss: 1.3532 - val_acc: 0.4125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6786 - acc: 0.7625 - val_loss: 1.3128 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4779 - acc: 0.8563 - val_loss: 1.2428 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3232 - acc: 0.9312 - val_loss: 1.4613 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1671 - acc: 0.9687 - val_loss: 1.3674 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0978 - acc: 0.9906 - val_loss: 1.4660 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0660 - acc: 0.9969 - val_loss: 1.9664 - val_acc: 0.4625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0448 - acc: 0.9969 - val_loss: 1.4537 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 786us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7006 - acc: 0.2531 - val_loss: 1.5206 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5321 - acc: 0.3594 - val_loss: 1.3385 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9937 - acc: 0.5844 - val_loss: 1.4134 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7502 - acc: 0.7156 - val_loss: 1.5073 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4897 - acc: 0.8406 - val_loss: 1.6245 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3278 - acc: 0.9125 - val_loss: 1.4653 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2134 - acc: 0.9656 - val_loss: 1.4947 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1305 - acc: 0.9687 - val_loss: 1.7369 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0763 - acc: 0.9937 - val_loss: 1.6667 - val_acc: 0.4750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 1.7878 - val_acc: 0.4500\n",
            "100/100 [==============================] - 0s 776us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6940 - acc: 0.2812 - val_loss: 1.5055 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4396 - acc: 0.4313 - val_loss: 1.7397 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8509 - acc: 0.6688 - val_loss: 1.2275 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6128 - acc: 0.7687 - val_loss: 1.2787 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4236 - acc: 0.8687 - val_loss: 1.2600 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2950 - acc: 0.9344 - val_loss: 1.1894 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2137 - acc: 0.9562 - val_loss: 1.3338 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1054 - acc: 0.9969 - val_loss: 1.4426 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0613 - acc: 0.9969 - val_loss: 1.4132 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0399 - acc: 1.0000 - val_loss: 1.2686 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 774us/step\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_45 (Conv2D)           (None, 1, 43, 32)         206432    \n",
            "_________________________________________________________________\n",
            "activation_87 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 1, 5, 32)          1632      \n",
            "_________________________________________________________________\n",
            "activation_88 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_89 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_90 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 210,117\n",
            "Trainable params: 210,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.7451 - acc: 0.1625 - val_loss: 1.5991 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5842 - acc: 0.2469 - val_loss: 1.6984 - val_acc: 0.1750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4283 - acc: 0.3844 - val_loss: 1.5937 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1539 - acc: 0.5187 - val_loss: 1.7308 - val_acc: 0.2625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8417 - acc: 0.6875 - val_loss: 2.0437 - val_acc: 0.3375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6019 - acc: 0.8000 - val_loss: 2.2928 - val_acc: 0.3125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3972 - acc: 0.8812 - val_loss: 2.9394 - val_acc: 0.3000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2859 - acc: 0.9312 - val_loss: 2.9454 - val_acc: 0.2750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1707 - acc: 0.9531 - val_loss: 2.8918 - val_acc: 0.2750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1111 - acc: 0.9719 - val_loss: 3.1632 - val_acc: 0.2875\n",
            "100/100 [==============================] - 0s 987us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6838 - acc: 0.2125 - val_loss: 1.6544 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6126 - acc: 0.2125 - val_loss: 1.5784 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5355 - acc: 0.2812 - val_loss: 1.5631 - val_acc: 0.3125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4838 - acc: 0.3344 - val_loss: 1.5556 - val_acc: 0.3125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3884 - acc: 0.4187 - val_loss: 1.5278 - val_acc: 0.3500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2449 - acc: 0.5469 - val_loss: 1.4950 - val_acc: 0.4000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0363 - acc: 0.6406 - val_loss: 1.5167 - val_acc: 0.3750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8446 - acc: 0.6906 - val_loss: 1.5694 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6846 - acc: 0.7625 - val_loss: 1.5171 - val_acc: 0.3875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4862 - acc: 0.8656 - val_loss: 1.5839 - val_acc: 0.4000\n",
            "100/100 [==============================] - 0s 826us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6359 - acc: 0.1781 - val_loss: 1.6745 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6060 - acc: 0.2000 - val_loss: 1.6139 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5497 - acc: 0.2625 - val_loss: 1.5811 - val_acc: 0.1750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5036 - acc: 0.3188 - val_loss: 1.5218 - val_acc: 0.3375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4487 - acc: 0.4031 - val_loss: 1.4965 - val_acc: 0.3875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3425 - acc: 0.4719 - val_loss: 1.4111 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1979 - acc: 0.5781 - val_loss: 1.3803 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0000 - acc: 0.6250 - val_loss: 1.3474 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8277 - acc: 0.7031 - val_loss: 1.3841 - val_acc: 0.4125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6674 - acc: 0.7937 - val_loss: 1.4297 - val_acc: 0.4375\n",
            "100/100 [==============================] - 0s 800us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6286 - acc: 0.1812 - val_loss: 1.5705 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6297 - acc: 0.1937 - val_loss: 1.6478 - val_acc: 0.1000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5907 - acc: 0.2594 - val_loss: 1.6200 - val_acc: 0.2250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5193 - acc: 0.3469 - val_loss: 1.5658 - val_acc: 0.3250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4835 - acc: 0.3500 - val_loss: 1.5285 - val_acc: 0.3250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4254 - acc: 0.4469 - val_loss: 1.5021 - val_acc: 0.3500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2927 - acc: 0.5031 - val_loss: 1.4839 - val_acc: 0.3750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1946 - acc: 0.5688 - val_loss: 1.4548 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0459 - acc: 0.6281 - val_loss: 1.4545 - val_acc: 0.4500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8962 - acc: 0.7250 - val_loss: 1.7211 - val_acc: 0.3125\n",
            "100/100 [==============================] - 0s 753us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6220 - acc: 0.2062 - val_loss: 1.5968 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5683 - acc: 0.3656 - val_loss: 1.5667 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4868 - acc: 0.4344 - val_loss: 1.5325 - val_acc: 0.3875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3745 - acc: 0.4656 - val_loss: 1.4104 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2698 - acc: 0.4969 - val_loss: 1.3246 - val_acc: 0.4625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1468 - acc: 0.5500 - val_loss: 1.3340 - val_acc: 0.4500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9996 - acc: 0.6844 - val_loss: 1.3069 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8818 - acc: 0.7156 - val_loss: 1.4080 - val_acc: 0.4625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8330 - acc: 0.7094 - val_loss: 1.4768 - val_acc: 0.3625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6754 - acc: 0.7813 - val_loss: 1.4304 - val_acc: 0.4500\n",
            "100/100 [==============================] - 0s 763us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6254 - acc: 0.1875 - val_loss: 1.6191 - val_acc: 0.1250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5838 - acc: 0.2094 - val_loss: 1.6124 - val_acc: 0.1250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5469 - acc: 0.2562 - val_loss: 1.5749 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4868 - acc: 0.3563 - val_loss: 1.5583 - val_acc: 0.2000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3966 - acc: 0.4625 - val_loss: 1.5025 - val_acc: 0.2500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3172 - acc: 0.5000 - val_loss: 1.4718 - val_acc: 0.4000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1594 - acc: 0.6156 - val_loss: 1.4322 - val_acc: 0.3750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0039 - acc: 0.6875 - val_loss: 1.4168 - val_acc: 0.4250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8602 - acc: 0.7344 - val_loss: 1.4492 - val_acc: 0.4250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7477 - acc: 0.7563 - val_loss: 1.4466 - val_acc: 0.4125\n",
            "100/100 [==============================] - 0s 768us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6280 - acc: 0.1875 - val_loss: 1.6345 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6159 - acc: 0.2687 - val_loss: 1.5935 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5607 - acc: 0.3062 - val_loss: 1.5939 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4819 - acc: 0.4656 - val_loss: 1.5514 - val_acc: 0.3125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3966 - acc: 0.4594 - val_loss: 1.5384 - val_acc: 0.3250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2992 - acc: 0.4750 - val_loss: 1.5076 - val_acc: 0.3125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2024 - acc: 0.5781 - val_loss: 1.4824 - val_acc: 0.3000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0809 - acc: 0.6250 - val_loss: 1.4633 - val_acc: 0.3000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9540 - acc: 0.7125 - val_loss: 1.4553 - val_acc: 0.3875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8090 - acc: 0.7625 - val_loss: 1.5048 - val_acc: 0.3125\n",
            "100/100 [==============================] - 0s 830us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6216 - acc: 0.1750 - val_loss: 1.6407 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5867 - acc: 0.2625 - val_loss: 1.6126 - val_acc: 0.1750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5534 - acc: 0.2813 - val_loss: 1.6006 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5123 - acc: 0.3187 - val_loss: 1.5182 - val_acc: 0.3250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4714 - acc: 0.3844 - val_loss: 1.5353 - val_acc: 0.3250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3063 - acc: 0.5031 - val_loss: 1.4614 - val_acc: 0.3250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2167 - acc: 0.5313 - val_loss: 1.5411 - val_acc: 0.3625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1130 - acc: 0.5562 - val_loss: 1.3913 - val_acc: 0.4250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0184 - acc: 0.5938 - val_loss: 1.3370 - val_acc: 0.3750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9555 - acc: 0.6313 - val_loss: 1.4331 - val_acc: 0.3750\n",
            "100/100 [==============================] - 0s 839us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6103 - acc: 0.1812 - val_loss: 1.6060 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5926 - acc: 0.2094 - val_loss: 1.5685 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5577 - acc: 0.3125 - val_loss: 1.5631 - val_acc: 0.2750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5036 - acc: 0.2781 - val_loss: 1.6113 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4811 - acc: 0.3438 - val_loss: 1.5999 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4290 - acc: 0.3563 - val_loss: 1.6021 - val_acc: 0.2875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3687 - acc: 0.4344 - val_loss: 1.6324 - val_acc: 0.3000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3280 - acc: 0.4312 - val_loss: 1.6138 - val_acc: 0.2500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1901 - acc: 0.5813 - val_loss: 1.5641 - val_acc: 0.4000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1095 - acc: 0.5625 - val_loss: 1.7965 - val_acc: 0.3125\n",
            "100/100 [==============================] - 0s 790us/step\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_47 (Conv2D)           (None, 1, 43, 32)         288992    \n",
            "_________________________________________________________________\n",
            "activation_91 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 1, 5, 32)          2272      \n",
            "_________________________________________________________________\n",
            "activation_92 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_93 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_94 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 293,317\n",
            "Trainable params: 293,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 2.5701 - acc: 0.2875 - val_loss: 2.4702 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5018 - acc: 0.4875 - val_loss: 1.6211 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8933 - acc: 0.6937 - val_loss: 1.5496 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6142 - acc: 0.7594 - val_loss: 1.2768 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3224 - acc: 0.8812 - val_loss: 1.6940 - val_acc: 0.4500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2271 - acc: 0.9156 - val_loss: 1.7816 - val_acc: 0.4750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1189 - acc: 0.9750 - val_loss: 2.0792 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0559 - acc: 0.9937 - val_loss: 1.9824 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0349 - acc: 0.9969 - val_loss: 1.9374 - val_acc: 0.4625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 2.1110 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 776us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7987 - acc: 0.3094 - val_loss: 1.7637 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3682 - acc: 0.4250 - val_loss: 1.5619 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0075 - acc: 0.5938 - val_loss: 1.6112 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5805 - acc: 0.7750 - val_loss: 1.5530 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2632 - acc: 0.9219 - val_loss: 1.5448 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9906 - val_loss: 1.9512 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0472 - acc: 0.9906 - val_loss: 2.4353 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0423 - acc: 0.9875 - val_loss: 2.0525 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 2.1089 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.3388 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 773us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.8403 - acc: 0.2406 - val_loss: 1.5175 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3205 - acc: 0.4562 - val_loss: 1.1312 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9379 - acc: 0.6687 - val_loss: 1.8228 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7796 - acc: 0.6969 - val_loss: 1.3690 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4464 - acc: 0.8594 - val_loss: 1.3100 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1934 - acc: 0.9719 - val_loss: 1.3374 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0843 - acc: 0.9875 - val_loss: 1.2126 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0494 - acc: 0.9969 - val_loss: 1.2189 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 1.4368 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.2980 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 779us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.9339 - acc: 0.2531 - val_loss: 1.6163 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3698 - acc: 0.4281 - val_loss: 1.1771 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0999 - acc: 0.5625 - val_loss: 1.2494 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5435 - acc: 0.7906 - val_loss: 1.9600 - val_acc: 0.4000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5277 - acc: 0.7937 - val_loss: 1.3178 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1938 - acc: 0.9531 - val_loss: 1.5136 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1112 - acc: 0.9750 - val_loss: 1.1767 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0421 - acc: 0.9969 - val_loss: 1.4579 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0227 - acc: 1.0000 - val_loss: 1.3498 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.3997 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 792us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.8331 - acc: 0.2750 - val_loss: 1.5392 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3131 - acc: 0.4344 - val_loss: 1.3633 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0827 - acc: 0.5938 - val_loss: 1.2324 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7168 - acc: 0.7438 - val_loss: 1.0364 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3727 - acc: 0.8937 - val_loss: 1.2996 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1592 - acc: 0.9687 - val_loss: 1.2634 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0640 - acc: 0.9937 - val_loss: 1.1924 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0290 - acc: 1.0000 - val_loss: 1.3902 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.3741 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.4309 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 787us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.8254 - acc: 0.2844 - val_loss: 1.5807 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4122 - acc: 0.4062 - val_loss: 1.2773 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0001 - acc: 0.6156 - val_loss: 1.2256 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6740 - acc: 0.7562 - val_loss: 0.9221 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3569 - acc: 0.9125 - val_loss: 1.3443 - val_acc: 0.4250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1810 - acc: 0.9656 - val_loss: 1.2611 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0784 - acc: 0.9906 - val_loss: 1.0760 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0392 - acc: 1.0000 - val_loss: 1.0919 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.2517 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.0508 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 771us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6688 - acc: 0.3406 - val_loss: 1.4210 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0958 - acc: 0.5094 - val_loss: 1.2948 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6342 - acc: 0.8062 - val_loss: 1.2485 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2950 - acc: 0.9156 - val_loss: 1.3821 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1391 - acc: 0.9594 - val_loss: 1.3700 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0452 - acc: 0.9969 - val_loss: 1.4811 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0249 - acc: 0.9969 - val_loss: 1.6102 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.6006 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.5658 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.6035 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 813us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.8302 - acc: 0.2406 - val_loss: 1.5552 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4495 - acc: 0.3687 - val_loss: 1.3634 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0032 - acc: 0.6031 - val_loss: 1.1492 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5967 - acc: 0.7906 - val_loss: 1.1991 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3165 - acc: 0.9250 - val_loss: 1.2118 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1821 - acc: 0.9594 - val_loss: 1.3653 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1224 - acc: 0.9812 - val_loss: 1.2076 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0735 - acc: 0.9844 - val_loss: 1.2828 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0322 - acc: 1.0000 - val_loss: 1.4231 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.3731 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 788us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.7866 - acc: 0.2375 - val_loss: 1.5610 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3825 - acc: 0.4437 - val_loss: 1.6103 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1491 - acc: 0.5250 - val_loss: 1.4155 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6904 - acc: 0.7656 - val_loss: 1.2157 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3433 - acc: 0.9125 - val_loss: 1.3023 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1601 - acc: 0.9812 - val_loss: 1.2849 - val_acc: 0.4500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0845 - acc: 0.9875 - val_loss: 1.5020 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0444 - acc: 0.9937 - val_loss: 1.4388 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0225 - acc: 1.0000 - val_loss: 1.5554 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.5161 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 794us/step\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_49 (Conv2D)           (None, 1, 43, 32)         288992    \n",
            "_________________________________________________________________\n",
            "activation_95 (Activation)   (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 1, 5, 32)          2272      \n",
            "_________________________________________________________________\n",
            "activation_96 (Activation)   (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_97 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_98 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 293,317\n",
            "Trainable params: 293,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.6792 - acc: 0.2187 - val_loss: 1.4721 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5430 - acc: 0.2781 - val_loss: 1.5446 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4493 - acc: 0.3594 - val_loss: 1.6541 - val_acc: 0.3250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1733 - acc: 0.5031 - val_loss: 1.7640 - val_acc: 0.3375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9455 - acc: 0.6344 - val_loss: 2.2943 - val_acc: 0.3250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7547 - acc: 0.6938 - val_loss: 2.3330 - val_acc: 0.3500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5473 - acc: 0.8219 - val_loss: 2.5993 - val_acc: 0.2500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3988 - acc: 0.8656 - val_loss: 2.5337 - val_acc: 0.3125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2730 - acc: 0.9094 - val_loss: 3.1767 - val_acc: 0.3375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1802 - acc: 0.9406 - val_loss: 2.9784 - val_acc: 0.3500\n",
            "100/100 [==============================] - 0s 910us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6161 - acc: 0.1938 - val_loss: 1.7485 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6241 - acc: 0.2281 - val_loss: 1.5948 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5428 - acc: 0.2750 - val_loss: 1.5753 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4527 - acc: 0.3500 - val_loss: 1.5532 - val_acc: 0.3250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3317 - acc: 0.4406 - val_loss: 1.5755 - val_acc: 0.2875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1580 - acc: 0.5469 - val_loss: 1.6627 - val_acc: 0.3250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9562 - acc: 0.6625 - val_loss: 1.8221 - val_acc: 0.3875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7560 - acc: 0.7281 - val_loss: 1.9638 - val_acc: 0.3500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6023 - acc: 0.7875 - val_loss: 2.4114 - val_acc: 0.3875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4604 - acc: 0.8406 - val_loss: 2.2647 - val_acc: 0.3500\n",
            "100/100 [==============================] - 0s 810us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6164 - acc: 0.2031 - val_loss: 1.6159 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5720 - acc: 0.2656 - val_loss: 1.5605 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5264 - acc: 0.2969 - val_loss: 1.4984 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4337 - acc: 0.3563 - val_loss: 1.4721 - val_acc: 0.3125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2923 - acc: 0.4812 - val_loss: 1.4937 - val_acc: 0.2500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1410 - acc: 0.5406 - val_loss: 1.5627 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9614 - acc: 0.6281 - val_loss: 1.5907 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8498 - acc: 0.7031 - val_loss: 1.5173 - val_acc: 0.4375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6041 - acc: 0.8031 - val_loss: 1.4398 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4584 - acc: 0.8625 - val_loss: 1.5601 - val_acc: 0.4125\n",
            "100/100 [==============================] - 0s 801us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6152 - acc: 0.2219 - val_loss: 1.6746 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5914 - acc: 0.2281 - val_loss: 1.5899 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5453 - acc: 0.3062 - val_loss: 1.5677 - val_acc: 0.2875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4565 - acc: 0.3875 - val_loss: 1.5372 - val_acc: 0.2500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2647 - acc: 0.5219 - val_loss: 1.5837 - val_acc: 0.2625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0590 - acc: 0.6000 - val_loss: 1.8263 - val_acc: 0.2750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8129 - acc: 0.6875 - val_loss: 1.8442 - val_acc: 0.2875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7241 - acc: 0.6938 - val_loss: 1.7407 - val_acc: 0.3625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6277 - acc: 0.7063 - val_loss: 1.6623 - val_acc: 0.3875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4531 - acc: 0.8500 - val_loss: 1.8168 - val_acc: 0.4000\n",
            "100/100 [==============================] - 0s 799us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6201 - acc: 0.2313 - val_loss: 1.6876 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5962 - acc: 0.2625 - val_loss: 1.6180 - val_acc: 0.2250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5596 - acc: 0.2844 - val_loss: 1.6066 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5246 - acc: 0.2969 - val_loss: 1.6196 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4745 - acc: 0.3906 - val_loss: 1.6784 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4221 - acc: 0.3750 - val_loss: 1.6143 - val_acc: 0.2500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3149 - acc: 0.5000 - val_loss: 1.5138 - val_acc: 0.3375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1639 - acc: 0.5937 - val_loss: 1.4906 - val_acc: 0.3500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0125 - acc: 0.6375 - val_loss: 1.5261 - val_acc: 0.3750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8359 - acc: 0.7156 - val_loss: 1.5142 - val_acc: 0.4625\n",
            "100/100 [==============================] - 0s 774us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6219 - acc: 0.1937 - val_loss: 1.6252 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6023 - acc: 0.2312 - val_loss: 1.5758 - val_acc: 0.2625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5509 - acc: 0.2625 - val_loss: 1.5610 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4895 - acc: 0.3469 - val_loss: 1.5315 - val_acc: 0.3625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4050 - acc: 0.4437 - val_loss: 1.5146 - val_acc: 0.2750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2977 - acc: 0.4875 - val_loss: 1.4908 - val_acc: 0.3000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1756 - acc: 0.5281 - val_loss: 1.5318 - val_acc: 0.4125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0477 - acc: 0.6562 - val_loss: 1.6205 - val_acc: 0.3125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9327 - acc: 0.6906 - val_loss: 1.5735 - val_acc: 0.3750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8118 - acc: 0.7281 - val_loss: 1.6401 - val_acc: 0.4250\n",
            "100/100 [==============================] - 0s 797us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6223 - acc: 0.1469 - val_loss: 1.6133 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6053 - acc: 0.2344 - val_loss: 1.6060 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5812 - acc: 0.2500 - val_loss: 1.6083 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5448 - acc: 0.3094 - val_loss: 1.6035 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4952 - acc: 0.3687 - val_loss: 1.5838 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4151 - acc: 0.3687 - val_loss: 1.5703 - val_acc: 0.1750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3080 - acc: 0.4687 - val_loss: 1.5976 - val_acc: 0.3000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1721 - acc: 0.5531 - val_loss: 1.5012 - val_acc: 0.3250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0139 - acc: 0.6563 - val_loss: 1.4888 - val_acc: 0.3625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8909 - acc: 0.6469 - val_loss: 1.5182 - val_acc: 0.4250\n",
            "100/100 [==============================] - 0s 774us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6126 - acc: 0.2219 - val_loss: 1.6164 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5924 - acc: 0.2281 - val_loss: 1.5796 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5530 - acc: 0.2656 - val_loss: 1.5791 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5126 - acc: 0.3031 - val_loss: 1.5681 - val_acc: 0.2500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4526 - acc: 0.3625 - val_loss: 1.5561 - val_acc: 0.3875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3498 - acc: 0.4937 - val_loss: 1.5252 - val_acc: 0.3375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2315 - acc: 0.5594 - val_loss: 1.5181 - val_acc: 0.3500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1099 - acc: 0.6531 - val_loss: 1.5053 - val_acc: 0.3875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9700 - acc: 0.6531 - val_loss: 1.4832 - val_acc: 0.3875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8505 - acc: 0.7156 - val_loss: 1.4918 - val_acc: 0.3875\n",
            "100/100 [==============================] - 0s 810us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6100 - acc: 0.1937 - val_loss: 1.6032 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5882 - acc: 0.2250 - val_loss: 1.5984 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5521 - acc: 0.3375 - val_loss: 1.5769 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5293 - acc: 0.3656 - val_loss: 1.5891 - val_acc: 0.1250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4801 - acc: 0.3781 - val_loss: 1.5414 - val_acc: 0.2625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3654 - acc: 0.5375 - val_loss: 1.4416 - val_acc: 0.4000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2908 - acc: 0.4844 - val_loss: 1.4216 - val_acc: 0.3875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1287 - acc: 0.6625 - val_loss: 1.3936 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9800 - acc: 0.6969 - val_loss: 1.4080 - val_acc: 0.4625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8130 - acc: 0.7250 - val_loss: 1.5150 - val_acc: 0.4000\n",
            "100/100 [==============================] - 0s 781us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQWU_DE7DDnF",
        "colab_type": "code",
        "outputId": "a0066291-6ae6-4f82-c047-c8e2c1b7cbb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "score_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parameter</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kernel Size: (3, 3)</td>\n",
              "      <td>0.473333</td>\n",
              "      <td>1.981357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kernel Size: (5, 5)</td>\n",
              "      <td>0.565556</td>\n",
              "      <td>1.611662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kernel Size: (7, 7)</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>1.577976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kernel Size: (1, 5)</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>1.530358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kernel Size: (5, 1)</td>\n",
              "      <td>0.368889</td>\n",
              "      <td>1.725819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kernel Size: (1, 7)</td>\n",
              "      <td>0.557778</td>\n",
              "      <td>1.488459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kernel Size: (7, 1)</td>\n",
              "      <td>0.407778</td>\n",
              "      <td>1.746344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Parameter  Accuracy      Loss\n",
              "0  Kernel Size: (3, 3)  0.473333  1.981357\n",
              "1  Kernel Size: (5, 5)  0.565556  1.611662\n",
              "2  Kernel Size: (7, 7)  0.588889  1.577976\n",
              "3  Kernel Size: (1, 5)  0.533333  1.530358\n",
              "4  Kernel Size: (5, 1)  0.368889  1.725819\n",
              "5  Kernel Size: (1, 7)  0.557778  1.488459\n",
              "6  Kernel Size: (7, 1)  0.407778  1.746344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpTwRdxfBs-6",
        "colab_type": "code",
        "outputId": "8a441e2f-b5a8-42fe-d3a5-82d252509880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "k_size = (7, 7)\n",
        "\n",
        "parameter = 'Conv Strides: '\n",
        "conv_strides = [(1, 1), (2, 2), (3, 3), (1, 2), (2, 1), (3, 1), (1, 3)]\n",
        "for conv_stride in conv_strides:\n",
        "  train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "  parameter_name = parameter+str(conv_stride)\n",
        "  parameter_acc = np.mean(test_accuracy)\n",
        "  parameter_loss = np.mean(test_loss)\n",
        "  score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_51 (Conv2D)           (None, 1, 128, 32)        2022752   \n",
            "_________________________________________________________________\n",
            "activation_99 (Activation)   (None, 1, 128, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 1, 42, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 1, 42, 32)         15712     \n",
            "_________________________________________________________________\n",
            "activation_100 (Activation)  (None, 1, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 140)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "activation_101 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_102 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,057,157\n",
            "Trainable params: 2,057,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 11.9396 - acc: 0.1937 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.8763 - acc: 0.2250 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 958us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.7852 - acc: 0.2125 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.2225 - acc: 0.2344 - val_loss: 6.8140 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.3095 - acc: 0.4000 - val_loss: 4.4653 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 2.2758 - acc: 0.4875 - val_loss: 1.3040 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9941 - acc: 0.6375 - val_loss: 1.1657 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6847 - acc: 0.7438 - val_loss: 1.0861 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4789 - acc: 0.8406 - val_loss: 1.2111 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3693 - acc: 0.8625 - val_loss: 1.2508 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2875 - acc: 0.9156 - val_loss: 1.2971 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1508 - acc: 0.9500 - val_loss: 1.1919 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0604 - acc: 0.9969 - val_loss: 1.2354 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 973us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1764 - acc: 0.2750 - val_loss: 3.0355 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8012 - acc: 0.4875 - val_loss: 2.2361 - val_acc: 0.2875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1337 - acc: 0.5719 - val_loss: 1.1829 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8860 - acc: 0.6781 - val_loss: 1.3416 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6048 - acc: 0.7844 - val_loss: 1.3137 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3714 - acc: 0.8688 - val_loss: 1.0940 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2129 - acc: 0.9437 - val_loss: 1.1230 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1632 - acc: 0.9469 - val_loss: 1.3065 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0602 - acc: 0.9812 - val_loss: 1.3864 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0283 - acc: 0.9969 - val_loss: 1.3672 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9112 - acc: 0.2875 - val_loss: 3.0266 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6166 - acc: 0.4812 - val_loss: 2.2049 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0724 - acc: 0.6063 - val_loss: 1.1530 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9371 - acc: 0.6531 - val_loss: 1.2332 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5123 - acc: 0.8219 - val_loss: 1.0598 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3821 - acc: 0.8781 - val_loss: 1.1548 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1444 - acc: 0.9719 - val_loss: 1.3047 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0719 - acc: 0.9938 - val_loss: 1.2674 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0307 - acc: 1.0000 - val_loss: 1.2028 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0234 - acc: 0.9969 - val_loss: 1.3596 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5736 - acc: 0.3219 - val_loss: 1.1473 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1427 - acc: 0.5938 - val_loss: 1.6836 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0675 - acc: 0.6375 - val_loss: 0.9193 - val_acc: 0.6375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5454 - acc: 0.7906 - val_loss: 1.1058 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3007 - acc: 0.8844 - val_loss: 0.9784 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1687 - acc: 0.9438 - val_loss: 0.9469 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1121 - acc: 0.9750 - val_loss: 0.9978 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0531 - acc: 0.9906 - val_loss: 0.9931 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 1.3561 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 1.0847 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7087 - acc: 0.2594 - val_loss: 1.6619 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0735 - acc: 0.5281 - val_loss: 1.7354 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8494 - acc: 0.6531 - val_loss: 1.1386 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7225 - acc: 0.7219 - val_loss: 1.0621 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5121 - acc: 0.8281 - val_loss: 0.9793 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3032 - acc: 0.8969 - val_loss: 1.2145 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1093 - acc: 0.9844 - val_loss: 1.1920 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0500 - acc: 0.9937 - val_loss: 1.1419 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.1700 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.2830 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 965us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7143 - acc: 0.2500 - val_loss: 1.4749 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1277 - acc: 0.5437 - val_loss: 1.0585 - val_acc: 0.5750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7752 - acc: 0.7219 - val_loss: 1.2860 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7188 - acc: 0.7344 - val_loss: 1.5438 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4623 - acc: 0.8406 - val_loss: 1.2667 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2550 - acc: 0.9312 - val_loss: 1.0506 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1239 - acc: 0.9750 - val_loss: 0.9486 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0598 - acc: 0.9937 - val_loss: 1.0116 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.9747 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 1.0002 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_53 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_103 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 1, 21, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 1, 11, 32)         15712     \n",
            "_________________________________________________________________\n",
            "activation_104 (Activation)  (None, 1, 11, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 1, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "activation_105 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_106 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,043,077\n",
            "Trainable params: 2,043,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.7840 - acc: 0.2969 - val_loss: 3.0019 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.9445 - acc: 0.3563 - val_loss: 1.5891 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2250 - acc: 0.5187 - val_loss: 1.4693 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1015 - acc: 0.5625 - val_loss: 1.1904 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0092 - acc: 0.5656 - val_loss: 1.4779 - val_acc: 0.4125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7836 - acc: 0.7094 - val_loss: 1.0896 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4998 - acc: 0.8188 - val_loss: 1.2789 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3472 - acc: 0.8875 - val_loss: 1.4123 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2267 - acc: 0.9469 - val_loss: 1.4484 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1369 - acc: 0.9750 - val_loss: 1.6477 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.7424 - acc: 0.3000 - val_loss: 2.3493 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3592 - acc: 0.5000 - val_loss: 1.3827 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9161 - acc: 0.6812 - val_loss: 1.7092 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5457 - acc: 0.8125 - val_loss: 1.2341 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2298 - acc: 0.9406 - val_loss: 1.1172 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1290 - acc: 0.9750 - val_loss: 1.3146 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0795 - acc: 0.9812 - val_loss: 1.4372 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0290 - acc: 1.0000 - val_loss: 1.4933 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.3652 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.4006 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 992us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5857 - acc: 0.2906 - val_loss: 1.1169 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2599 - acc: 0.5031 - val_loss: 1.0850 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9899 - acc: 0.6281 - val_loss: 1.0035 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6229 - acc: 0.7750 - val_loss: 1.8218 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4830 - acc: 0.8125 - val_loss: 1.3443 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2211 - acc: 0.9344 - val_loss: 1.2038 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1063 - acc: 0.9750 - val_loss: 1.0052 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0408 - acc: 0.9969 - val_loss: 1.2422 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 1.4002 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.2822 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5717 - acc: 0.2969 - val_loss: 1.4621 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3063 - acc: 0.4906 - val_loss: 1.0388 - val_acc: 0.6250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8344 - acc: 0.6688 - val_loss: 1.1337 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5797 - acc: 0.7938 - val_loss: 1.3606 - val_acc: 0.4250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3532 - acc: 0.8875 - val_loss: 0.8987 - val_acc: 0.6750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1966 - acc: 0.9562 - val_loss: 0.9470 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0897 - acc: 0.9719 - val_loss: 1.1266 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0427 - acc: 0.9969 - val_loss: 1.0042 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.1800 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.1782 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 977us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5894 - acc: 0.2844 - val_loss: 1.3765 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2530 - acc: 0.5156 - val_loss: 1.6744 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9436 - acc: 0.6531 - val_loss: 1.0684 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6552 - acc: 0.7406 - val_loss: 0.9690 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4696 - acc: 0.8250 - val_loss: 1.1420 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2859 - acc: 0.8969 - val_loss: 1.3648 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1509 - acc: 0.9656 - val_loss: 1.0114 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0804 - acc: 0.9937 - val_loss: 1.1298 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 1.2942 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 1.2606 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5264 - acc: 0.3531 - val_loss: 1.3457 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1001 - acc: 0.5531 - val_loss: 1.6563 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9557 - acc: 0.6344 - val_loss: 1.8299 - val_acc: 0.4125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7335 - acc: 0.7125 - val_loss: 1.1851 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4026 - acc: 0.8781 - val_loss: 1.3919 - val_acc: 0.4500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2689 - acc: 0.9250 - val_loss: 1.1488 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1645 - acc: 0.9562 - val_loss: 1.2738 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1162 - acc: 0.9719 - val_loss: 1.4204 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0565 - acc: 0.9906 - val_loss: 1.4373 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0308 - acc: 0.9969 - val_loss: 1.2666 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5345 - acc: 0.3094 - val_loss: 1.4861 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1337 - acc: 0.5469 - val_loss: 1.6938 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8447 - acc: 0.6719 - val_loss: 1.3116 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5066 - acc: 0.8281 - val_loss: 1.1754 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2564 - acc: 0.9344 - val_loss: 1.0881 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1294 - acc: 0.9844 - val_loss: 1.1478 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0727 - acc: 0.9937 - val_loss: 1.0837 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0418 - acc: 1.0000 - val_loss: 1.1894 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0256 - acc: 1.0000 - val_loss: 1.1113 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 1.2512 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5844 - acc: 0.2438 - val_loss: 1.6638 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3592 - acc: 0.4781 - val_loss: 1.1822 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8931 - acc: 0.6312 - val_loss: 1.3434 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6106 - acc: 0.7750 - val_loss: 1.1840 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3270 - acc: 0.9094 - val_loss: 1.4527 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2601 - acc: 0.9125 - val_loss: 1.3787 - val_acc: 0.4500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1096 - acc: 0.9812 - val_loss: 1.5232 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0663 - acc: 1.0000 - val_loss: 1.5610 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0484 - acc: 0.9937 - val_loss: 1.8842 - val_acc: 0.4625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0375 - acc: 1.0000 - val_loss: 1.7416 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5682 - acc: 0.2656 - val_loss: 1.4680 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2319 - acc: 0.5187 - val_loss: 1.1929 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7771 - acc: 0.7156 - val_loss: 1.1270 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6440 - acc: 0.7500 - val_loss: 1.4360 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4668 - acc: 0.8188 - val_loss: 1.1648 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2101 - acc: 0.9531 - val_loss: 1.0798 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1223 - acc: 0.9781 - val_loss: 1.0696 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0652 - acc: 0.9906 - val_loss: 1.0994 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0296 - acc: 1.0000 - val_loss: 1.1132 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.0692 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_55 (Conv2D)           (None, 1, 43, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_107 (Activation)  (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 1, 5, 32)          15712     \n",
            "_________________________________________________________________\n",
            "activation_108 (Activation)  (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_109 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_110 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,040,517\n",
            "Trainable params: 2,040,517\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.9322 - acc: 0.2687 - val_loss: 2.0490 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2064 - acc: 0.5312 - val_loss: 1.3885 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8877 - acc: 0.6125 - val_loss: 1.3442 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7189 - acc: 0.7281 - val_loss: 1.4961 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4410 - acc: 0.8500 - val_loss: 1.4761 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1728 - acc: 0.9437 - val_loss: 1.8344 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0712 - acc: 0.9781 - val_loss: 1.9749 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0257 - acc: 0.9969 - val_loss: 2.0710 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.1382 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.2987 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6423 - acc: 0.2844 - val_loss: 1.3367 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1328 - acc: 0.5344 - val_loss: 1.4281 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8613 - acc: 0.6281 - val_loss: 1.4448 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5726 - acc: 0.7469 - val_loss: 1.4994 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3408 - acc: 0.8719 - val_loss: 1.4499 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1313 - acc: 0.9531 - val_loss: 1.6746 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1034 - acc: 0.9625 - val_loss: 2.5727 - val_acc: 0.4250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9687 - val_loss: 2.1761 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0936 - acc: 0.9719 - val_loss: 1.8671 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0696 - acc: 0.9812 - val_loss: 2.3074 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.7311 - acc: 0.2719 - val_loss: 1.3840 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3065 - acc: 0.4375 - val_loss: 1.1425 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0277 - acc: 0.5531 - val_loss: 1.2240 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7973 - acc: 0.7031 - val_loss: 0.9458 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5041 - acc: 0.8219 - val_loss: 1.0055 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3190 - acc: 0.8969 - val_loss: 1.1342 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1268 - acc: 0.9844 - val_loss: 1.1940 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0668 - acc: 0.9906 - val_loss: 1.1935 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0492 - acc: 0.9875 - val_loss: 1.2616 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0335 - acc: 0.9906 - val_loss: 1.5189 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.7259 - acc: 0.2250 - val_loss: 1.5190 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3055 - acc: 0.5219 - val_loss: 1.2373 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9748 - acc: 0.6125 - val_loss: 1.1570 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7558 - acc: 0.7000 - val_loss: 1.1348 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4884 - acc: 0.8500 - val_loss: 1.3661 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2920 - acc: 0.9219 - val_loss: 1.1410 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1262 - acc: 0.9687 - val_loss: 1.3763 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0591 - acc: 0.9844 - val_loss: 1.1564 - val_acc: 0.7000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0254 - acc: 0.9969 - val_loss: 1.4114 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0256 - acc: 0.9937 - val_loss: 1.4005 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 993us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6755 - acc: 0.2000 - val_loss: 1.6699 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5083 - acc: 0.3187 - val_loss: 1.3571 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1433 - acc: 0.5500 - val_loss: 1.2050 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9843 - acc: 0.5750 - val_loss: 1.1109 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7258 - acc: 0.6812 - val_loss: 1.1512 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5832 - acc: 0.7594 - val_loss: 1.2952 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4452 - acc: 0.8437 - val_loss: 1.1077 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2362 - acc: 0.9219 - val_loss: 1.2036 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1475 - acc: 0.9531 - val_loss: 1.3144 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0734 - acc: 0.9875 - val_loss: 1.4318 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6986 - acc: 0.2031 - val_loss: 1.6386 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4865 - acc: 0.3562 - val_loss: 1.5452 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0654 - acc: 0.5719 - val_loss: 1.1336 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9073 - acc: 0.6000 - val_loss: 1.0929 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5675 - acc: 0.7469 - val_loss: 1.1670 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4332 - acc: 0.8344 - val_loss: 1.2537 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2768 - acc: 0.9031 - val_loss: 1.8294 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1607 - acc: 0.9594 - val_loss: 1.8845 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0837 - acc: 0.9812 - val_loss: 1.5384 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0457 - acc: 0.9969 - val_loss: 1.6310 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.7060 - acc: 0.2000 - val_loss: 1.6256 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5431 - acc: 0.3125 - val_loss: 1.4304 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2142 - acc: 0.5469 - val_loss: 1.1765 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8563 - acc: 0.6625 - val_loss: 1.0461 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5762 - acc: 0.8094 - val_loss: 1.1090 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3965 - acc: 0.8531 - val_loss: 1.4661 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2397 - acc: 0.9219 - val_loss: 1.5656 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0811 - acc: 0.9875 - val_loss: 1.6530 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0320 - acc: 1.0000 - val_loss: 1.5652 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 1.7660 - val_acc: 0.4875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6714 - acc: 0.2062 - val_loss: 1.6692 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5711 - acc: 0.2469 - val_loss: 1.5123 - val_acc: 0.3250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2532 - acc: 0.5188 - val_loss: 1.3770 - val_acc: 0.3875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9569 - acc: 0.6094 - val_loss: 1.0770 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6865 - acc: 0.7563 - val_loss: 1.1403 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4767 - acc: 0.8281 - val_loss: 1.3635 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3028 - acc: 0.9125 - val_loss: 1.2578 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1642 - acc: 0.9500 - val_loss: 1.4146 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1122 - acc: 0.9781 - val_loss: 1.7119 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 1.3768 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 998us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6668 - acc: 0.2062 - val_loss: 1.6804 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5411 - acc: 0.2531 - val_loss: 1.5914 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2755 - acc: 0.4687 - val_loss: 1.2428 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9033 - acc: 0.6563 - val_loss: 1.2269 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6060 - acc: 0.7594 - val_loss: 1.1710 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3803 - acc: 0.8781 - val_loss: 1.3329 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1787 - acc: 0.9594 - val_loss: 1.3887 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0917 - acc: 0.9875 - val_loss: 1.5725 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0453 - acc: 0.9969 - val_loss: 1.4028 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.7444 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 994us/step\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_111 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 1, 21, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 1, 11, 32)         15712     \n",
            "_________________________________________________________________\n",
            "activation_112 (Activation)  (None, 1, 11, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 1, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "activation_113 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_114 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,043,077\n",
            "Trainable params: 2,043,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 3.7528 - acc: 0.2031 - val_loss: 1.7706 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6669 - acc: 0.3937 - val_loss: 1.3293 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2659 - acc: 0.4469 - val_loss: 1.2757 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0285 - acc: 0.6062 - val_loss: 1.0512 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7426 - acc: 0.7063 - val_loss: 1.1591 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4984 - acc: 0.8375 - val_loss: 1.0768 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3593 - acc: 0.8937 - val_loss: 1.2254 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2351 - acc: 0.9375 - val_loss: 1.3895 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1484 - acc: 0.9531 - val_loss: 1.4201 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0953 - acc: 0.9719 - val_loss: 1.7895 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.8155 - acc: 0.2937 - val_loss: 1.8565 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4549 - acc: 0.4500 - val_loss: 1.6089 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0337 - acc: 0.5844 - val_loss: 1.3728 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6393 - acc: 0.7750 - val_loss: 1.3408 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2842 - acc: 0.9187 - val_loss: 1.5299 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3203 - acc: 0.8719 - val_loss: 1.4556 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1301 - acc: 0.9781 - val_loss: 1.7808 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0740 - acc: 0.9875 - val_loss: 1.5878 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0343 - acc: 0.9969 - val_loss: 1.6742 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0174 - acc: 0.9969 - val_loss: 2.0021 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 999us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6889 - acc: 0.2594 - val_loss: 1.2786 - val_acc: 0.5125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4696 - acc: 0.4719 - val_loss: 1.1936 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8720 - acc: 0.6875 - val_loss: 1.1304 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5356 - acc: 0.8000 - val_loss: 1.2355 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3294 - acc: 0.8937 - val_loss: 1.1937 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1526 - acc: 0.9437 - val_loss: 1.1706 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9969 - val_loss: 1.2947 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0379 - acc: 0.9937 - val_loss: 1.2469 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.1622 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.2092 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5810 - acc: 0.3281 - val_loss: 1.4160 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2169 - acc: 0.5094 - val_loss: 1.4491 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8546 - acc: 0.6969 - val_loss: 1.3507 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5484 - acc: 0.7938 - val_loss: 1.2209 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2640 - acc: 0.9094 - val_loss: 1.3139 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1688 - acc: 0.9562 - val_loss: 1.2191 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1233 - acc: 0.9656 - val_loss: 1.5401 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0549 - acc: 0.9969 - val_loss: 1.4239 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0297 - acc: 0.9969 - val_loss: 1.4363 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.4658 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6039 - acc: 0.2625 - val_loss: 1.6325 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3150 - acc: 0.5031 - val_loss: 1.2477 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8439 - acc: 0.6750 - val_loss: 1.1502 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5680 - acc: 0.8094 - val_loss: 1.2107 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4116 - acc: 0.8625 - val_loss: 1.0914 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1606 - acc: 0.9594 - val_loss: 1.4071 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0922 - acc: 0.9812 - val_loss: 1.6116 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0637 - acc: 0.9844 - val_loss: 1.3252 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 1.1366 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 1.2655 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6311 - acc: 0.2594 - val_loss: 1.5879 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6891 - acc: 0.4156 - val_loss: 2.2154 - val_acc: 0.3125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3056 - acc: 0.4406 - val_loss: 1.3094 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8700 - acc: 0.6594 - val_loss: 1.3108 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5413 - acc: 0.8219 - val_loss: 1.2361 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3276 - acc: 0.9094 - val_loss: 1.7655 - val_acc: 0.3875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2199 - acc: 0.9406 - val_loss: 1.6600 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0822 - acc: 1.0000 - val_loss: 1.5644 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0513 - acc: 0.9969 - val_loss: 1.6485 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 1.5411 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6568 - acc: 0.2687 - val_loss: 1.4580 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2270 - acc: 0.4906 - val_loss: 1.4949 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.9203 - acc: 0.6781 - val_loss: 1.4047 - val_acc: 0.4125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8081 - acc: 0.6750 - val_loss: 1.7705 - val_acc: 0.3875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4315 - acc: 0.8406 - val_loss: 1.4315 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2006 - acc: 0.9594 - val_loss: 1.2875 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1053 - acc: 0.9844 - val_loss: 1.4075 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.9781 - val_loss: 1.4014 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0367 - acc: 0.9938 - val_loss: 1.4347 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.4136 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 990us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5938 - acc: 0.3313 - val_loss: 1.5623 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3299 - acc: 0.4844 - val_loss: 1.4613 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9815 - acc: 0.6219 - val_loss: 1.3007 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5565 - acc: 0.8125 - val_loss: 1.3996 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4966 - acc: 0.8375 - val_loss: 1.3325 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2130 - acc: 0.9656 - val_loss: 1.4748 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1168 - acc: 0.9781 - val_loss: 1.6397 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 1.5584 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0312 - acc: 1.0000 - val_loss: 1.7137 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.6580 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 982us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6238 - acc: 0.3031 - val_loss: 1.7010 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5456 - acc: 0.3594 - val_loss: 1.6219 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1025 - acc: 0.5594 - val_loss: 1.1903 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7189 - acc: 0.7406 - val_loss: 1.1781 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4680 - acc: 0.8906 - val_loss: 1.4222 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.3666 - acc: 0.8969 - val_loss: 1.1699 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2688 - acc: 0.9406 - val_loss: 1.2884 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1262 - acc: 0.9812 - val_loss: 1.3625 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0677 - acc: 0.9937 - val_loss: 1.3372 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0377 - acc: 0.9969 - val_loss: 1.5023 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_59 (Conv2D)           (None, 1, 128, 32)        2022752   \n",
            "_________________________________________________________________\n",
            "activation_115 (Activation)  (None, 1, 128, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 1, 42, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 1, 42, 32)         15712     \n",
            "_________________________________________________________________\n",
            "activation_116 (Activation)  (None, 1, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 140)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "activation_117 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_118 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,057,157\n",
            "Trainable params: 2,057,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 10ms/step - loss: 10.7266 - acc: 0.2219 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.1721 - acc: 0.2625 - val_loss: 11.7484 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.1310 - acc: 0.3187 - val_loss: 8.7111 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.1742 - acc: 0.3781 - val_loss: 1.8723 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3258 - acc: 0.4844 - val_loss: 1.1587 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7367 - acc: 0.7125 - val_loss: 1.2186 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5262 - acc: 0.8219 - val_loss: 1.3539 - val_acc: 0.4625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3341 - acc: 0.8844 - val_loss: 1.0582 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1857 - acc: 0.9625 - val_loss: 1.2029 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1221 - acc: 0.9656 - val_loss: 1.2372 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0580 - acc: 0.9906 - val_loss: 1.2189 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 1.2904 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.5255 - acc: 0.3281 - val_loss: 3.6156 - val_acc: 0.1250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9919 - acc: 0.4250 - val_loss: 1.5513 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2383 - acc: 0.5625 - val_loss: 1.2250 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0939 - acc: 0.6219 - val_loss: 1.1114 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6093 - acc: 0.7688 - val_loss: 0.9033 - val_acc: 0.7000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3906 - acc: 0.8656 - val_loss: 1.0275 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2623 - acc: 0.9156 - val_loss: 1.0238 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2165 - acc: 0.9437 - val_loss: 0.8864 - val_acc: 0.7125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0832 - acc: 0.9937 - val_loss: 1.2462 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0476 - acc: 0.9969 - val_loss: 0.9850 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7742 - acc: 0.3219 - val_loss: 1.8484 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3954 - acc: 0.5031 - val_loss: 1.2572 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0269 - acc: 0.5563 - val_loss: 1.3076 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6611 - acc: 0.7219 - val_loss: 1.1773 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4977 - acc: 0.8281 - val_loss: 1.1658 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3739 - acc: 0.8719 - val_loss: 1.0939 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1082 - acc: 0.9719 - val_loss: 1.4262 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1047 - acc: 0.9687 - val_loss: 1.3280 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0452 - acc: 0.9875 - val_loss: 1.4270 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 1.1462 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7822 - acc: 0.3000 - val_loss: 1.3564 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3484 - acc: 0.4781 - val_loss: 1.2399 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9703 - acc: 0.6656 - val_loss: 1.7594 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8499 - acc: 0.6344 - val_loss: 1.2188 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6120 - acc: 0.7562 - val_loss: 1.0599 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4527 - acc: 0.8125 - val_loss: 1.1108 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2557 - acc: 0.9250 - val_loss: 1.1918 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0945 - acc: 0.9875 - val_loss: 1.1210 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.9029 - val_acc: 0.6875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.9204 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5948 - acc: 0.3656 - val_loss: 1.7046 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2800 - acc: 0.5250 - val_loss: 1.5319 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9920 - acc: 0.6406 - val_loss: 1.3538 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7035 - acc: 0.7344 - val_loss: 1.3473 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5507 - acc: 0.8000 - val_loss: 1.3246 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3037 - acc: 0.9062 - val_loss: 1.2029 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2296 - acc: 0.9281 - val_loss: 1.4852 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0858 - acc: 0.9844 - val_loss: 1.2847 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0421 - acc: 0.9969 - val_loss: 1.2184 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 1.4255 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5744 - acc: 0.3406 - val_loss: 1.6609 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0944 - acc: 0.5844 - val_loss: 1.3029 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6783 - acc: 0.7563 - val_loss: 1.4741 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5210 - acc: 0.8125 - val_loss: 1.7535 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3528 - acc: 0.8906 - val_loss: 1.4963 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2232 - acc: 0.9281 - val_loss: 1.4553 - val_acc: 0.4500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0814 - acc: 0.9906 - val_loss: 1.5612 - val_acc: 0.4500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0471 - acc: 0.9937 - val_loss: 1.5524 - val_acc: 0.4750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 1.6178 - val_acc: 0.4750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.6581 - val_acc: 0.4750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9398 - acc: 0.3281 - val_loss: 2.1909 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6477 - acc: 0.4812 - val_loss: 2.3813 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4044 - acc: 0.5594 - val_loss: 1.2575 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0526 - acc: 0.6219 - val_loss: 1.1703 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7927 - acc: 0.7156 - val_loss: 1.2586 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5459 - acc: 0.7938 - val_loss: 0.9374 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2878 - acc: 0.9344 - val_loss: 1.0254 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1892 - acc: 0.9594 - val_loss: 1.0710 - val_acc: 0.7125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1443 - acc: 0.9625 - val_loss: 1.1036 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0588 - acc: 1.0000 - val_loss: 1.0748 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_61 (Conv2D)           (None, 1, 128, 32)        2022752   \n",
            "_________________________________________________________________\n",
            "activation_119 (Activation)  (None, 1, 128, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling (None, 1, 42, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 1, 42, 32)         15712     \n",
            "_________________________________________________________________\n",
            "activation_120 (Activation)  (None, 1, 42, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 140)               0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "activation_121 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_122 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,057,157\n",
            "Trainable params: 2,057,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 10ms/step - loss: 11.6394 - acc: 0.2187 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.3325 - acc: 0.1906 - val_loss: 12.4284 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.1467 - acc: 0.2969 - val_loss: 12.2906 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.9564 - acc: 0.2531 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.1918 - acc: 0.2250 - val_loss: 3.2594 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2699 - acc: 0.3906 - val_loss: 1.3533 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1509 - acc: 0.5125 - val_loss: 1.2334 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7884 - acc: 0.7094 - val_loss: 0.9436 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6699 - acc: 0.7344 - val_loss: 1.0480 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5500 - acc: 0.7906 - val_loss: 1.5616 - val_acc: 0.4375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5881 - acc: 0.7531 - val_loss: 0.8874 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3224 - acc: 0.9156 - val_loss: 1.0768 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2442 - acc: 0.9375 - val_loss: 0.8566 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1526 - acc: 0.9625 - val_loss: 0.7681 - val_acc: 0.7375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2099 - acc: 0.2625 - val_loss: 1.3699 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2127 - acc: 0.5063 - val_loss: 1.1226 - val_acc: 0.5750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8741 - acc: 0.6687 - val_loss: 0.8937 - val_acc: 0.6375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6915 - acc: 0.7344 - val_loss: 0.9278 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5771 - acc: 0.7812 - val_loss: 1.2357 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3576 - acc: 0.8844 - val_loss: 0.8793 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2117 - acc: 0.9344 - val_loss: 0.9331 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1048 - acc: 0.9781 - val_loss: 0.8501 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 0.6875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 1.0356 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1808 - acc: 0.2406 - val_loss: 2.3750 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7809 - acc: 0.3937 - val_loss: 1.6570 - val_acc: 0.2875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2171 - acc: 0.5437 - val_loss: 1.0229 - val_acc: 0.6125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7927 - acc: 0.6938 - val_loss: 0.8698 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5476 - acc: 0.7937 - val_loss: 0.9003 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3625 - acc: 0.8781 - val_loss: 1.0017 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2333 - acc: 0.9312 - val_loss: 1.4046 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2225 - acc: 0.9250 - val_loss: 1.5682 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2050 - acc: 0.9437 - val_loss: 1.1324 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0803 - acc: 0.9844 - val_loss: 1.2592 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3085 - acc: 0.2969 - val_loss: 1.6509 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4859 - acc: 0.4406 - val_loss: 1.0736 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0945 - acc: 0.5687 - val_loss: 1.2331 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8474 - acc: 0.7000 - val_loss: 1.3314 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5653 - acc: 0.8031 - val_loss: 0.9091 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3419 - acc: 0.8937 - val_loss: 1.0347 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2424 - acc: 0.9281 - val_loss: 0.9675 - val_acc: 0.6875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1393 - acc: 0.9531 - val_loss: 1.2434 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1613 - acc: 0.9500 - val_loss: 1.1262 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0605 - acc: 0.9937 - val_loss: 1.0742 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1772 - acc: 0.2500 - val_loss: 2.4606 - val_acc: 0.1500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5360 - acc: 0.4156 - val_loss: 1.4554 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2337 - acc: 0.5531 - val_loss: 2.0219 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8492 - acc: 0.6687 - val_loss: 1.2662 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5373 - acc: 0.8063 - val_loss: 1.3160 - val_acc: 0.4500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4150 - acc: 0.8406 - val_loss: 1.5711 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2627 - acc: 0.9031 - val_loss: 0.9520 - val_acc: 0.6875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1782 - acc: 0.9469 - val_loss: 1.1608 - val_acc: 0.4750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1020 - acc: 0.9719 - val_loss: 1.1823 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0721 - acc: 0.9844 - val_loss: 1.1445 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9516 - acc: 0.2844 - val_loss: 1.6501 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2104 - acc: 0.4844 - val_loss: 1.1743 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0704 - acc: 0.6187 - val_loss: 1.1497 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8047 - acc: 0.6844 - val_loss: 0.9982 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4511 - acc: 0.8500 - val_loss: 0.8524 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2587 - acc: 0.9219 - val_loss: 0.8413 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1493 - acc: 0.9625 - val_loss: 0.9407 - val_acc: 0.7000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0760 - acc: 0.9937 - val_loss: 1.0249 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0442 - acc: 0.9969 - val_loss: 0.8908 - val_acc: 0.7500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.9233 - val_acc: 0.7500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8467 - acc: 0.2531 - val_loss: 1.7293 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4037 - acc: 0.4375 - val_loss: 1.1155 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0165 - acc: 0.6188 - val_loss: 1.0968 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6912 - acc: 0.7344 - val_loss: 1.0712 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4841 - acc: 0.8219 - val_loss: 0.9939 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2831 - acc: 0.9187 - val_loss: 0.8850 - val_acc: 0.7125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1659 - acc: 0.9719 - val_loss: 0.9969 - val_acc: 0.6875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1064 - acc: 0.9812 - val_loss: 1.1888 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0604 - acc: 0.9937 - val_loss: 1.2420 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0380 - acc: 0.9937 - val_loss: 1.2318 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_63 (Conv2D)           (None, 1, 43, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_123 (Activation)  (None, 1, 43, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling (None, 1, 14, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 1, 5, 32)          15712     \n",
            "_________________________________________________________________\n",
            "activation_124 (Activation)  (None, 1, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_31 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "activation_125 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_126 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,040,517\n",
            "Trainable params: 2,040,517\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 10ms/step - loss: 2.0450 - acc: 0.2406 - val_loss: 1.6081 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5474 - acc: 0.3313 - val_loss: 1.4882 - val_acc: 0.3125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1794 - acc: 0.4875 - val_loss: 1.2797 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8167 - acc: 0.6781 - val_loss: 1.0659 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5232 - acc: 0.8063 - val_loss: 1.2477 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2984 - acc: 0.9031 - val_loss: 1.1978 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1664 - acc: 0.9500 - val_loss: 1.1563 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0756 - acc: 0.9812 - val_loss: 1.4276 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0415 - acc: 0.9906 - val_loss: 1.3087 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.5135 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6656 - acc: 0.2375 - val_loss: 1.7310 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1754 - acc: 0.5250 - val_loss: 1.3154 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6628 - acc: 0.7656 - val_loss: 1.3243 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4149 - acc: 0.8719 - val_loss: 1.4643 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2023 - acc: 0.9500 - val_loss: 1.8486 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0916 - acc: 0.9781 - val_loss: 1.9701 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0373 - acc: 0.9969 - val_loss: 2.4007 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0342 - acc: 0.9969 - val_loss: 2.0515 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0118 - acc: 0.9969 - val_loss: 2.3953 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.2138 - val_acc: 0.4750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6257 - acc: 0.2500 - val_loss: 1.5012 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3272 - acc: 0.4719 - val_loss: 1.2292 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8395 - acc: 0.6938 - val_loss: 1.0659 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4679 - acc: 0.8187 - val_loss: 1.4283 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3205 - acc: 0.9031 - val_loss: 1.1264 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1171 - acc: 0.9656 - val_loss: 1.6479 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0492 - acc: 0.9875 - val_loss: 1.7901 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 1.7908 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0139 - acc: 0.9969 - val_loss: 1.8067 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0167 - acc: 0.9969 - val_loss: 2.1467 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6174 - acc: 0.2188 - val_loss: 1.3735 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3068 - acc: 0.4406 - val_loss: 1.2428 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1815 - acc: 0.4969 - val_loss: 1.3511 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7553 - acc: 0.6719 - val_loss: 1.3814 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4257 - acc: 0.8250 - val_loss: 1.5240 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2009 - acc: 0.9281 - val_loss: 1.5133 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1117 - acc: 0.9719 - val_loss: 1.6202 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0429 - acc: 0.9906 - val_loss: 1.7417 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0190 - acc: 0.9969 - val_loss: 1.8658 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.8303 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6232 - acc: 0.1844 - val_loss: 1.5573 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4739 - acc: 0.3062 - val_loss: 1.4482 - val_acc: 0.2875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0908 - acc: 0.5813 - val_loss: 1.2260 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6170 - acc: 0.7844 - val_loss: 1.3004 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3122 - acc: 0.9281 - val_loss: 1.2777 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1612 - acc: 0.9687 - val_loss: 1.5910 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0547 - acc: 1.0000 - val_loss: 1.5862 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 1.7365 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.8236 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.7941 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6223 - acc: 0.2094 - val_loss: 1.5863 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3765 - acc: 0.4344 - val_loss: 1.3241 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9483 - acc: 0.6094 - val_loss: 1.4205 - val_acc: 0.4125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5653 - acc: 0.8156 - val_loss: 1.3320 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3052 - acc: 0.9031 - val_loss: 1.4143 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1776 - acc: 0.9438 - val_loss: 1.6344 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0848 - acc: 0.9781 - val_loss: 1.5985 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0257 - acc: 0.9969 - val_loss: 1.6025 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.6499 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.6806 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5875 - acc: 0.2125 - val_loss: 1.7803 - val_acc: 0.1500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4766 - acc: 0.2906 - val_loss: 1.3673 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1655 - acc: 0.5188 - val_loss: 1.3951 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8372 - acc: 0.6969 - val_loss: 1.3008 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5328 - acc: 0.8188 - val_loss: 1.0872 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3186 - acc: 0.9125 - val_loss: 1.4180 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1800 - acc: 0.9500 - val_loss: 1.4548 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1000 - acc: 0.9750 - val_loss: 1.4112 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0676 - acc: 0.9875 - val_loss: 1.5807 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0298 - acc: 0.9969 - val_loss: 1.7079 - val_acc: 0.4750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6320 - acc: 0.2000 - val_loss: 1.6051 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4730 - acc: 0.3500 - val_loss: 1.5128 - val_acc: 0.3000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1772 - acc: 0.5469 - val_loss: 1.4437 - val_acc: 0.3500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8362 - acc: 0.7062 - val_loss: 1.1534 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5397 - acc: 0.8188 - val_loss: 1.3033 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2671 - acc: 0.9437 - val_loss: 1.6610 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1343 - acc: 0.9781 - val_loss: 1.5565 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0562 - acc: 0.9937 - val_loss: 1.6590 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 1.6820 - val_acc: 0.4875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.7288 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6259 - acc: 0.1750 - val_loss: 1.5540 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4948 - acc: 0.2969 - val_loss: 1.4599 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1924 - acc: 0.4594 - val_loss: 1.5998 - val_acc: 0.3375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9742 - acc: 0.6031 - val_loss: 1.0402 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6133 - acc: 0.7937 - val_loss: 1.1661 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3279 - acc: 0.9031 - val_loss: 1.0275 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2166 - acc: 0.9437 - val_loss: 1.0468 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0857 - acc: 0.9844 - val_loss: 0.9800 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 1.0928 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 1.0578 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQRHz7KEDO9O",
        "colab_type": "code",
        "outputId": "df74600e-b83d-4ba8-e6e3-ba0b8a5d90c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "score_df "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parameter</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kernel Size: (3, 3)</td>\n",
              "      <td>0.473333</td>\n",
              "      <td>1.981357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kernel Size: (5, 5)</td>\n",
              "      <td>0.565556</td>\n",
              "      <td>1.611662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kernel Size: (7, 7)</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>1.577976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kernel Size: (1, 5)</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>1.530358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kernel Size: (5, 1)</td>\n",
              "      <td>0.368889</td>\n",
              "      <td>1.725819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kernel Size: (1, 7)</td>\n",
              "      <td>0.557778</td>\n",
              "      <td>1.488459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kernel Size: (7, 1)</td>\n",
              "      <td>0.407778</td>\n",
              "      <td>1.746344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Conv Strides: (1, 1)</td>\n",
              "      <td>0.504444</td>\n",
              "      <td>5.114644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Conv Strides: (2, 2)</td>\n",
              "      <td>0.595556</td>\n",
              "      <td>1.339987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Conv Strides: (3, 3)</td>\n",
              "      <td>0.602222</td>\n",
              "      <td>1.447754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Conv Strides: (1, 2)</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>1.342004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Conv Strides: (2, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.748762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Conv Strides: (3, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.823076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Conv Strides: (1, 3)</td>\n",
              "      <td>0.563333</td>\n",
              "      <td>1.780330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Batch Size: 32x32</td>\n",
              "      <td>0.577778</td>\n",
              "      <td>1.482059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Batch Size: 32x64</td>\n",
              "      <td>0.621111</td>\n",
              "      <td>1.388098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Batch Size: 32x128</td>\n",
              "      <td>0.606667</td>\n",
              "      <td>1.410528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Batch Size: 64x32</td>\n",
              "      <td>0.598889</td>\n",
              "      <td>1.449866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Parameter  Accuracy      Loss\n",
              "0    Kernel Size: (3, 3)  0.473333  1.981357\n",
              "1    Kernel Size: (5, 5)  0.565556  1.611662\n",
              "2    Kernel Size: (7, 7)  0.588889  1.577976\n",
              "3    Kernel Size: (1, 5)  0.533333  1.530358\n",
              "4    Kernel Size: (5, 1)  0.368889  1.725819\n",
              "5    Kernel Size: (1, 7)  0.557778  1.488459\n",
              "6    Kernel Size: (7, 1)  0.407778  1.746344\n",
              "7   Conv Strides: (1, 1)  0.504444  5.114644\n",
              "8   Conv Strides: (2, 2)  0.595556  1.339987\n",
              "9   Conv Strides: (3, 3)  0.602222  1.447754\n",
              "10  Conv Strides: (1, 2)  0.610000  1.342004\n",
              "11  Conv Strides: (2, 1)  0.528889  3.748762\n",
              "12  Conv Strides: (3, 1)  0.528889  3.823076\n",
              "13  Conv Strides: (1, 3)  0.563333  1.780330\n",
              "14     Batch Size: 32x32  0.577778  1.482059\n",
              "15     Batch Size: 32x64  0.621111  1.388098\n",
              "16    Batch Size: 32x128  0.606667  1.410528\n",
              "17     Batch Size: 64x32  0.598889  1.449866"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqACrCrA-ft",
        "colab_type": "code",
        "outputId": "66914826-f5d5-4c2f-fa3f-fa5d48ffaf0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_stride = (1, 2)\n",
        "\n",
        "parameter = 'Batch Size: '\n",
        "batch_sizes = [32, 64, 128]\n",
        "\n",
        "for batch1 in batch_sizes:\n",
        "  for batch2 in batch_sizes:\n",
        "    train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                            optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "    parameter_name = parameter+str(batch1)+\"x\"+str(batch2)\n",
        "    parameter_acc = np.mean(test_accuracy)\n",
        "    parameter_loss = np.mean(test_loss)\n",
        "    score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_75 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_147 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_75 (MaxPooling (None, 1, 21, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 1, 11, 32)         15712     \n",
            "_________________________________________________________________\n",
            "activation_148 (Activation)  (None, 1, 11, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_76 (MaxPooling (None, 1, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_37 (Flatten)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "activation_149 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_150 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,043,077\n",
            "Trainable params: 2,043,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 4s 13ms/step - loss: 7.1418 - acc: 0.1844 - val_loss: 6.4332 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.0892 - acc: 0.2750 - val_loss: 5.2766 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.0937 - acc: 0.3219 - val_loss: 4.6363 - val_acc: 0.3500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8193 - acc: 0.3313 - val_loss: 1.4904 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3639 - acc: 0.4312 - val_loss: 1.5258 - val_acc: 0.3750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2219 - acc: 0.5031 - val_loss: 1.4725 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0309 - acc: 0.6250 - val_loss: 1.4868 - val_acc: 0.4375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8202 - acc: 0.7438 - val_loss: 1.5275 - val_acc: 0.4250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6105 - acc: 0.8187 - val_loss: 1.3905 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4687 - acc: 0.8844 - val_loss: 1.3921 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9605 - acc: 0.2344 - val_loss: 1.6801 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4665 - acc: 0.4375 - val_loss: 1.2742 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0527 - acc: 0.5812 - val_loss: 1.2565 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9171 - acc: 0.6406 - val_loss: 1.2776 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5363 - acc: 0.8094 - val_loss: 1.0895 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2810 - acc: 0.9250 - val_loss: 0.9774 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1247 - acc: 0.9781 - val_loss: 1.0613 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0839 - acc: 0.9906 - val_loss: 1.0710 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0384 - acc: 1.0000 - val_loss: 1.1839 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 1.2766 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6855 - acc: 0.2625 - val_loss: 1.5407 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3721 - acc: 0.4594 - val_loss: 1.4047 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9289 - acc: 0.6313 - val_loss: 1.1542 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7466 - acc: 0.7438 - val_loss: 1.3646 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4166 - acc: 0.8719 - val_loss: 1.2793 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2618 - acc: 0.9062 - val_loss: 1.3636 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1696 - acc: 0.9437 - val_loss: 1.3341 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0646 - acc: 0.9906 - val_loss: 1.6252 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 1.4432 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.5342 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6433 - acc: 0.2969 - val_loss: 1.9878 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3904 - acc: 0.4406 - val_loss: 1.8129 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2081 - acc: 0.5500 - val_loss: 1.3622 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8560 - acc: 0.6500 - val_loss: 1.2222 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6747 - acc: 0.7750 - val_loss: 1.3995 - val_acc: 0.4500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4258 - acc: 0.8312 - val_loss: 1.1830 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2378 - acc: 0.9313 - val_loss: 1.1850 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1116 - acc: 0.9937 - val_loss: 1.2054 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0714 - acc: 0.9906 - val_loss: 1.3569 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0359 - acc: 1.0000 - val_loss: 1.5362 - val_acc: 0.4625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6536 - acc: 0.2406 - val_loss: 1.5209 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3951 - acc: 0.3844 - val_loss: 1.5828 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1067 - acc: 0.5406 - val_loss: 1.3973 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7711 - acc: 0.6844 - val_loss: 1.5666 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6116 - acc: 0.7531 - val_loss: 1.3005 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3612 - acc: 0.8688 - val_loss: 1.2756 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2639 - acc: 0.9187 - val_loss: 1.3343 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1085 - acc: 0.9844 - val_loss: 1.9809 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0546 - acc: 1.0000 - val_loss: 1.8531 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0348 - acc: 1.0000 - val_loss: 1.5650 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7024 - acc: 0.2469 - val_loss: 1.2480 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3255 - acc: 0.4500 - val_loss: 1.4895 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2958 - acc: 0.5563 - val_loss: 1.1368 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7260 - acc: 0.7531 - val_loss: 1.1557 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4614 - acc: 0.8625 - val_loss: 1.1103 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3256 - acc: 0.9062 - val_loss: 1.0005 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9750 - val_loss: 1.2353 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0901 - acc: 0.9969 - val_loss: 1.0562 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0488 - acc: 0.9969 - val_loss: 1.0353 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.0981 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6608 - acc: 0.2344 - val_loss: 1.7608 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3600 - acc: 0.4344 - val_loss: 1.7435 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1695 - acc: 0.5031 - val_loss: 1.4610 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7269 - acc: 0.7094 - val_loss: 1.1729 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4273 - acc: 0.8469 - val_loss: 1.1391 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2711 - acc: 0.9312 - val_loss: 1.2854 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1383 - acc: 0.9719 - val_loss: 1.1936 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1045 - acc: 0.9844 - val_loss: 1.3230 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0575 - acc: 0.9969 - val_loss: 1.2683 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0397 - acc: 0.9969 - val_loss: 1.3944 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5619 - acc: 0.2969 - val_loss: 1.5333 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3559 - acc: 0.4531 - val_loss: 1.2346 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9742 - acc: 0.6344 - val_loss: 1.4886 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6407 - acc: 0.7625 - val_loss: 1.2694 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3535 - acc: 0.8937 - val_loss: 1.3705 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1989 - acc: 0.9656 - val_loss: 1.3116 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0998 - acc: 0.9906 - val_loss: 1.4939 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0730 - acc: 0.9969 - val_loss: 1.5874 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 1.6034 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 1.6114 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6383 - acc: 0.2406 - val_loss: 1.5433 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3741 - acc: 0.4563 - val_loss: 1.3105 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0466 - acc: 0.5625 - val_loss: 1.3416 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8078 - acc: 0.6781 - val_loss: 1.1141 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5635 - acc: 0.7906 - val_loss: 1.1822 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4360 - acc: 0.8594 - val_loss: 1.1398 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3453 - acc: 0.8906 - val_loss: 1.3726 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2966 - acc: 0.9000 - val_loss: 1.1229 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1261 - acc: 0.9875 - val_loss: 1.4038 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0818 - acc: 0.9969 - val_loss: 1.3239 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_77 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_151 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling (None, 1, 21, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_152 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling (None, 1, 3, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_38 (Flatten)         (None, 63)                0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 128)               8192      \n",
            "_________________________________________________________________\n",
            "activation_153 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_154 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,063,013\n",
            "Trainable params: 2,063,013\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 4s 13ms/step - loss: 4.4255 - acc: 0.2125 - val_loss: 2.9770 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9945 - acc: 0.3125 - val_loss: 1.4823 - val_acc: 0.3250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4181 - acc: 0.4344 - val_loss: 1.3877 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1906 - acc: 0.4969 - val_loss: 1.2300 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9758 - acc: 0.6031 - val_loss: 1.4112 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8896 - acc: 0.6563 - val_loss: 1.1091 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6149 - acc: 0.7375 - val_loss: 1.1984 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4339 - acc: 0.8438 - val_loss: 1.2044 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3322 - acc: 0.8656 - val_loss: 1.5008 - val_acc: 0.4625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2818 - acc: 0.8781 - val_loss: 1.4023 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1466 - acc: 0.2531 - val_loss: 1.5112 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5944 - acc: 0.4094 - val_loss: 1.4219 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0723 - acc: 0.5719 - val_loss: 1.1403 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6208 - acc: 0.7406 - val_loss: 1.2147 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3653 - acc: 0.8687 - val_loss: 1.3394 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2591 - acc: 0.9188 - val_loss: 1.1613 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1218 - acc: 0.9750 - val_loss: 1.4349 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0540 - acc: 0.9937 - val_loss: 1.4683 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0280 - acc: 0.9937 - val_loss: 1.4868 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.5526 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6040 - acc: 0.2875 - val_loss: 1.3108 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4719 - acc: 0.4687 - val_loss: 1.2091 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9441 - acc: 0.6094 - val_loss: 1.1449 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7207 - acc: 0.7406 - val_loss: 1.1872 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4100 - acc: 0.8500 - val_loss: 1.0799 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1546 - acc: 0.9687 - val_loss: 1.1443 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0617 - acc: 0.9937 - val_loss: 1.2074 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0633 - acc: 0.9844 - val_loss: 1.1174 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0373 - acc: 0.9969 - val_loss: 1.3973 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0307 - acc: 0.9969 - val_loss: 1.2640 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5524 - acc: 0.2625 - val_loss: 1.3560 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0997 - acc: 0.5719 - val_loss: 1.4627 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8945 - acc: 0.6375 - val_loss: 1.2988 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5710 - acc: 0.7938 - val_loss: 1.4362 - val_acc: 0.4125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3754 - acc: 0.8656 - val_loss: 1.3654 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1646 - acc: 0.9406 - val_loss: 1.6694 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0607 - acc: 0.9906 - val_loss: 1.8973 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0260 - acc: 1.0000 - val_loss: 1.7429 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.9379 - val_acc: 0.4875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.9688 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5840 - acc: 0.2625 - val_loss: 1.4065 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3388 - acc: 0.4469 - val_loss: 1.0920 - val_acc: 0.5750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0857 - acc: 0.5625 - val_loss: 1.3370 - val_acc: 0.3500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8171 - acc: 0.6750 - val_loss: 1.3169 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5708 - acc: 0.7656 - val_loss: 1.2139 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3334 - acc: 0.8812 - val_loss: 1.1703 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1105 - acc: 0.9906 - val_loss: 1.1962 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 1.3107 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0188 - acc: 1.0000 - val_loss: 1.3531 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.3754 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6347 - acc: 0.2844 - val_loss: 1.4258 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2382 - acc: 0.5062 - val_loss: 1.7398 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1378 - acc: 0.5500 - val_loss: 1.2718 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6876 - acc: 0.7406 - val_loss: 1.4152 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3974 - acc: 0.8906 - val_loss: 1.3316 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2214 - acc: 0.9344 - val_loss: 1.4082 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1162 - acc: 0.9750 - val_loss: 1.3548 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0581 - acc: 0.9906 - val_loss: 1.4708 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0358 - acc: 0.9969 - val_loss: 1.4348 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 1.6418 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5919 - acc: 0.2844 - val_loss: 1.4751 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3326 - acc: 0.4781 - val_loss: 1.1921 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9789 - acc: 0.6062 - val_loss: 1.3034 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6165 - acc: 0.7594 - val_loss: 1.3477 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4062 - acc: 0.8469 - val_loss: 1.0950 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1622 - acc: 0.9719 - val_loss: 1.2589 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0815 - acc: 0.9813 - val_loss: 1.2082 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0743 - acc: 0.9875 - val_loss: 1.6734 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0346 - acc: 0.9906 - val_loss: 1.6984 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 1.4438 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6319 - acc: 0.3156 - val_loss: 1.5651 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2221 - acc: 0.4719 - val_loss: 1.1745 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8804 - acc: 0.6313 - val_loss: 1.2989 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5841 - acc: 0.7594 - val_loss: 1.2074 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3270 - acc: 0.9125 - val_loss: 1.0637 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1605 - acc: 0.9656 - val_loss: 1.1423 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0875 - acc: 0.9812 - val_loss: 1.2313 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0369 - acc: 1.0000 - val_loss: 1.4187 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 1.4451 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.5053 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6246 - acc: 0.2625 - val_loss: 1.4809 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2753 - acc: 0.4937 - val_loss: 1.2472 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9662 - acc: 0.5813 - val_loss: 1.2066 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6477 - acc: 0.7688 - val_loss: 1.2582 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4400 - acc: 0.8375 - val_loss: 1.1440 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2023 - acc: 0.9469 - val_loss: 1.2244 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1386 - acc: 0.9656 - val_loss: 1.2261 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0658 - acc: 0.9875 - val_loss: 0.9475 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0318 - acc: 1.0000 - val_loss: 1.0466 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 1.2362 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_79 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_155 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling (None, 1, 21, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 1, 11, 128)        62848     \n",
            "_________________________________________________________________\n",
            "activation_156 (Activation)  (None, 1, 11, 128)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_80 (MaxPooling (None, 1, 3, 42)          0         \n",
            "_________________________________________________________________\n",
            "flatten_39 (Flatten)         (None, 126)               0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 128)               16256     \n",
            "_________________________________________________________________\n",
            "activation_157 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_158 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,102,501\n",
            "Trainable params: 2,102,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 4s 14ms/step - loss: 5.2042 - acc: 0.2281 - val_loss: 4.5687 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1643 - acc: 0.3656 - val_loss: 1.2520 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2359 - acc: 0.5344 - val_loss: 1.1154 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9879 - acc: 0.5719 - val_loss: 1.0625 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8869 - acc: 0.6281 - val_loss: 1.0544 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6530 - acc: 0.7313 - val_loss: 0.8874 - val_acc: 0.7125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4632 - acc: 0.8437 - val_loss: 0.9276 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4741 - acc: 0.8281 - val_loss: 0.8575 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2839 - acc: 0.9000 - val_loss: 0.8816 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1534 - acc: 0.9781 - val_loss: 0.8819 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0593 - acc: 0.2219 - val_loss: 4.4605 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8220 - acc: 0.3813 - val_loss: 1.7076 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2000 - acc: 0.5094 - val_loss: 1.1404 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0030 - acc: 0.6281 - val_loss: 1.3763 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6855 - acc: 0.7125 - val_loss: 1.1713 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3845 - acc: 0.8500 - val_loss: 1.3571 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2172 - acc: 0.9187 - val_loss: 1.3516 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1491 - acc: 0.9531 - val_loss: 1.7544 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1527 - acc: 0.9375 - val_loss: 1.6691 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0651 - acc: 0.9875 - val_loss: 1.6314 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6120 - acc: 0.3594 - val_loss: 1.8767 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5373 - acc: 0.4375 - val_loss: 2.0075 - val_acc: 0.2625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5487 - acc: 0.4500 - val_loss: 2.3379 - val_acc: 0.3625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2980 - acc: 0.5469 - val_loss: 1.4099 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8194 - acc: 0.6656 - val_loss: 1.0920 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6739 - acc: 0.7344 - val_loss: 1.1163 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3791 - acc: 0.8719 - val_loss: 0.9567 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2032 - acc: 0.9469 - val_loss: 0.9873 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1235 - acc: 0.9719 - val_loss: 0.9879 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0592 - acc: 0.9844 - val_loss: 1.0710 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6123 - acc: 0.3063 - val_loss: 1.4419 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5253 - acc: 0.4344 - val_loss: 2.0267 - val_acc: 0.3250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2553 - acc: 0.4781 - val_loss: 1.4343 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1027 - acc: 0.5781 - val_loss: 1.1087 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7364 - acc: 0.6781 - val_loss: 1.1171 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4458 - acc: 0.8406 - val_loss: 1.4135 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2327 - acc: 0.9375 - val_loss: 1.8369 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1113 - acc: 0.9625 - val_loss: 1.7126 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 1.6099 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 1.9648 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5374 - acc: 0.2719 - val_loss: 1.5743 - val_acc: 0.4750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3058 - acc: 0.4594 - val_loss: 1.0963 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9481 - acc: 0.6312 - val_loss: 1.1589 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6921 - acc: 0.7344 - val_loss: 1.3353 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4290 - acc: 0.8469 - val_loss: 1.3142 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2465 - acc: 0.9031 - val_loss: 1.5352 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1087 - acc: 0.9625 - val_loss: 1.4736 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0390 - acc: 0.9969 - val_loss: 1.7427 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.7773 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.8402 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5218 - acc: 0.2969 - val_loss: 1.2404 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3740 - acc: 0.4313 - val_loss: 1.1983 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1244 - acc: 0.6000 - val_loss: 1.0504 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7572 - acc: 0.7219 - val_loss: 1.3012 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4330 - acc: 0.8469 - val_loss: 1.1002 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2178 - acc: 0.9406 - val_loss: 1.1673 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0893 - acc: 0.9844 - val_loss: 1.3492 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0356 - acc: 1.0000 - val_loss: 1.6496 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0276 - acc: 0.9937 - val_loss: 1.6542 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.5710 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6376 - acc: 0.2719 - val_loss: 1.5691 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4279 - acc: 0.4625 - val_loss: 1.4117 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0132 - acc: 0.5812 - val_loss: 1.6135 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7708 - acc: 0.6969 - val_loss: 1.1642 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4489 - acc: 0.8375 - val_loss: 1.2238 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3872 - acc: 0.8625 - val_loss: 1.1591 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2218 - acc: 0.9312 - val_loss: 1.3580 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1002 - acc: 0.9656 - val_loss: 1.4889 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0352 - acc: 0.9937 - val_loss: 1.3548 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0205 - acc: 0.9969 - val_loss: 1.6111 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4576 - acc: 0.3594 - val_loss: 1.4087 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3445 - acc: 0.4500 - val_loss: 1.3240 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9567 - acc: 0.6344 - val_loss: 1.2544 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7875 - acc: 0.6969 - val_loss: 1.4689 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5446 - acc: 0.7844 - val_loss: 1.2004 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2738 - acc: 0.9187 - val_loss: 1.2348 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1360 - acc: 0.9750 - val_loss: 1.3798 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0599 - acc: 0.9937 - val_loss: 1.5425 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.6183 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0153 - acc: 0.9969 - val_loss: 1.7294 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5241 - acc: 0.3187 - val_loss: 1.1673 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1371 - acc: 0.5531 - val_loss: 1.8087 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0595 - acc: 0.6063 - val_loss: 1.3229 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6521 - acc: 0.7531 - val_loss: 0.9868 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3376 - acc: 0.8813 - val_loss: 1.0046 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1540 - acc: 0.9656 - val_loss: 1.1278 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0527 - acc: 0.9937 - val_loss: 0.9273 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.0522 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.1736 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_81 (Conv2D)           (None, 1, 64, 64)         4045504   \n",
            "_________________________________________________________________\n",
            "activation_159 (Activation)  (None, 1, 64, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_81 (MaxPooling (None, 1, 21, 21)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 1, 11, 32)         32960     \n",
            "_________________________________________________________________\n",
            "activation_160 (Activation)  (None, 1, 11, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_82 (MaxPooling (None, 1, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_40 (Flatten)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "activation_161 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_162 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 4,083,077\n",
            "Trainable params: 4,083,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 15ms/step - loss: 7.0998 - acc: 0.2031 - val_loss: 8.0783 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 6.6572 - acc: 0.3781 - val_loss: 6.2168 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.6106 - acc: 0.3750 - val_loss: 1.4903 - val_acc: 0.2750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5838 - acc: 0.2219 - val_loss: 1.6040 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6058 - acc: 0.1875 - val_loss: 1.6150 - val_acc: 0.1750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6017 - acc: 0.2062 - val_loss: 1.6178 - val_acc: 0.1750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5994 - acc: 0.2031 - val_loss: 1.6205 - val_acc: 0.1500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5989 - acc: 0.2188 - val_loss: 1.6190 - val_acc: 0.1500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5986 - acc: 0.2188 - val_loss: 1.6203 - val_acc: 0.1500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5986 - acc: 0.2187 - val_loss: 1.6207 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.5917 - acc: 0.2063 - val_loss: 6.9761 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.0577 - acc: 0.3969 - val_loss: 1.5549 - val_acc: 0.3250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6873 - acc: 0.3938 - val_loss: 1.3954 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0768 - acc: 0.5781 - val_loss: 1.1556 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7414 - acc: 0.7063 - val_loss: 1.1531 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4579 - acc: 0.8250 - val_loss: 1.1995 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2794 - acc: 0.9344 - val_loss: 1.2343 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1704 - acc: 0.9625 - val_loss: 1.2511 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0954 - acc: 0.9906 - val_loss: 1.2188 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0488 - acc: 0.9937 - val_loss: 1.3641 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5228 - acc: 0.3625 - val_loss: 2.4253 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4426 - acc: 0.5062 - val_loss: 1.3034 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7521 - acc: 0.7125 - val_loss: 1.3940 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4148 - acc: 0.8594 - val_loss: 1.5176 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2241 - acc: 0.9406 - val_loss: 1.4638 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1042 - acc: 0.9687 - val_loss: 1.4660 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0657 - acc: 0.9906 - val_loss: 1.5784 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 1.5914 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.5616 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.6111 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7058 - acc: 0.3219 - val_loss: 1.5447 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7485 - acc: 0.4531 - val_loss: 3.0891 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5590 - acc: 0.5031 - val_loss: 1.4628 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8762 - acc: 0.6563 - val_loss: 1.2773 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9410 - acc: 0.6844 - val_loss: 1.6378 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4371 - acc: 0.8594 - val_loss: 1.1153 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1943 - acc: 0.9656 - val_loss: 1.0719 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1026 - acc: 0.9812 - val_loss: 1.1494 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0553 - acc: 0.9969 - val_loss: 1.2568 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0287 - acc: 1.0000 - val_loss: 1.1920 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5432 - acc: 0.3031 - val_loss: 1.7668 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3048 - acc: 0.5469 - val_loss: 1.4390 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8226 - acc: 0.6906 - val_loss: 1.2354 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4598 - acc: 0.8500 - val_loss: 1.3885 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3367 - acc: 0.8937 - val_loss: 1.5775 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1629 - acc: 0.9594 - val_loss: 1.8932 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0642 - acc: 0.9937 - val_loss: 2.0892 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0352 - acc: 0.9969 - val_loss: 1.5738 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.7721 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.7718 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5918 - acc: 0.3656 - val_loss: 1.6554 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5783 - acc: 0.4719 - val_loss: 1.2387 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1901 - acc: 0.5656 - val_loss: 1.8219 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8287 - acc: 0.6688 - val_loss: 1.4663 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4844 - acc: 0.8281 - val_loss: 1.2353 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2375 - acc: 0.9281 - val_loss: 1.3071 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0857 - acc: 0.9875 - val_loss: 1.1456 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0366 - acc: 1.0000 - val_loss: 1.2672 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.2043 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.2136 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6907 - acc: 0.2656 - val_loss: 1.3057 - val_acc: 0.5250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3500 - acc: 0.5219 - val_loss: 1.9820 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1545 - acc: 0.6281 - val_loss: 1.7161 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8274 - acc: 0.6813 - val_loss: 1.1456 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4641 - acc: 0.8531 - val_loss: 1.2156 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2393 - acc: 0.9156 - val_loss: 1.3248 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1958 - acc: 0.9344 - val_loss: 1.0544 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0882 - acc: 0.9906 - val_loss: 0.9896 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0510 - acc: 0.9969 - val_loss: 1.2824 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 1.0654 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5095 - acc: 0.3000 - val_loss: 1.3861 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2503 - acc: 0.5625 - val_loss: 1.5641 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0786 - acc: 0.6125 - val_loss: 1.5075 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7150 - acc: 0.7500 - val_loss: 1.3499 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2887 - acc: 0.9375 - val_loss: 1.0154 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1403 - acc: 0.9781 - val_loss: 0.9569 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0751 - acc: 0.9906 - val_loss: 1.0114 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0397 - acc: 1.0000 - val_loss: 1.0440 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0331 - acc: 1.0000 - val_loss: 1.0031 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.0856 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5427 - acc: 0.3063 - val_loss: 1.3805 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3761 - acc: 0.5156 - val_loss: 2.1818 - val_acc: 0.2875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1327 - acc: 0.5688 - val_loss: 1.1460 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6528 - acc: 0.7656 - val_loss: 1.2437 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4856 - acc: 0.8281 - val_loss: 1.5842 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3559 - acc: 0.8875 - val_loss: 1.3247 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1906 - acc: 0.9562 - val_loss: 1.3134 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0998 - acc: 0.9875 - val_loss: 1.2913 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0490 - acc: 0.9937 - val_loss: 1.3400 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.2836 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_83 (Conv2D)           (None, 1, 64, 64)         4045504   \n",
            "_________________________________________________________________\n",
            "activation_163 (Activation)  (None, 1, 64, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_83 (MaxPooling (None, 1, 21, 21)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 1, 11, 64)         65920     \n",
            "_________________________________________________________________\n",
            "activation_164 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_84 (MaxPooling (None, 1, 3, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_41 (Flatten)         (None, 63)                0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 128)               8192      \n",
            "_________________________________________________________________\n",
            "activation_165 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_166 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 4,120,261\n",
            "Trainable params: 4,120,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 14ms/step - loss: 11.3217 - acc: 0.2187 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.1091 - acc: 0.2281 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.7391 - acc: 0.1812 - val_loss: 4.2812 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.0549 - acc: 0.2906 - val_loss: 2.4638 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5915 - acc: 0.4875 - val_loss: 1.0610 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1412 - acc: 0.4906 - val_loss: 0.8257 - val_acc: 0.7250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7691 - acc: 0.7094 - val_loss: 1.0485 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4762 - acc: 0.8375 - val_loss: 1.0286 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2599 - acc: 0.9250 - val_loss: 1.0532 - val_acc: 0.7000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1262 - acc: 0.9875 - val_loss: 1.2457 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0631 - acc: 0.9937 - val_loss: 1.4089 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0327 - acc: 0.9969 - val_loss: 1.3680 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.7541 - acc: 0.2344 - val_loss: 6.4758 - val_acc: 0.1375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.8699 - acc: 0.3281 - val_loss: 3.1467 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8073 - acc: 0.3719 - val_loss: 1.6272 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2950 - acc: 0.5188 - val_loss: 1.0334 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9310 - acc: 0.6469 - val_loss: 1.3792 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6473 - acc: 0.7656 - val_loss: 1.0650 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3846 - acc: 0.8844 - val_loss: 1.0767 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1876 - acc: 0.9469 - val_loss: 0.9317 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0867 - acc: 0.9875 - val_loss: 0.9586 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0475 - acc: 0.9937 - val_loss: 1.0907 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0577 - acc: 0.2469 - val_loss: 1.2601 - val_acc: 0.5875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.1084 - acc: 0.3063 - val_loss: 1.4218 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4717 - acc: 0.4500 - val_loss: 1.3463 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0733 - acc: 0.5906 - val_loss: 1.5049 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8473 - acc: 0.6687 - val_loss: 0.9696 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4671 - acc: 0.8219 - val_loss: 1.0240 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3409 - acc: 0.8969 - val_loss: 1.2141 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2039 - acc: 0.9469 - val_loss: 1.1064 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0848 - acc: 0.9875 - val_loss: 1.0413 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0538 - acc: 0.9906 - val_loss: 1.0574 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.4294 - acc: 0.1906 - val_loss: 3.7220 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2112 - acc: 0.3906 - val_loss: 1.9684 - val_acc: 0.3750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5026 - acc: 0.4937 - val_loss: 1.1950 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8768 - acc: 0.6500 - val_loss: 1.0542 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5258 - acc: 0.8094 - val_loss: 1.3539 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3531 - acc: 0.8750 - val_loss: 1.1576 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1737 - acc: 0.9687 - val_loss: 1.1762 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0700 - acc: 0.9969 - val_loss: 1.1101 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0476 - acc: 1.0000 - val_loss: 1.2727 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 1.4613 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5636 - acc: 0.3031 - val_loss: 3.0179 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9540 - acc: 0.3969 - val_loss: 1.3754 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3570 - acc: 0.5469 - val_loss: 1.7399 - val_acc: 0.4125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9635 - acc: 0.6688 - val_loss: 1.0714 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5627 - acc: 0.7812 - val_loss: 1.5076 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4770 - acc: 0.8219 - val_loss: 0.9652 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2801 - acc: 0.9000 - val_loss: 1.0846 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1287 - acc: 0.9719 - val_loss: 1.1999 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0617 - acc: 0.9937 - val_loss: 1.1901 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 1.0565 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6275 - acc: 0.3031 - val_loss: 1.6107 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4580 - acc: 0.4750 - val_loss: 1.4759 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8509 - acc: 0.6906 - val_loss: 1.2621 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5210 - acc: 0.8094 - val_loss: 1.1004 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2273 - acc: 0.9344 - val_loss: 1.1222 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0997 - acc: 0.9875 - val_loss: 1.0851 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0375 - acc: 1.0000 - val_loss: 1.2832 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 1.2131 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.3540 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5590 - acc: 0.2937 - val_loss: 1.1868 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5199 - acc: 0.4625 - val_loss: 1.2468 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0614 - acc: 0.6625 - val_loss: 1.3176 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7989 - acc: 0.6969 - val_loss: 1.1239 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4508 - acc: 0.8312 - val_loss: 1.2205 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2751 - acc: 0.9094 - val_loss: 1.6665 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1637 - acc: 0.9500 - val_loss: 1.2659 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0773 - acc: 0.9750 - val_loss: 1.5164 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0395 - acc: 0.9969 - val_loss: 1.3848 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 1.2864 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_85 (Conv2D)           (None, 1, 64, 64)         4045504   \n",
            "_________________________________________________________________\n",
            "activation_167 (Activation)  (None, 1, 64, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_85 (MaxPooling (None, 1, 21, 21)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 1, 11, 128)        131840    \n",
            "_________________________________________________________________\n",
            "activation_168 (Activation)  (None, 1, 11, 128)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_86 (MaxPooling (None, 1, 3, 42)          0         \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 126)               0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 128)               16256     \n",
            "_________________________________________________________________\n",
            "activation_169 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_170 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 4,194,245\n",
            "Trainable params: 4,194,245\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 14ms/step - loss: 11.7128 - acc: 0.1938 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6692 - acc: 0.1969 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.0028 - acc: 0.2094 - val_loss: 3.6617 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.4057 - acc: 0.3000 - val_loss: 5.1259 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.0797 - acc: 0.4406 - val_loss: 3.9160 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5454 - acc: 0.4937 - val_loss: 1.3433 - val_acc: 0.4250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0822 - acc: 0.5563 - val_loss: 1.2380 - val_acc: 0.4625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7776 - acc: 0.6969 - val_loss: 1.3067 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5717 - acc: 0.7875 - val_loss: 0.9886 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3141 - acc: 0.8844 - val_loss: 1.7001 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1468 - acc: 0.9562 - val_loss: 1.2098 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0794 - acc: 0.9719 - val_loss: 1.9673 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.4783 - acc: 0.2406 - val_loss: 1.5285 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.6912 - acc: 0.3594 - val_loss: 5.5256 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.3829 - acc: 0.3469 - val_loss: 2.3434 - val_acc: 0.3250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3933 - acc: 0.4969 - val_loss: 1.2919 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8637 - acc: 0.6594 - val_loss: 1.0498 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6308 - acc: 0.7500 - val_loss: 1.1062 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4304 - acc: 0.8469 - val_loss: 0.9296 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3729 - acc: 0.8938 - val_loss: 1.0734 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2619 - acc: 0.9000 - val_loss: 1.0279 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0976 - acc: 0.9937 - val_loss: 1.0836 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8882 - acc: 0.2469 - val_loss: 1.2989 - val_acc: 0.4750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7512 - acc: 0.4656 - val_loss: 1.5038 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1791 - acc: 0.5094 - val_loss: 1.2753 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6245 - acc: 0.7750 - val_loss: 1.1311 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3833 - acc: 0.8719 - val_loss: 1.1548 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1304 - acc: 0.9719 - val_loss: 1.1226 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0675 - acc: 0.9812 - val_loss: 1.4165 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0425 - acc: 0.9937 - val_loss: 1.2484 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.4178 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.3580 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8150 - acc: 0.2656 - val_loss: 2.0045 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8703 - acc: 0.3594 - val_loss: 1.1063 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5770 - acc: 0.4969 - val_loss: 1.2199 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0704 - acc: 0.6344 - val_loss: 1.3737 - val_acc: 0.4000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7230 - acc: 0.7344 - val_loss: 1.3213 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5217 - acc: 0.8063 - val_loss: 1.4107 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2539 - acc: 0.9281 - val_loss: 1.0019 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1692 - acc: 0.9406 - val_loss: 2.2401 - val_acc: 0.4250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1317 - acc: 0.9594 - val_loss: 1.2964 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0328 - acc: 0.9937 - val_loss: 1.1719 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5026 - acc: 0.3219 - val_loss: 2.8322 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3478 - acc: 0.3812 - val_loss: 1.9396 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7905 - acc: 0.4219 - val_loss: 1.4707 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1541 - acc: 0.5875 - val_loss: 1.5958 - val_acc: 0.3625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7627 - acc: 0.6844 - val_loss: 1.0985 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4790 - acc: 0.8406 - val_loss: 1.0133 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2373 - acc: 0.9312 - val_loss: 1.1719 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1021 - acc: 0.9906 - val_loss: 1.1370 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0508 - acc: 0.9937 - val_loss: 1.2134 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0314 - acc: 0.9969 - val_loss: 1.2967 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6819 - acc: 0.3250 - val_loss: 1.9379 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9200 - acc: 0.4281 - val_loss: 2.2577 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5097 - acc: 0.4719 - val_loss: 2.2425 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4446 - acc: 0.5594 - val_loss: 1.3424 - val_acc: 0.3750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8644 - acc: 0.6594 - val_loss: 1.0870 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4907 - acc: 0.8219 - val_loss: 1.2625 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3240 - acc: 0.8781 - val_loss: 1.4211 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2069 - acc: 0.9094 - val_loss: 1.3256 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1186 - acc: 0.9750 - val_loss: 1.2602 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0463 - acc: 0.9969 - val_loss: 1.3022 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6069 - acc: 0.2969 - val_loss: 1.6521 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0737 - acc: 0.5719 - val_loss: 2.2147 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0328 - acc: 0.6031 - val_loss: 1.5379 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7138 - acc: 0.7438 - val_loss: 1.2272 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2740 - acc: 0.9250 - val_loss: 1.3175 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1706 - acc: 0.9375 - val_loss: 1.4709 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0641 - acc: 0.9844 - val_loss: 1.6106 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0263 - acc: 0.9969 - val_loss: 1.4010 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.5666 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.6891 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_87 (Conv2D)           (None, 1, 64, 128)        8091008   \n",
            "_________________________________________________________________\n",
            "activation_171 (Activation)  (None, 1, 64, 128)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_87 (MaxPooling (None, 1, 21, 42)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 1, 11, 32)         65888     \n",
            "_________________________________________________________________\n",
            "activation_172 (Activation)  (None, 1, 11, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_88 (MaxPooling (None, 1, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_43 (Flatten)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "activation_173 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_174 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 8,161,509\n",
            "Trainable params: 8,161,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 15ms/step - loss: 10.8820 - acc: 0.2000 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.2487 - acc: 0.1750 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.5919 - acc: 0.2594 - val_loss: 8.1590 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.9171 - acc: 0.3563 - val_loss: 11.8520 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0687 - acc: 0.2594 - val_loss: 11.0808 - val_acc: 0.3000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0783 - acc: 0.3531 - val_loss: 11.0218 - val_acc: 0.2875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.7584 - acc: 0.3844 - val_loss: 10.7279 - val_acc: 0.3125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6080 - acc: 0.3969 - val_loss: 10.6892 - val_acc: 0.3375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.5349 - acc: 0.4000 - val_loss: 10.9489 - val_acc: 0.3000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.5793 - acc: 0.3938 - val_loss: 10.6791 - val_acc: 0.3375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.4712 - acc: 0.4125 - val_loss: 10.9946 - val_acc: 0.2875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.4694 - acc: 0.4125 - val_loss: 11.0407 - val_acc: 0.2875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.4334 - acc: 0.2469 - val_loss: 2.9526 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.6399 - acc: 0.3500 - val_loss: 2.3438 - val_acc: 0.2625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5122 - acc: 0.4531 - val_loss: 1.4020 - val_acc: 0.3750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0866 - acc: 0.5625 - val_loss: 1.3426 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6970 - acc: 0.7188 - val_loss: 1.3619 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4734 - acc: 0.8281 - val_loss: 1.1622 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2271 - acc: 0.9500 - val_loss: 1.2701 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1145 - acc: 0.9812 - val_loss: 1.3232 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0637 - acc: 0.9969 - val_loss: 1.5177 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0306 - acc: 0.9969 - val_loss: 1.6041 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.4072 - acc: 0.2219 - val_loss: 3.9390 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.8806 - acc: 0.3094 - val_loss: 2.4570 - val_acc: 0.2250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3761 - acc: 0.5187 - val_loss: 1.2955 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9310 - acc: 0.6313 - val_loss: 1.7870 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0346 - acc: 0.6687 - val_loss: 1.2171 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6464 - acc: 0.7437 - val_loss: 1.1515 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3240 - acc: 0.9031 - val_loss: 0.9141 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1549 - acc: 0.9594 - val_loss: 0.9473 - val_acc: 0.7125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0814 - acc: 0.9812 - val_loss: 0.9968 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.9623 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0951 - acc: 0.2656 - val_loss: 1.6160 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.6497 - acc: 0.3500 - val_loss: 1.7803 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6394 - acc: 0.4656 - val_loss: 1.5678 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0267 - acc: 0.5938 - val_loss: 1.2769 - val_acc: 0.4250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8847 - acc: 0.6688 - val_loss: 0.9251 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5447 - acc: 0.8281 - val_loss: 1.2481 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3894 - acc: 0.8750 - val_loss: 0.8981 - val_acc: 0.6875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2125 - acc: 0.9437 - val_loss: 0.9930 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1118 - acc: 0.9937 - val_loss: 1.0317 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0676 - acc: 1.0000 - val_loss: 1.0303 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7108 - acc: 0.3500 - val_loss: 1.2664 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2683 - acc: 0.5625 - val_loss: 1.1790 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8020 - acc: 0.7094 - val_loss: 1.2891 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4396 - acc: 0.8438 - val_loss: 1.0587 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2082 - acc: 0.9562 - val_loss: 1.1235 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0917 - acc: 0.9906 - val_loss: 0.9128 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1088 - acc: 0.9687 - val_loss: 1.1245 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6675 - acc: 0.8094 - val_loss: 1.3146 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1409 - acc: 0.9594 - val_loss: 1.0468 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0403 - acc: 0.9969 - val_loss: 1.1387 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5743 - acc: 0.2781 - val_loss: 1.3002 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0892 - acc: 0.5500 - val_loss: 1.2796 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6836 - acc: 0.7250 - val_loss: 1.3502 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3838 - acc: 0.8844 - val_loss: 1.2087 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2102 - acc: 0.9500 - val_loss: 1.2357 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1163 - acc: 0.9656 - val_loss: 1.1930 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0431 - acc: 0.9937 - val_loss: 1.0691 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.1197 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.0178 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.0382 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8713 - acc: 0.2844 - val_loss: 1.6596 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9202 - acc: 0.4094 - val_loss: 2.4613 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7563 - acc: 0.4781 - val_loss: 1.4941 - val_acc: 0.3750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9558 - acc: 0.6219 - val_loss: 1.4628 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6874 - acc: 0.7125 - val_loss: 1.0696 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4384 - acc: 0.8594 - val_loss: 1.0618 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2740 - acc: 0.9250 - val_loss: 1.3039 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1561 - acc: 0.9625 - val_loss: 1.1799 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0917 - acc: 0.9875 - val_loss: 1.3463 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0450 - acc: 1.0000 - val_loss: 1.3799 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_89 (Conv2D)           (None, 1, 64, 128)        8091008   \n",
            "_________________________________________________________________\n",
            "activation_175 (Activation)  (None, 1, 64, 128)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_89 (MaxPooling (None, 1, 21, 42)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 1, 11, 64)         131776    \n",
            "_________________________________________________________________\n",
            "activation_176 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_90 (MaxPooling (None, 1, 3, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_44 (Flatten)         (None, 63)                0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 128)               8192      \n",
            "_________________________________________________________________\n",
            "activation_177 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_178 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 8,231,621\n",
            "Trainable params: 8,231,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 15ms/step - loss: 11.4225 - acc: 0.1750 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.3566 - acc: 0.1906 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.8207 - acc: 0.1875 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.4403 - acc: 0.2656 - val_loss: 10.3762 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.9218 - acc: 0.3750 - val_loss: 12.8753 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6939 - acc: 0.3906 - val_loss: 11.2831 - val_acc: 0.3000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.7240 - acc: 0.3938 - val_loss: 11.3326 - val_acc: 0.2875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.9871 - acc: 0.3750 - val_loss: 12.8953 - val_acc: 0.2000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.4184 - acc: 0.3469 - val_loss: 10.2753 - val_acc: 0.3625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6205 - acc: 0.4031 - val_loss: 10.4768 - val_acc: 0.3500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6083 - acc: 0.4031 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.1841 - acc: 0.3656 - val_loss: 13.0899 - val_acc: 0.1750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.2514 - acc: 0.3000 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.1214 - acc: 0.3375 - val_loss: 7.7523 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.4486 - acc: 0.3781 - val_loss: 4.1021 - val_acc: 0.2625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1005 - acc: 0.3844 - val_loss: 1.8242 - val_acc: 0.3750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1397 - acc: 0.5375 - val_loss: 1.5730 - val_acc: 0.4250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7564 - acc: 0.7031 - val_loss: 1.4733 - val_acc: 0.4125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6319 - acc: 0.7375 - val_loss: 1.2382 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4584 - acc: 0.8469 - val_loss: 1.2850 - val_acc: 0.4875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2630 - acc: 0.9312 - val_loss: 1.3494 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1608 - acc: 0.9719 - val_loss: 1.4499 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0702 - acc: 0.9969 - val_loss: 1.4716 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.7362 - acc: 0.2562 - val_loss: 4.3454 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.9944 - acc: 0.3344 - val_loss: 4.6495 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.2975 - acc: 0.5094 - val_loss: 2.0733 - val_acc: 0.3375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3481 - acc: 0.5625 - val_loss: 1.7683 - val_acc: 0.3500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7616 - acc: 0.6937 - val_loss: 1.2880 - val_acc: 0.4625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3893 - acc: 0.8656 - val_loss: 1.3424 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1630 - acc: 0.9625 - val_loss: 1.1012 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0690 - acc: 0.9937 - val_loss: 1.2916 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0424 - acc: 0.9969 - val_loss: 1.2823 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0268 - acc: 1.0000 - val_loss: 1.2727 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0894 - acc: 0.3094 - val_loss: 3.7959 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3956 - acc: 0.3562 - val_loss: 2.2606 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3691 - acc: 0.5469 - val_loss: 1.5575 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8416 - acc: 0.7156 - val_loss: 1.7444 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5468 - acc: 0.8062 - val_loss: 1.2212 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2935 - acc: 0.9187 - val_loss: 1.3171 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1358 - acc: 0.9656 - val_loss: 1.4323 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0603 - acc: 0.9937 - val_loss: 1.4302 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0338 - acc: 1.0000 - val_loss: 1.4130 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 1.5691 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8990 - acc: 0.3094 - val_loss: 2.7640 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9753 - acc: 0.4781 - val_loss: 1.6343 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1552 - acc: 0.5969 - val_loss: 1.1281 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5723 - acc: 0.7656 - val_loss: 1.2164 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3243 - acc: 0.8844 - val_loss: 1.0723 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1492 - acc: 0.9562 - val_loss: 0.9923 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0738 - acc: 0.9844 - val_loss: 1.0771 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0348 - acc: 0.9969 - val_loss: 0.8498 - val_acc: 0.7125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 1.0449 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9510 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.4509 - acc: 0.2625 - val_loss: 4.2341 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.3668 - acc: 0.3844 - val_loss: 1.5401 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4071 - acc: 0.5063 - val_loss: 1.5334 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9062 - acc: 0.6437 - val_loss: 1.4062 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6297 - acc: 0.7531 - val_loss: 1.4032 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3511 - acc: 0.8906 - val_loss: 1.4046 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2016 - acc: 0.9375 - val_loss: 1.2820 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0944 - acc: 0.9844 - val_loss: 1.2315 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0466 - acc: 0.9938 - val_loss: 1.2760 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.3426 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_91 (Conv2D)           (None, 1, 64, 128)        8091008   \n",
            "_________________________________________________________________\n",
            "activation_179 (Activation)  (None, 1, 64, 128)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling (None, 1, 21, 42)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 1, 11, 128)        263552    \n",
            "_________________________________________________________________\n",
            "activation_180 (Activation)  (None, 1, 11, 128)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling (None, 1, 3, 42)          0         \n",
            "_________________________________________________________________\n",
            "flatten_45 (Flatten)         (None, 126)               0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 128)               16256     \n",
            "_________________________________________________________________\n",
            "activation_181 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_182 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 8,371,461\n",
            "Trainable params: 8,371,461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 11.8572 - acc: 0.2062 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.2217 - acc: 0.1844 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.3112 - acc: 0.1594 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.4235 - acc: 0.2094 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.0502 - acc: 0.2281 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.7709 - acc: 0.1813 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.6845 - acc: 0.1937 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.8864 - acc: 0.1937 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.2324 - acc: 0.2094 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXaCHzhqOQQK",
        "colab_type": "code",
        "outputId": "a0ae03b9-f950-4bf8-f201-5387028b3a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "score_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Parameter</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Kernel Size: (3, 3)</td>\n",
              "      <td>0.473333</td>\n",
              "      <td>1.981357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Kernel Size: (5, 5)</td>\n",
              "      <td>0.565556</td>\n",
              "      <td>1.611662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Kernel Size: (7, 7)</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>1.577976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Kernel Size: (1, 5)</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>1.530358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Kernel Size: (5, 1)</td>\n",
              "      <td>0.368889</td>\n",
              "      <td>1.725819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Kernel Size: (1, 7)</td>\n",
              "      <td>0.557778</td>\n",
              "      <td>1.488459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Kernel Size: (7, 1)</td>\n",
              "      <td>0.407778</td>\n",
              "      <td>1.746344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Conv Strides: (1, 1)</td>\n",
              "      <td>0.504444</td>\n",
              "      <td>5.114644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.0</td>\n",
              "      <td>Conv Strides: (2, 2)</td>\n",
              "      <td>0.595556</td>\n",
              "      <td>1.339987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Conv Strides: (3, 3)</td>\n",
              "      <td>0.602222</td>\n",
              "      <td>1.447754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Conv Strides: (1, 2)</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>1.342004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11.0</td>\n",
              "      <td>Conv Strides: (2, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.748762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12.0</td>\n",
              "      <td>Conv Strides: (3, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.823076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13.0</td>\n",
              "      <td>Conv Strides: (1, 3)</td>\n",
              "      <td>0.563333</td>\n",
              "      <td>1.780330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x32</td>\n",
              "      <td>0.608889</td>\n",
              "      <td>1.293163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x64</td>\n",
              "      <td>0.596667</td>\n",
              "      <td>1.311897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x128</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.443874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x32</td>\n",
              "      <td>0.544444</td>\n",
              "      <td>1.366712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x64</td>\n",
              "      <td>0.521111</td>\n",
              "      <td>3.820026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x128</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>3.871442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x32</td>\n",
              "      <td>0.465556</td>\n",
              "      <td>4.841143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x64</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>6.063469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x128</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.894476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0             Parameter  Accuracy       Loss\n",
              "0          0.0   Kernel Size: (3, 3)  0.473333   1.981357\n",
              "1          1.0   Kernel Size: (5, 5)  0.565556   1.611662\n",
              "2          2.0   Kernel Size: (7, 7)  0.588889   1.577976\n",
              "3          3.0   Kernel Size: (1, 5)  0.533333   1.530358\n",
              "4          4.0   Kernel Size: (5, 1)  0.368889   1.725819\n",
              "5          5.0   Kernel Size: (1, 7)  0.557778   1.488459\n",
              "6          6.0   Kernel Size: (7, 1)  0.407778   1.746344\n",
              "7          7.0  Conv Strides: (1, 1)  0.504444   5.114644\n",
              "8          8.0  Conv Strides: (2, 2)  0.595556   1.339987\n",
              "9          9.0  Conv Strides: (3, 3)  0.602222   1.447754\n",
              "10        10.0  Conv Strides: (1, 2)  0.610000   1.342004\n",
              "11        11.0  Conv Strides: (2, 1)  0.528889   3.748762\n",
              "12        12.0  Conv Strides: (3, 1)  0.528889   3.823076\n",
              "13        13.0  Conv Strides: (1, 3)  0.563333   1.780330\n",
              "14         NaN     Batch Size: 32x32  0.608889   1.293163\n",
              "15         NaN     Batch Size: 32x64  0.596667   1.311897\n",
              "16         NaN    Batch Size: 32x128  0.600000   1.443874\n",
              "17         NaN     Batch Size: 64x32  0.544444   1.366712\n",
              "18         NaN     Batch Size: 64x64  0.521111   3.820026\n",
              "19         NaN    Batch Size: 64x128  0.533333   3.871442\n",
              "20         NaN    Batch Size: 128x32  0.465556   4.841143\n",
              "21         NaN    Batch Size: 128x64  0.472222   6.063469\n",
              "22         NaN   Batch Size: 128x128  0.200000  12.894476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4xAgja7sI9",
        "colab_type": "code",
        "outputId": "6c7abb4a-2bf7-452e-d8e2-5662c1c82b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch1 = 32\n",
        "batch2 = 64\n",
        "\n",
        "parameter = 'Pool Size: '\n",
        "pool_sizes = [(1, 1), (2, 2), (3, 3), (1, 2), (2, 1), (1, 3), (3, 1)]\n",
        "\n",
        "for p_size in pool_sizes:\n",
        "  train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "  parameter_name = parameter+str(p_size)\n",
        "  parameter_acc = np.mean(test_accuracy)\n",
        "  parameter_loss = np.mean(test_loss)\n",
        "  score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 1), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 1), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_93 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_183 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling (None, 1, 22, 11)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 1, 11, 64)         34560     \n",
            "_________________________________________________________________\n",
            "activation_184 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling (None, 1, 4, 22)          0         \n",
            "_________________________________________________________________\n",
            "flatten_46 (Flatten)         (None, 88)                0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 128)               11392     \n",
            "_________________________________________________________________\n",
            "activation_185 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_186 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,069,349\n",
            "Trainable params: 2,069,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 15ms/step - loss: 2.2847 - acc: 0.2750 - val_loss: 1.5850 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2636 - acc: 0.5031 - val_loss: 1.3596 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0682 - acc: 0.5625 - val_loss: 1.4695 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9438 - acc: 0.5938 - val_loss: 1.1203 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6918 - acc: 0.7313 - val_loss: 1.0480 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4742 - acc: 0.8187 - val_loss: 1.2770 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3244 - acc: 0.8812 - val_loss: 1.5080 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2710 - acc: 0.8969 - val_loss: 1.5483 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2409 - acc: 0.9156 - val_loss: 1.6420 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1446 - acc: 0.9594 - val_loss: 1.5338 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5201 - acc: 0.3062 - val_loss: 1.2724 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0640 - acc: 0.5750 - val_loss: 1.2023 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7368 - acc: 0.7281 - val_loss: 1.1065 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4793 - acc: 0.8125 - val_loss: 1.2644 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2367 - acc: 0.8969 - val_loss: 1.3213 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1160 - acc: 0.9625 - val_loss: 1.3515 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0505 - acc: 0.9875 - val_loss: 1.5825 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0207 - acc: 0.9969 - val_loss: 1.6269 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 1.6534 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.6638 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5074 - acc: 0.3062 - val_loss: 1.2792 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1314 - acc: 0.5406 - val_loss: 1.2291 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9001 - acc: 0.6656 - val_loss: 1.0776 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5671 - acc: 0.7906 - val_loss: 1.0686 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3142 - acc: 0.8969 - val_loss: 1.3306 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1755 - acc: 0.9500 - val_loss: 1.1332 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0588 - acc: 0.9937 - val_loss: 1.7052 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0343 - acc: 0.9969 - val_loss: 1.5249 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.6602 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.9969 - val_loss: 1.6791 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5286 - acc: 0.3063 - val_loss: 1.3492 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1505 - acc: 0.5250 - val_loss: 1.1415 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8356 - acc: 0.6844 - val_loss: 1.0911 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5498 - acc: 0.7844 - val_loss: 1.4258 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3739 - acc: 0.8781 - val_loss: 1.4484 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1846 - acc: 0.9281 - val_loss: 1.5289 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0694 - acc: 0.9875 - val_loss: 1.7112 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0436 - acc: 0.9937 - val_loss: 1.8676 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 2.0087 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.0654 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5216 - acc: 0.3188 - val_loss: 1.1512 - val_acc: 0.5250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1540 - acc: 0.5250 - val_loss: 1.0654 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9974 - acc: 0.6188 - val_loss: 0.9447 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6734 - acc: 0.7156 - val_loss: 0.9384 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4008 - acc: 0.8656 - val_loss: 1.1614 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3206 - acc: 0.8906 - val_loss: 1.1299 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1155 - acc: 0.9781 - val_loss: 1.2257 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0498 - acc: 0.9937 - val_loss: 1.4386 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0234 - acc: 1.0000 - val_loss: 1.4735 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.5191 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4536 - acc: 0.3156 - val_loss: 1.2024 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1146 - acc: 0.5469 - val_loss: 1.1983 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8814 - acc: 0.6406 - val_loss: 1.0645 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6047 - acc: 0.8125 - val_loss: 1.1043 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3632 - acc: 0.8813 - val_loss: 1.3124 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2645 - acc: 0.9219 - val_loss: 1.3028 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1019 - acc: 0.9719 - val_loss: 1.4305 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0466 - acc: 0.9937 - val_loss: 1.5901 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.4858 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.6047 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5293 - acc: 0.3344 - val_loss: 1.4468 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1814 - acc: 0.5031 - val_loss: 1.1509 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9105 - acc: 0.6219 - val_loss: 1.0500 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7596 - acc: 0.6688 - val_loss: 0.9704 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5536 - acc: 0.8000 - val_loss: 0.9625 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2697 - acc: 0.9375 - val_loss: 0.8105 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1530 - acc: 0.9625 - val_loss: 1.1439 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0728 - acc: 0.9875 - val_loss: 1.0203 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0339 - acc: 0.9969 - val_loss: 1.0238 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 1.2162 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5616 - acc: 0.2625 - val_loss: 1.5085 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0867 - acc: 0.5750 - val_loss: 1.3071 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8820 - acc: 0.6469 - val_loss: 1.3048 - val_acc: 0.4125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6750 - acc: 0.7250 - val_loss: 1.2094 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4516 - acc: 0.8187 - val_loss: 1.4043 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2813 - acc: 0.9031 - val_loss: 1.2348 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1440 - acc: 0.9719 - val_loss: 1.4739 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0933 - acc: 0.9812 - val_loss: 1.5161 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0464 - acc: 0.9937 - val_loss: 1.6087 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0237 - acc: 0.9969 - val_loss: 1.5506 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5441 - acc: 0.3062 - val_loss: 1.3065 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0866 - acc: 0.5469 - val_loss: 1.7826 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9986 - acc: 0.5625 - val_loss: 1.0117 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6406 - acc: 0.7344 - val_loss: 1.1576 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4803 - acc: 0.8156 - val_loss: 1.0299 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2737 - acc: 0.9188 - val_loss: 1.2722 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1442 - acc: 0.9719 - val_loss: 1.4011 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0735 - acc: 0.9875 - val_loss: 1.3108 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.4288 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 1.4736 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_95 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_187 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling (None, 1, 21, 11)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 1, 11, 64)         34560     \n",
            "_________________________________________________________________\n",
            "activation_188 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_96 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_47 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 128)               10880     \n",
            "_________________________________________________________________\n",
            "activation_189 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_190 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,068,837\n",
            "Trainable params: 2,068,837\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 4.4103 - acc: 0.2094 - val_loss: 2.1165 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.7761 - acc: 0.3594 - val_loss: 1.0209 - val_acc: 0.6250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0732 - acc: 0.5219 - val_loss: 0.7878 - val_acc: 0.7000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8498 - acc: 0.6688 - val_loss: 0.8277 - val_acc: 0.7000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7531 - acc: 0.7000 - val_loss: 0.7970 - val_acc: 0.7250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5226 - acc: 0.8437 - val_loss: 0.9401 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3908 - acc: 0.8500 - val_loss: 0.8510 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4444 - acc: 0.8375 - val_loss: 0.9107 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.9094 - val_loss: 0.9425 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1659 - acc: 0.9500 - val_loss: 1.0546 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9403 - acc: 0.3062 - val_loss: 2.2226 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6555 - acc: 0.3875 - val_loss: 1.4961 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4701 - acc: 0.4719 - val_loss: 1.2296 - val_acc: 0.4250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9061 - acc: 0.6219 - val_loss: 0.9064 - val_acc: 0.6750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6792 - acc: 0.7187 - val_loss: 0.9725 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4383 - acc: 0.8281 - val_loss: 1.1123 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2151 - acc: 0.9406 - val_loss: 1.0888 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0818 - acc: 0.9844 - val_loss: 1.1277 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0389 - acc: 1.0000 - val_loss: 1.2814 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0212 - acc: 0.9969 - val_loss: 1.2703 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5854 - acc: 0.2813 - val_loss: 1.5707 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4111 - acc: 0.4469 - val_loss: 1.3273 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9719 - acc: 0.6281 - val_loss: 1.2918 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6641 - acc: 0.7344 - val_loss: 1.5110 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4179 - acc: 0.8375 - val_loss: 1.5768 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2645 - acc: 0.9094 - val_loss: 1.4838 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1926 - acc: 0.9344 - val_loss: 1.8719 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0971 - acc: 0.9687 - val_loss: 1.6453 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0311 - acc: 1.0000 - val_loss: 2.0541 - val_acc: 0.5125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0156 - acc: 0.9969 - val_loss: 2.0660 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5439 - acc: 0.3281 - val_loss: 1.4695 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5349 - acc: 0.4469 - val_loss: 1.8876 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1911 - acc: 0.5250 - val_loss: 1.7716 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0760 - acc: 0.6031 - val_loss: 1.3301 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7308 - acc: 0.7250 - val_loss: 1.3097 - val_acc: 0.4750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4620 - acc: 0.8312 - val_loss: 1.1006 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2153 - acc: 0.9406 - val_loss: 1.1088 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0953 - acc: 0.9812 - val_loss: 1.4399 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 1.3812 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.6998 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5442 - acc: 0.3219 - val_loss: 1.7032 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2389 - acc: 0.5156 - val_loss: 1.2411 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8763 - acc: 0.6594 - val_loss: 1.1721 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6357 - acc: 0.7562 - val_loss: 1.2373 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3932 - acc: 0.8625 - val_loss: 1.1341 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1764 - acc: 0.9687 - val_loss: 1.1844 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1429 - acc: 0.9625 - val_loss: 1.4465 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0587 - acc: 0.9875 - val_loss: 1.4062 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.4236 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.4416 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5700 - acc: 0.3000 - val_loss: 1.3904 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1788 - acc: 0.5406 - val_loss: 1.5299 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8312 - acc: 0.6844 - val_loss: 1.1029 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6280 - acc: 0.7469 - val_loss: 1.0415 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2959 - acc: 0.9187 - val_loss: 0.9622 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1899 - acc: 0.9531 - val_loss: 1.3750 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0835 - acc: 0.9937 - val_loss: 1.0666 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0300 - acc: 1.0000 - val_loss: 1.2204 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 1.2575 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.3088 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5744 - acc: 0.2875 - val_loss: 1.6109 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3032 - acc: 0.5125 - val_loss: 1.2651 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8647 - acc: 0.6438 - val_loss: 1.3366 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8251 - acc: 0.6594 - val_loss: 1.1895 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5042 - acc: 0.8406 - val_loss: 1.0372 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3051 - acc: 0.8906 - val_loss: 1.5507 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1443 - acc: 0.9656 - val_loss: 1.1577 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0713 - acc: 0.9969 - val_loss: 1.1939 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0290 - acc: 1.0000 - val_loss: 1.2910 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 1.2960 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5498 - acc: 0.3125 - val_loss: 1.3351 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1174 - acc: 0.5500 - val_loss: 1.7285 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2667 - acc: 0.5406 - val_loss: 1.1486 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7930 - acc: 0.6844 - val_loss: 1.1856 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6343 - acc: 0.7750 - val_loss: 1.2290 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3986 - acc: 0.8625 - val_loss: 1.0970 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2306 - acc: 0.9344 - val_loss: 1.2591 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1005 - acc: 0.9844 - val_loss: 1.1763 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0451 - acc: 0.9969 - val_loss: 1.3064 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0268 - acc: 0.9969 - val_loss: 1.2217 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6286 - acc: 0.2469 - val_loss: 1.5658 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3405 - acc: 0.4375 - val_loss: 1.1492 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0541 - acc: 0.5594 - val_loss: 1.2391 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7672 - acc: 0.7156 - val_loss: 1.2118 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7778 - acc: 0.7250 - val_loss: 1.0832 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3024 - acc: 0.9312 - val_loss: 1.0312 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1500 - acc: 0.9687 - val_loss: 1.3154 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0765 - acc: 0.9875 - val_loss: 1.1460 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0460 - acc: 0.9969 - val_loss: 1.2754 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 1.4475 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_97 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_191 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_97 (MaxPooling (None, 1, 21, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_192 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_98 (MaxPooling (None, 1, 3, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_48 (Flatten)         (None, 63)                0         \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 128)               8192      \n",
            "_________________________________________________________________\n",
            "activation_193 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_194 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,063,013\n",
            "Trainable params: 2,063,013\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 5.0317 - acc: 0.2312 - val_loss: 3.4245 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1306 - acc: 0.3313 - val_loss: 1.6547 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2426 - acc: 0.4906 - val_loss: 1.0713 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0702 - acc: 0.4969 - val_loss: 1.0266 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9492 - acc: 0.5875 - val_loss: 0.9823 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7964 - acc: 0.6938 - val_loss: 0.8312 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6106 - acc: 0.7656 - val_loss: 0.9540 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.8344 - val_loss: 0.8499 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3111 - acc: 0.8844 - val_loss: 0.9201 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1853 - acc: 0.9625 - val_loss: 0.8602 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.7500 - acc: 0.3000 - val_loss: 1.7761 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7714 - acc: 0.4344 - val_loss: 1.5728 - val_acc: 0.3250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1781 - acc: 0.5156 - val_loss: 1.3103 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8887 - acc: 0.6781 - val_loss: 1.1013 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5586 - acc: 0.8000 - val_loss: 0.9525 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.9281 - val_loss: 1.1009 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1484 - acc: 0.9625 - val_loss: 1.5708 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1012 - acc: 0.9687 - val_loss: 1.5264 - val_acc: 0.4750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0627 - acc: 0.9906 - val_loss: 1.5381 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 1.7403 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5556 - acc: 0.3094 - val_loss: 1.2123 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2666 - acc: 0.5281 - val_loss: 1.2741 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8128 - acc: 0.6688 - val_loss: 1.4646 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5345 - acc: 0.7844 - val_loss: 1.1768 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2749 - acc: 0.9062 - val_loss: 1.9905 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2629 - acc: 0.8938 - val_loss: 1.1043 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1174 - acc: 0.9625 - val_loss: 1.6795 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0294 - acc: 1.0000 - val_loss: 1.4120 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0294 - acc: 0.9906 - val_loss: 2.2141 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.5137 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5484 - acc: 0.3375 - val_loss: 1.8981 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4251 - acc: 0.4750 - val_loss: 1.3092 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0469 - acc: 0.5875 - val_loss: 1.2784 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6223 - acc: 0.7688 - val_loss: 1.2675 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4685 - acc: 0.8344 - val_loss: 1.3131 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2064 - acc: 0.9562 - val_loss: 1.2965 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0856 - acc: 0.9906 - val_loss: 1.4307 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0413 - acc: 0.9937 - val_loss: 1.4005 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.5915 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.5398 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4621 - acc: 0.3562 - val_loss: 1.3454 - val_acc: 0.5250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2883 - acc: 0.5219 - val_loss: 1.4406 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7680 - acc: 0.7187 - val_loss: 1.5676 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4301 - acc: 0.8437 - val_loss: 1.4554 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1779 - acc: 0.9531 - val_loss: 1.9437 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0747 - acc: 0.9844 - val_loss: 2.0442 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 2.3145 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 2.2092 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.4460 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3791 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5516 - acc: 0.3156 - val_loss: 1.3080 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5068 - acc: 0.4687 - val_loss: 1.3867 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9582 - acc: 0.6250 - val_loss: 1.3224 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7331 - acc: 0.7187 - val_loss: 1.1632 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4326 - acc: 0.8562 - val_loss: 1.1811 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2882 - acc: 0.9156 - val_loss: 1.5430 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1339 - acc: 0.9687 - val_loss: 1.4589 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0652 - acc: 0.9875 - val_loss: 1.3771 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.4020 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.6243 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6071 - acc: 0.3250 - val_loss: 1.3107 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5173 - acc: 0.4750 - val_loss: 1.2676 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0547 - acc: 0.5688 - val_loss: 1.2110 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8397 - acc: 0.6781 - val_loss: 0.9605 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5050 - acc: 0.8125 - val_loss: 0.8506 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2723 - acc: 0.9187 - val_loss: 0.9672 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0962 - acc: 0.9875 - val_loss: 1.0732 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0622 - acc: 1.0000 - val_loss: 1.0043 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.1465 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 1.3350 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4815 - acc: 0.3375 - val_loss: 1.5027 - val_acc: 0.3500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9911 - acc: 0.6187 - val_loss: 1.4524 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8367 - acc: 0.6844 - val_loss: 1.3046 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5307 - acc: 0.8250 - val_loss: 1.2603 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2237 - acc: 0.9406 - val_loss: 1.2315 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0962 - acc: 0.9812 - val_loss: 1.2522 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 1.4184 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0251 - acc: 1.0000 - val_loss: 1.3486 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.4421 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 1.3934 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5335 - acc: 0.3250 - val_loss: 1.2004 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0861 - acc: 0.5719 - val_loss: 1.4746 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9455 - acc: 0.6406 - val_loss: 1.1474 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5338 - acc: 0.8125 - val_loss: 1.1802 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3949 - acc: 0.8625 - val_loss: 1.1686 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2371 - acc: 0.9344 - val_loss: 1.1057 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1103 - acc: 0.9813 - val_loss: 1.2401 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0611 - acc: 0.9844 - val_loss: 1.5952 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0460 - acc: 0.9906 - val_loss: 1.4939 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0225 - acc: 0.9969 - val_loss: 1.4960 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_99 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_195 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_99 (MaxPooling (None, 1, 22, 11)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 1, 11, 64)         34560     \n",
            "_________________________________________________________________\n",
            "activation_196 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_100 (MaxPoolin (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_49 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 128)               10880     \n",
            "_________________________________________________________________\n",
            "activation_197 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_198 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,068,837\n",
            "Trainable params: 2,068,837\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 2), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 2), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 16ms/step - loss: 3.3080 - acc: 0.2969 - val_loss: 2.1777 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5913 - acc: 0.4063 - val_loss: 1.2371 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1534 - acc: 0.5500 - val_loss: 1.1822 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9004 - acc: 0.6500 - val_loss: 1.1192 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7891 - acc: 0.7031 - val_loss: 1.1555 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5788 - acc: 0.8031 - val_loss: 1.1401 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4080 - acc: 0.8812 - val_loss: 1.2493 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2784 - acc: 0.9187 - val_loss: 1.2239 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2093 - acc: 0.9375 - val_loss: 1.2892 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2007 - acc: 0.9281 - val_loss: 1.4727 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5171 - acc: 0.3656 - val_loss: 1.4003 - val_acc: 0.5625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3781 - acc: 0.5250 - val_loss: 1.0292 - val_acc: 0.6375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1458 - acc: 0.5781 - val_loss: 1.1222 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7045 - acc: 0.7438 - val_loss: 1.1429 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4920 - acc: 0.8094 - val_loss: 1.1658 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2664 - acc: 0.9250 - val_loss: 1.3940 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1723 - acc: 0.9469 - val_loss: 1.5798 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0978 - acc: 0.9687 - val_loss: 1.3744 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0437 - acc: 0.9937 - val_loss: 1.2522 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 1.7190 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4943 - acc: 0.3469 - val_loss: 1.3243 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1260 - acc: 0.5375 - val_loss: 1.0791 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6425 - acc: 0.7500 - val_loss: 1.2702 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3645 - acc: 0.8594 - val_loss: 1.4247 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1718 - acc: 0.9406 - val_loss: 1.2233 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0478 - acc: 0.9969 - val_loss: 1.6139 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0159 - acc: 0.9969 - val_loss: 1.5698 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.6532 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.6957 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.6977 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6007 - acc: 0.3187 - val_loss: 1.2251 - val_acc: 0.5250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1785 - acc: 0.5313 - val_loss: 1.1153 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8932 - acc: 0.6531 - val_loss: 1.2123 - val_acc: 0.6250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5515 - acc: 0.8094 - val_loss: 1.4909 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3183 - acc: 0.8781 - val_loss: 1.4505 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2202 - acc: 0.9375 - val_loss: 1.4732 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1421 - acc: 0.9625 - val_loss: 1.6665 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0768 - acc: 0.9781 - val_loss: 1.7360 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0208 - acc: 0.9969 - val_loss: 1.9227 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.8160 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4216 - acc: 0.3813 - val_loss: 1.4528 - val_acc: 0.4750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0829 - acc: 0.6125 - val_loss: 1.5249 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6405 - acc: 0.8000 - val_loss: 1.3928 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4182 - acc: 0.8438 - val_loss: 1.0498 - val_acc: 0.6750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1573 - acc: 0.9625 - val_loss: 1.1740 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0543 - acc: 0.9937 - val_loss: 1.2474 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0321 - acc: 0.9969 - val_loss: 1.3297 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.2620 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.4849 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.4859 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4694 - acc: 0.3281 - val_loss: 1.7556 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0710 - acc: 0.5719 - val_loss: 1.2615 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1050 - acc: 0.6281 - val_loss: 1.2541 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7777 - acc: 0.6906 - val_loss: 1.2874 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4213 - acc: 0.8250 - val_loss: 2.2093 - val_acc: 0.4500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2191 - acc: 0.9281 - val_loss: 1.2945 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0700 - acc: 0.9875 - val_loss: 1.6614 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0434 - acc: 0.9937 - val_loss: 1.5660 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.5599 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.5129 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5326 - acc: 0.2781 - val_loss: 1.6696 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2883 - acc: 0.5344 - val_loss: 1.3936 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9372 - acc: 0.6344 - val_loss: 1.4083 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5733 - acc: 0.7938 - val_loss: 1.2402 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2934 - acc: 0.9187 - val_loss: 1.4646 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1246 - acc: 0.9625 - val_loss: 1.4798 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0529 - acc: 0.9906 - val_loss: 1.5585 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.9270 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.8156 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.8125 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5082 - acc: 0.3344 - val_loss: 1.2055 - val_acc: 0.5125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2295 - acc: 0.5500 - val_loss: 1.0223 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8186 - acc: 0.6469 - val_loss: 1.2797 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7015 - acc: 0.7500 - val_loss: 1.1394 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4734 - acc: 0.8312 - val_loss: 0.9702 - val_acc: 0.6750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2179 - acc: 0.9312 - val_loss: 0.9643 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1000 - acc: 0.9812 - val_loss: 1.1124 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0578 - acc: 0.9875 - val_loss: 1.1079 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0300 - acc: 1.0000 - val_loss: 1.0399 - val_acc: 0.6875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 1.0129 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5134 - acc: 0.2750 - val_loss: 1.4262 - val_acc: 0.2875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1845 - acc: 0.5094 - val_loss: 1.2893 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9423 - acc: 0.6437 - val_loss: 1.0936 - val_acc: 0.6250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6536 - acc: 0.7406 - val_loss: 0.9490 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3702 - acc: 0.8844 - val_loss: 1.0361 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1764 - acc: 0.9594 - val_loss: 1.1025 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0978 - acc: 0.9875 - val_loss: 1.2951 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0474 - acc: 1.0000 - val_loss: 1.2320 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.1560 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.2928 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_101 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_199 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_101 (MaxPoolin (None, 1, 21, 11)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 1, 11, 64)         34560     \n",
            "_________________________________________________________________\n",
            "activation_200 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_102 (MaxPoolin (None, 1, 4, 22)          0         \n",
            "_________________________________________________________________\n",
            "flatten_50 (Flatten)         (None, 88)                0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 128)               11392     \n",
            "_________________________________________________________________\n",
            "activation_201 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_202 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,069,349\n",
            "Trainable params: 2,069,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 1), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 1), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 2.4611 - acc: 0.2750 - val_loss: 2.1574 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4211 - acc: 0.3937 - val_loss: 1.2671 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0890 - acc: 0.5438 - val_loss: 1.1353 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9519 - acc: 0.6250 - val_loss: 1.0337 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7320 - acc: 0.6969 - val_loss: 1.0526 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5767 - acc: 0.7750 - val_loss: 1.0196 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5054 - acc: 0.7969 - val_loss: 1.1139 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3615 - acc: 0.8719 - val_loss: 1.1428 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2562 - acc: 0.9219 - val_loss: 1.1885 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1803 - acc: 0.9500 - val_loss: 1.3968 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4857 - acc: 0.3188 - val_loss: 1.1078 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1394 - acc: 0.5437 - val_loss: 1.0378 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0320 - acc: 0.6375 - val_loss: 1.0625 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.7802 - acc: 0.6938 - val_loss: 1.1441 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5309 - acc: 0.7875 - val_loss: 0.9279 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3019 - acc: 0.9062 - val_loss: 1.1337 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1584 - acc: 0.9594 - val_loss: 1.1225 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0651 - acc: 0.9906 - val_loss: 1.2738 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 1.4540 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0159 - acc: 0.9969 - val_loss: 1.6228 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5169 - acc: 0.2937 - val_loss: 1.3605 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1079 - acc: 0.5562 - val_loss: 1.3624 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9348 - acc: 0.6281 - val_loss: 1.1503 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7010 - acc: 0.7344 - val_loss: 1.3888 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4393 - acc: 0.8500 - val_loss: 1.2562 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1845 - acc: 0.9500 - val_loss: 1.5041 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1548 - acc: 0.9469 - val_loss: 1.6236 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0854 - acc: 0.9750 - val_loss: 1.6915 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1072 - acc: 0.9656 - val_loss: 1.7844 - val_acc: 0.5375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 1.8715 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.5559 - acc: 0.2406 - val_loss: 1.2943 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1741 - acc: 0.5375 - val_loss: 1.0809 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0178 - acc: 0.6375 - val_loss: 1.3607 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6827 - acc: 0.7313 - val_loss: 1.0282 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3274 - acc: 0.9187 - val_loss: 1.1026 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2196 - acc: 0.9125 - val_loss: 1.1738 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1386 - acc: 0.9688 - val_loss: 1.4612 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.9750 - val_loss: 1.6845 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0446 - acc: 0.9875 - val_loss: 1.6442 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0216 - acc: 0.9969 - val_loss: 1.5375 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5977 - acc: 0.2031 - val_loss: 1.5945 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.2380 - acc: 0.4875 - val_loss: 1.3326 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9608 - acc: 0.6156 - val_loss: 1.0531 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7045 - acc: 0.7344 - val_loss: 1.0755 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4754 - acc: 0.8313 - val_loss: 1.0684 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3579 - acc: 0.8688 - val_loss: 1.0648 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1391 - acc: 0.9562 - val_loss: 1.2684 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0661 - acc: 0.9875 - val_loss: 1.3298 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 1.5394 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.5672 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6436 - acc: 0.2125 - val_loss: 1.5395 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.3735 - acc: 0.4187 - val_loss: 1.2146 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.0550 - acc: 0.5938 - val_loss: 0.9484 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8427 - acc: 0.6438 - val_loss: 0.9029 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6611 - acc: 0.7656 - val_loss: 1.1735 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4792 - acc: 0.8187 - val_loss: 0.8765 - val_acc: 0.7125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2359 - acc: 0.9406 - val_loss: 0.9168 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1322 - acc: 0.9719 - val_loss: 0.9572 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0729 - acc: 0.9937 - val_loss: 1.0275 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0755 - acc: 0.9781 - val_loss: 1.2968 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6028 - acc: 0.2125 - val_loss: 1.4157 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3014 - acc: 0.4344 - val_loss: 1.1252 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2282 - acc: 0.5031 - val_loss: 1.3190 - val_acc: 0.3750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9198 - acc: 0.6469 - val_loss: 0.8673 - val_acc: 0.6625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6503 - acc: 0.7469 - val_loss: 0.7823 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3992 - acc: 0.9094 - val_loss: 0.7960 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2130 - acc: 0.9375 - val_loss: 0.9069 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1478 - acc: 0.9656 - val_loss: 0.9371 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0660 - acc: 0.9875 - val_loss: 0.8349 - val_acc: 0.7500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0251 - acc: 1.0000 - val_loss: 1.0045 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.6022 - acc: 0.2125 - val_loss: 1.4451 - val_acc: 0.4000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2771 - acc: 0.4594 - val_loss: 1.3552 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1314 - acc: 0.5187 - val_loss: 1.1714 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8576 - acc: 0.6750 - val_loss: 1.1493 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6559 - acc: 0.7469 - val_loss: 1.4266 - val_acc: 0.4375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5196 - acc: 0.8156 - val_loss: 1.0717 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2694 - acc: 0.9031 - val_loss: 1.2527 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1343 - acc: 0.9781 - val_loss: 1.5238 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0722 - acc: 0.9906 - val_loss: 1.3324 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 1.4321 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5784 - acc: 0.2344 - val_loss: 1.4423 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2489 - acc: 0.4687 - val_loss: 1.2564 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0512 - acc: 0.5687 - val_loss: 1.2075 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9241 - acc: 0.6562 - val_loss: 1.1208 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.6660 - acc: 0.7438 - val_loss: 1.1984 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4447 - acc: 0.8344 - val_loss: 1.2207 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2667 - acc: 0.9375 - val_loss: 1.2676 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2106 - acc: 0.9375 - val_loss: 1.1884 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1147 - acc: 0.9781 - val_loss: 1.9106 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0627 - acc: 0.9906 - val_loss: 1.6739 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 995us/step\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_103 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_203 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_103 (MaxPoolin (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_204 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_104 (MaxPoolin (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_51 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 128)               10880     \n",
            "_________________________________________________________________\n",
            "activation_205 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_206 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,065,701\n",
            "Trainable params: 2,065,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 5s 17ms/step - loss: 3.0293 - acc: 0.2812 - val_loss: 1.8736 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4493 - acc: 0.4562 - val_loss: 1.3190 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9513 - acc: 0.6469 - val_loss: 1.2030 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6556 - acc: 0.7281 - val_loss: 1.0100 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3491 - acc: 0.8906 - val_loss: 0.9691 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1873 - acc: 0.9656 - val_loss: 1.1212 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1105 - acc: 0.9781 - val_loss: 1.1191 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0571 - acc: 0.9906 - val_loss: 1.2082 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0231 - acc: 1.0000 - val_loss: 1.2708 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.3009 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 2.2960 - acc: 0.2844 - val_loss: 1.6017 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4521 - acc: 0.4875 - val_loss: 2.0514 - val_acc: 0.3625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1586 - acc: 0.5406 - val_loss: 1.0724 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8346 - acc: 0.6844 - val_loss: 1.2688 - val_acc: 0.5375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4959 - acc: 0.8219 - val_loss: 1.1834 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2867 - acc: 0.9187 - val_loss: 1.1283 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1294 - acc: 0.9812 - val_loss: 1.3014 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0662 - acc: 0.9781 - val_loss: 1.3192 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 1.3990 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 1.4358 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5503 - acc: 0.3563 - val_loss: 1.1965 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5798 - acc: 0.4844 - val_loss: 1.1477 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1394 - acc: 0.5656 - val_loss: 1.1231 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6526 - acc: 0.7344 - val_loss: 1.1095 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4186 - acc: 0.8656 - val_loss: 1.1992 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1918 - acc: 0.9687 - val_loss: 1.3428 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0918 - acc: 0.9719 - val_loss: 1.3954 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0427 - acc: 0.9906 - val_loss: 1.3358 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 1.4285 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0116 - acc: 0.9969 - val_loss: 1.3570 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4947 - acc: 0.3625 - val_loss: 1.4614 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2183 - acc: 0.5250 - val_loss: 1.2649 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8476 - acc: 0.6438 - val_loss: 1.3327 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5024 - acc: 0.8375 - val_loss: 1.4457 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3146 - acc: 0.8812 - val_loss: 1.2521 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1414 - acc: 0.9687 - val_loss: 1.5468 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0893 - acc: 0.9750 - val_loss: 1.5966 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0247 - acc: 0.9969 - val_loss: 1.9637 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.6604 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.8422 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4452 - acc: 0.3344 - val_loss: 1.1916 - val_acc: 0.5625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0717 - acc: 0.5531 - val_loss: 1.3164 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8428 - acc: 0.6781 - val_loss: 1.1419 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3776 - acc: 0.8625 - val_loss: 1.3462 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2321 - acc: 0.9156 - val_loss: 1.2806 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0880 - acc: 0.9844 - val_loss: 1.2745 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0489 - acc: 0.9875 - val_loss: 1.8152 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 1.5912 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.5075 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.5473 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4523 - acc: 0.3969 - val_loss: 1.6756 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0281 - acc: 0.5906 - val_loss: 1.8787 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7248 - acc: 0.7031 - val_loss: 1.3052 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4947 - acc: 0.8219 - val_loss: 1.2586 - val_acc: 0.4375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2612 - acc: 0.9156 - val_loss: 1.3206 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2403 - acc: 0.9156 - val_loss: 1.8674 - val_acc: 0.4875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1496 - acc: 0.9656 - val_loss: 1.5330 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0969 - acc: 0.9687 - val_loss: 1.5443 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0333 - acc: 0.9937 - val_loss: 2.2651 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.9090 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4373 - acc: 0.3656 - val_loss: 1.2435 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1183 - acc: 0.5812 - val_loss: 1.4412 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9875 - acc: 0.6281 - val_loss: 1.0503 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5438 - acc: 0.8031 - val_loss: 0.9649 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2951 - acc: 0.9031 - val_loss: 1.0981 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1649 - acc: 0.9531 - val_loss: 1.0313 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0608 - acc: 0.9938 - val_loss: 0.9624 - val_acc: 0.7125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0329 - acc: 0.9969 - val_loss: 1.1291 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.0610 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.1135 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5024 - acc: 0.3500 - val_loss: 1.1886 - val_acc: 0.5625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0426 - acc: 0.5969 - val_loss: 1.2259 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6431 - acc: 0.7531 - val_loss: 1.2390 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3908 - acc: 0.8594 - val_loss: 1.1482 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2021 - acc: 0.9469 - val_loss: 1.1774 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1956 - acc: 0.9344 - val_loss: 1.3208 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1735 - acc: 0.9531 - val_loss: 1.6763 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0469 - acc: 0.9937 - val_loss: 1.7257 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.7861 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.8741 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4754 - acc: 0.3188 - val_loss: 1.0916 - val_acc: 0.5875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0733 - acc: 0.5219 - val_loss: 1.2905 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9379 - acc: 0.6219 - val_loss: 1.1331 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6258 - acc: 0.7750 - val_loss: 1.2590 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4247 - acc: 0.8406 - val_loss: 1.3828 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.2149 - acc: 0.9250 - val_loss: 1.2547 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0868 - acc: 0.9875 - val_loss: 1.3209 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 0.9969 - val_loss: 1.5661 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.6410 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.5814 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_105 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_207 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_105 (MaxPoolin (None, 1, 21, 11)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 1, 11, 64)         34560     \n",
            "_________________________________________________________________\n",
            "activation_208 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_106 (MaxPoolin (None, 1, 3, 22)          0         \n",
            "_________________________________________________________________\n",
            "flatten_52 (Flatten)         (None, 66)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 128)               8576      \n",
            "_________________________________________________________________\n",
            "activation_209 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_210 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,066,533\n",
            "Trainable params: 2,066,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 1), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 1), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 17ms/step - loss: 2.6207 - acc: 0.2563 - val_loss: 1.3904 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4376 - acc: 0.4156 - val_loss: 1.4209 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2173 - acc: 0.4500 - val_loss: 1.4431 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9504 - acc: 0.5969 - val_loss: 1.2304 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6878 - acc: 0.7125 - val_loss: 1.3019 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4832 - acc: 0.8156 - val_loss: 1.3417 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3689 - acc: 0.8875 - val_loss: 1.4374 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2581 - acc: 0.9219 - val_loss: 1.4874 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1486 - acc: 0.9500 - val_loss: 1.5415 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0815 - acc: 0.9812 - val_loss: 1.6265 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6078 - acc: 0.2531 - val_loss: 1.4079 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1621 - acc: 0.5125 - val_loss: 1.3939 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.7127 - acc: 0.6938 - val_loss: 1.2878 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3828 - acc: 0.8531 - val_loss: 1.4669 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1810 - acc: 0.9375 - val_loss: 1.9180 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0769 - acc: 0.9719 - val_loss: 2.0328 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0500 - acc: 0.9875 - val_loss: 2.6393 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0446 - acc: 0.9906 - val_loss: 2.8273 - val_acc: 0.4875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0652 - acc: 0.9687 - val_loss: 2.5646 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0300 - acc: 0.9937 - val_loss: 3.2445 - val_acc: 0.4875\n",
            "100/100 [==============================] - 0s 987us/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5504 - acc: 0.2844 - val_loss: 1.3196 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1302 - acc: 0.5375 - val_loss: 1.2730 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9976 - acc: 0.6125 - val_loss: 1.0257 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5288 - acc: 0.7906 - val_loss: 1.0970 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3491 - acc: 0.8625 - val_loss: 1.2442 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1880 - acc: 0.9500 - val_loss: 1.3914 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0881 - acc: 0.9812 - val_loss: 1.4874 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0350 - acc: 0.9969 - val_loss: 1.3724 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0246 - acc: 0.9969 - val_loss: 1.7781 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0217 - acc: 0.9969 - val_loss: 1.5369 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5853 - acc: 0.2625 - val_loss: 1.3475 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2243 - acc: 0.4781 - val_loss: 1.1717 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8795 - acc: 0.6469 - val_loss: 1.0148 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5908 - acc: 0.7875 - val_loss: 0.9527 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3583 - acc: 0.8625 - val_loss: 0.9777 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1931 - acc: 0.9531 - val_loss: 0.9549 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1124 - acc: 0.9656 - val_loss: 1.2887 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0932 - acc: 0.9781 - val_loss: 1.2002 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0458 - acc: 0.9969 - val_loss: 1.4188 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.9969 - val_loss: 1.3269 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6330 - acc: 0.2063 - val_loss: 1.5894 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4301 - acc: 0.4219 - val_loss: 1.4392 - val_acc: 0.3375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9695 - acc: 0.5625 - val_loss: 1.2310 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6023 - acc: 0.7719 - val_loss: 1.0837 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3485 - acc: 0.8656 - val_loss: 1.1415 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1643 - acc: 0.9562 - val_loss: 1.3740 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0783 - acc: 0.9875 - val_loss: 1.5984 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0740 - acc: 0.9781 - val_loss: 2.0331 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0411 - acc: 0.9906 - val_loss: 1.6416 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 1.8900 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6135 - acc: 0.2656 - val_loss: 1.6264 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2278 - acc: 0.5156 - val_loss: 1.2582 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9240 - acc: 0.6437 - val_loss: 1.2801 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7261 - acc: 0.7094 - val_loss: 1.5015 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.6210 - acc: 0.7719 - val_loss: 1.2700 - val_acc: 0.4625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3487 - acc: 0.8781 - val_loss: 1.6048 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1307 - acc: 0.9719 - val_loss: 1.5967 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0642 - acc: 0.9906 - val_loss: 1.7820 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0366 - acc: 0.9937 - val_loss: 1.9208 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 1.9349 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6186 - acc: 0.2156 - val_loss: 1.6664 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.3721 - acc: 0.4156 - val_loss: 1.2951 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8345 - acc: 0.6937 - val_loss: 1.4825 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8828 - acc: 0.6531 - val_loss: 1.8077 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4352 - acc: 0.8531 - val_loss: 1.2866 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2764 - acc: 0.9063 - val_loss: 1.4659 - val_acc: 0.5125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0998 - acc: 0.9844 - val_loss: 1.6021 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9875 - val_loss: 1.8300 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0344 - acc: 0.9875 - val_loss: 1.7882 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 2.1802 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6323 - acc: 0.2125 - val_loss: 1.5571 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4222 - acc: 0.4125 - val_loss: 1.3014 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9183 - acc: 0.6750 - val_loss: 1.1311 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6506 - acc: 0.7313 - val_loss: 1.2720 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3914 - acc: 0.8938 - val_loss: 1.1595 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1842 - acc: 0.9562 - val_loss: 1.5464 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0724 - acc: 0.9906 - val_loss: 1.6451 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0409 - acc: 0.9969 - val_loss: 1.7652 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.8456 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.8657 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6456 - acc: 0.2062 - val_loss: 1.7010 - val_acc: 0.1500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.4582 - acc: 0.3719 - val_loss: 1.2410 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.0830 - acc: 0.5781 - val_loss: 1.3621 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8303 - acc: 0.6813 - val_loss: 1.0189 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5636 - acc: 0.7719 - val_loss: 0.9720 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.4421 - acc: 0.8187 - val_loss: 1.2581 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2596 - acc: 0.9094 - val_loss: 1.5427 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1949 - acc: 0.9469 - val_loss: 1.4484 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1164 - acc: 0.9750 - val_loss: 1.6109 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0887 - acc: 0.9812 - val_loss: 1.8029 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlRs021L7sU5",
        "colab_type": "code",
        "outputId": "fd990c1f-0c5f-4c0b-f6b5-a1e13be07081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "score_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Parameter</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Kernel Size: (3, 3)</td>\n",
              "      <td>0.473333</td>\n",
              "      <td>1.981357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Kernel Size: (5, 5)</td>\n",
              "      <td>0.565556</td>\n",
              "      <td>1.611662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Kernel Size: (7, 7)</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>1.577976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Kernel Size: (1, 5)</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>1.530358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Kernel Size: (5, 1)</td>\n",
              "      <td>0.368889</td>\n",
              "      <td>1.725819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Kernel Size: (1, 7)</td>\n",
              "      <td>0.557778</td>\n",
              "      <td>1.488459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Kernel Size: (7, 1)</td>\n",
              "      <td>0.407778</td>\n",
              "      <td>1.746344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Conv Strides: (1, 1)</td>\n",
              "      <td>0.504444</td>\n",
              "      <td>5.114644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.0</td>\n",
              "      <td>Conv Strides: (2, 2)</td>\n",
              "      <td>0.595556</td>\n",
              "      <td>1.339987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Conv Strides: (3, 3)</td>\n",
              "      <td>0.602222</td>\n",
              "      <td>1.447754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Conv Strides: (1, 2)</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>1.342004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11.0</td>\n",
              "      <td>Conv Strides: (2, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.748762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12.0</td>\n",
              "      <td>Conv Strides: (3, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.823076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13.0</td>\n",
              "      <td>Conv Strides: (1, 3)</td>\n",
              "      <td>0.563333</td>\n",
              "      <td>1.780330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x32</td>\n",
              "      <td>0.608889</td>\n",
              "      <td>1.293163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x64</td>\n",
              "      <td>0.596667</td>\n",
              "      <td>1.311897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x128</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.443874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x32</td>\n",
              "      <td>0.544444</td>\n",
              "      <td>1.366712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x64</td>\n",
              "      <td>0.521111</td>\n",
              "      <td>3.820026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x128</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>3.871442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x32</td>\n",
              "      <td>0.465556</td>\n",
              "      <td>4.841143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x64</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>6.063469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x128</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.894476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (1, 1)</td>\n",
              "      <td>0.597778</td>\n",
              "      <td>1.630594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (2, 2)</td>\n",
              "      <td>0.618889</td>\n",
              "      <td>1.368143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (3, 3)</td>\n",
              "      <td>0.597778</td>\n",
              "      <td>1.454984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (1, 2)</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>1.454244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (2, 1)</td>\n",
              "      <td>0.596667</td>\n",
              "      <td>1.507703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (1, 3)</td>\n",
              "      <td>0.625556</td>\n",
              "      <td>1.394259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (3, 1)</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>1.927103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0             Parameter  Accuracy       Loss\n",
              "0          0.0   Kernel Size: (3, 3)  0.473333   1.981357\n",
              "1          1.0   Kernel Size: (5, 5)  0.565556   1.611662\n",
              "2          2.0   Kernel Size: (7, 7)  0.588889   1.577976\n",
              "3          3.0   Kernel Size: (1, 5)  0.533333   1.530358\n",
              "4          4.0   Kernel Size: (5, 1)  0.368889   1.725819\n",
              "5          5.0   Kernel Size: (1, 7)  0.557778   1.488459\n",
              "6          6.0   Kernel Size: (7, 1)  0.407778   1.746344\n",
              "7          7.0  Conv Strides: (1, 1)  0.504444   5.114644\n",
              "8          8.0  Conv Strides: (2, 2)  0.595556   1.339987\n",
              "9          9.0  Conv Strides: (3, 3)  0.602222   1.447754\n",
              "10        10.0  Conv Strides: (1, 2)  0.610000   1.342004\n",
              "11        11.0  Conv Strides: (2, 1)  0.528889   3.748762\n",
              "12        12.0  Conv Strides: (3, 1)  0.528889   3.823076\n",
              "13        13.0  Conv Strides: (1, 3)  0.563333   1.780330\n",
              "14         NaN     Batch Size: 32x32  0.608889   1.293163\n",
              "15         NaN     Batch Size: 32x64  0.596667   1.311897\n",
              "16         NaN    Batch Size: 32x128  0.600000   1.443874\n",
              "17         NaN     Batch Size: 64x32  0.544444   1.366712\n",
              "18         NaN     Batch Size: 64x64  0.521111   3.820026\n",
              "19         NaN    Batch Size: 64x128  0.533333   3.871442\n",
              "20         NaN    Batch Size: 128x32  0.465556   4.841143\n",
              "21         NaN    Batch Size: 128x64  0.472222   6.063469\n",
              "22         NaN   Batch Size: 128x128  0.200000  12.894476\n",
              "23         NaN     Pool Size: (1, 1)  0.597778   1.630594\n",
              "24         NaN     Pool Size: (2, 2)  0.618889   1.368143\n",
              "25         NaN     Pool Size: (3, 3)  0.597778   1.454984\n",
              "26         NaN     Pool Size: (1, 2)  0.613333   1.454244\n",
              "27         NaN     Pool Size: (2, 1)  0.596667   1.507703\n",
              "28         NaN     Pool Size: (1, 3)  0.625556   1.394259\n",
              "29         NaN     Pool Size: (3, 1)  0.573333   1.927103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kplpjBv47sXK",
        "colab_type": "code",
        "outputId": "207629fe-f9dd-483b-ba15-e8e3dc3d59f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "p_size = (1, 3)\n",
        "\n",
        "parameter = 'Pool Strides: '\n",
        "pool_strides = [(1, 1), (2, 2), (3, 3), (1, 2), (2, 1), (3, 1), (1, 3)]\n",
        "\n",
        "for pool_stride in pool_strides:\n",
        "  train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "  parameter_name = parameter+str(pool_stride)\n",
        "  parameter_acc = np.mean(test_accuracy)\n",
        "  parameter_loss = np.mean(test_loss)\n",
        "  score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(1, 1), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(1, 1), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_107 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_211 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_107 (MaxPoolin (None, 1, 64, 30)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 1, 32, 64)         94144     \n",
            "_________________________________________________________________\n",
            "activation_212 (Activation)  (None, 1, 32, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_108 (MaxPoolin (None, 1, 32, 62)         0         \n",
            "_________________________________________________________________\n",
            "flatten_53 (Flatten)         (None, 1984)              0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 128)               254080    \n",
            "_________________________________________________________________\n",
            "activation_213 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_214 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,371,621\n",
            "Trainable params: 2,371,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 17ms/step - loss: 12.4158 - acc: 0.1687 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.7353 - acc: 0.1969 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.8944 - acc: 0.1687 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0609 - acc: 0.2125 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.3816 - acc: 0.2000 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.2280 - acc: 0.2125 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.4061 - acc: 0.2437 - val_loss: 1.7109 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5968 - acc: 0.2156 - val_loss: 1.6068 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6105 - acc: 0.1969 - val_loss: 1.6082 - val_acc: 0.2125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6099 - acc: 0.1969 - val_loss: 1.6101 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6094 - acc: 0.1969 - val_loss: 1.6118 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6091 - acc: 0.2188 - val_loss: 1.6133 - val_acc: 0.1125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6089 - acc: 0.2219 - val_loss: 1.6143 - val_acc: 0.1125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6087 - acc: 0.2219 - val_loss: 1.6145 - val_acc: 0.1125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6086 - acc: 0.2219 - val_loss: 1.6156 - val_acc: 0.1125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6084 - acc: 0.2219 - val_loss: 1.6160 - val_acc: 0.1125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.5458 - acc: 0.1781 - val_loss: 1.6037 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6086 - acc: 0.2219 - val_loss: 1.6077 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6592 - acc: 0.2875 - val_loss: 1.6142 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6079 - acc: 0.2031 - val_loss: 1.6120 - val_acc: 0.2125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6058 - acc: 0.2187 - val_loss: 1.6061 - val_acc: 0.2125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6041 - acc: 0.2000 - val_loss: 1.6022 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7428 - acc: 0.2594 - val_loss: 1.6181 - val_acc: 0.1500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6066 - acc: 0.2062 - val_loss: 1.6185 - val_acc: 0.1375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6034 - acc: 0.2094 - val_loss: 1.6183 - val_acc: 0.1625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6110 - acc: 0.2406 - val_loss: 1.6028 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.7411 - acc: 0.3063 - val_loss: 2.6826 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7323 - acc: 0.2531 - val_loss: 1.6133 - val_acc: 0.1250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6085 - acc: 0.2187 - val_loss: 1.6152 - val_acc: 0.1250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6041 - acc: 0.2344 - val_loss: 1.6127 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5871 - acc: 0.2562 - val_loss: 1.5882 - val_acc: 0.2250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7371 - acc: 0.2625 - val_loss: 1.6227 - val_acc: 0.2125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5493 - acc: 0.2437 - val_loss: 1.6373 - val_acc: 0.1750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4982 - acc: 0.3094 - val_loss: 1.6329 - val_acc: 0.2750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4069 - acc: 0.3844 - val_loss: 1.5800 - val_acc: 0.3125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2843 - acc: 0.4469 - val_loss: 1.7831 - val_acc: 0.4375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_109 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_215 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_109 (MaxPoolin (None, 1, 32, 15)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 1, 16, 64)         47104     \n",
            "_________________________________________________________________\n",
            "activation_216 (Activation)  (None, 1, 16, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_110 (MaxPoolin (None, 1, 8, 31)          0         \n",
            "_________________________________________________________________\n",
            "flatten_54 (Flatten)         (None, 248)               0         \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 128)               31872     \n",
            "_________________________________________________________________\n",
            "activation_217 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_218 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,102,373\n",
            "Trainable params: 2,102,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(2, 2), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(2, 2), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 18ms/step - loss: 11.1999 - acc: 0.1656 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.1083 - acc: 0.2594 - val_loss: 10.3997 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7363 - acc: 0.2062 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1813 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.3322 - acc: 0.2750 - val_loss: 11.6061 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.2036 - acc: 0.3406 - val_loss: 12.0661 - val_acc: 0.2125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.2785 - acc: 0.2875 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.5421 - acc: 0.2813 - val_loss: 11.4848 - val_acc: 0.2875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.6426 - acc: 0.2750 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.8713 - acc: 0.3844 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 9.8743 - acc: 0.3875 - val_loss: 10.8164 - val_acc: 0.3250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.2437 - acc: 0.3594 - val_loss: 10.6782 - val_acc: 0.3375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 9.8222 - acc: 0.3906 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.1131 - acc: 0.3656 - val_loss: 11.3187 - val_acc: 0.2875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.0553 - acc: 0.2781 - val_loss: 1.9215 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.5384 - acc: 0.3594 - val_loss: 1.4244 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1808 - acc: 0.5437 - val_loss: 1.4420 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8811 - acc: 0.6906 - val_loss: 1.0163 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6107 - acc: 0.7969 - val_loss: 1.6702 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4565 - acc: 0.8406 - val_loss: 1.1042 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2065 - acc: 0.9375 - val_loss: 1.1285 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1104 - acc: 0.9844 - val_loss: 1.3848 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0744 - acc: 0.9781 - val_loss: 1.3061 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0338 - acc: 0.9937 - val_loss: 1.2092 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6938 - acc: 0.3156 - val_loss: 1.7352 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2151 - acc: 0.5219 - val_loss: 1.5016 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.9338 - acc: 0.6125 - val_loss: 1.1584 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5781 - acc: 0.7937 - val_loss: 0.9116 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.4232 - acc: 0.8594 - val_loss: 1.0936 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1871 - acc: 0.9562 - val_loss: 1.0973 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0593 - acc: 0.9875 - val_loss: 1.1436 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0243 - acc: 0.9969 - val_loss: 1.3660 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.2273 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.1395 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6447 - acc: 0.3344 - val_loss: 2.7242 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4987 - acc: 0.4875 - val_loss: 1.3257 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9320 - acc: 0.6187 - val_loss: 1.3131 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6903 - acc: 0.7500 - val_loss: 0.8621 - val_acc: 0.7000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3406 - acc: 0.8937 - val_loss: 1.2730 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2271 - acc: 0.9375 - val_loss: 1.0046 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0621 - acc: 0.9969 - val_loss: 1.1994 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.2936 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.3405 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.4044 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6445 - acc: 0.3312 - val_loss: 1.4002 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.8116 - acc: 0.4594 - val_loss: 2.2234 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.4621 - acc: 0.4906 - val_loss: 1.1999 - val_acc: 0.4750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.8061 - acc: 0.6844 - val_loss: 0.8267 - val_acc: 0.6875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5194 - acc: 0.8219 - val_loss: 0.7806 - val_acc: 0.7375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3043 - acc: 0.9000 - val_loss: 0.7780 - val_acc: 0.7250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1533 - acc: 0.9656 - val_loss: 0.6308 - val_acc: 0.7250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.0783 - acc: 0.9875 - val_loss: 0.7230 - val_acc: 0.7125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.7250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.7555 - val_acc: 0.7625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6619 - acc: 0.3094 - val_loss: 1.2464 - val_acc: 0.6000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6048 - acc: 0.4938 - val_loss: 1.3572 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8978 - acc: 0.6469 - val_loss: 0.7996 - val_acc: 0.6500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5768 - acc: 0.7781 - val_loss: 1.1747 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3565 - acc: 0.8719 - val_loss: 1.1590 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1936 - acc: 0.9437 - val_loss: 0.7304 - val_acc: 0.7250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0894 - acc: 0.9750 - val_loss: 0.9159 - val_acc: 0.7125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.7250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.0021 - val_acc: 0.7375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9451 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5107 - acc: 0.3656 - val_loss: 1.8570 - val_acc: 0.4750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5749 - acc: 0.4531 - val_loss: 1.8445 - val_acc: 0.4000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 1.1781 - acc: 0.5188 - val_loss: 1.2907 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.8614 - acc: 0.6719 - val_loss: 1.0880 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5439 - acc: 0.8125 - val_loss: 1.3029 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.2427 - acc: 0.9094 - val_loss: 1.0783 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.1721 - acc: 0.9437 - val_loss: 1.3995 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0804 - acc: 0.9812 - val_loss: 1.1595 - val_acc: 0.7000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 1.0725 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.0579 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_111 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_219 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_111 (MaxPoolin (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_220 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_112 (MaxPoolin (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_55 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 128)               10880     \n",
            "_________________________________________________________________\n",
            "activation_221 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_222 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,065,701\n",
            "Trainable params: 2,065,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 18ms/step - loss: 5.0154 - acc: 0.2719 - val_loss: 2.2093 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7905 - acc: 0.4281 - val_loss: 1.1526 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9515 - acc: 0.6125 - val_loss: 0.8976 - val_acc: 0.6625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9827 - acc: 0.6125 - val_loss: 0.9047 - val_acc: 0.6875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6796 - acc: 0.7219 - val_loss: 1.0856 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4384 - acc: 0.8313 - val_loss: 1.1318 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3392 - acc: 0.9031 - val_loss: 1.1363 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2337 - acc: 0.9312 - val_loss: 1.1117 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0944 - acc: 0.9844 - val_loss: 1.1443 - val_acc: 0.6875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0582 - acc: 0.9875 - val_loss: 1.1429 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7173 - acc: 0.3219 - val_loss: 1.5416 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4561 - acc: 0.5125 - val_loss: 0.9665 - val_acc: 0.6375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8442 - acc: 0.6531 - val_loss: 1.3576 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5422 - acc: 0.7969 - val_loss: 1.1234 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2475 - acc: 0.9219 - val_loss: 1.3275 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1301 - acc: 0.9594 - val_loss: 1.5441 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0572 - acc: 0.9969 - val_loss: 1.6580 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.6787 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.7487 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.7939 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6006 - acc: 0.3031 - val_loss: 1.3873 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3313 - acc: 0.5000 - val_loss: 1.3717 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9202 - acc: 0.6469 - val_loss: 1.7745 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7390 - acc: 0.6813 - val_loss: 1.2605 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5168 - acc: 0.8219 - val_loss: 1.1345 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2402 - acc: 0.9406 - val_loss: 1.3654 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1059 - acc: 0.9844 - val_loss: 1.2095 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0679 - acc: 0.9844 - val_loss: 1.5815 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.4510 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.6549 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6643 - acc: 0.3250 - val_loss: 1.6530 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2690 - acc: 0.4687 - val_loss: 1.2336 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9770 - acc: 0.6469 - val_loss: 0.8074 - val_acc: 0.6750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6643 - acc: 0.7313 - val_loss: 0.8677 - val_acc: 0.7000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3605 - acc: 0.8781 - val_loss: 0.8770 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1638 - acc: 0.9562 - val_loss: 1.1379 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1434 - acc: 0.9531 - val_loss: 1.0959 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0611 - acc: 0.9875 - val_loss: 1.1475 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.0902 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 1.1060 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5753 - acc: 0.3344 - val_loss: 1.5568 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2478 - acc: 0.5500 - val_loss: 1.3642 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7216 - acc: 0.7313 - val_loss: 1.1465 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5883 - acc: 0.8000 - val_loss: 1.4570 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3981 - acc: 0.8438 - val_loss: 1.3941 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1986 - acc: 0.9500 - val_loss: 1.3118 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0798 - acc: 0.9906 - val_loss: 1.4948 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0419 - acc: 0.9844 - val_loss: 1.9023 - val_acc: 0.4500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.4779 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.8356 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6016 - acc: 0.2406 - val_loss: 1.5662 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2838 - acc: 0.5250 - val_loss: 1.3681 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0595 - acc: 0.6000 - val_loss: 1.3597 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8967 - acc: 0.6625 - val_loss: 1.3635 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7113 - acc: 0.7250 - val_loss: 1.1741 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3528 - acc: 0.8844 - val_loss: 1.0221 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1359 - acc: 0.9687 - val_loss: 1.1977 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0470 - acc: 0.9906 - val_loss: 1.1425 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 1.2500 - val_acc: 0.6875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.2337 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4938 - acc: 0.3062 - val_loss: 1.2584 - val_acc: 0.5125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9811 - acc: 0.6000 - val_loss: 0.9938 - val_acc: 0.6375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8115 - acc: 0.6500 - val_loss: 1.0597 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5193 - acc: 0.8000 - val_loss: 0.9030 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2748 - acc: 0.9187 - val_loss: 0.8689 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1188 - acc: 0.9781 - val_loss: 0.8841 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0441 - acc: 0.9969 - val_loss: 0.9967 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.0227 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0244 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4942 - acc: 0.3250 - val_loss: 2.4332 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3672 - acc: 0.5187 - val_loss: 1.0760 - val_acc: 0.6125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0201 - acc: 0.5875 - val_loss: 1.1291 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5675 - acc: 0.7688 - val_loss: 1.2160 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4542 - acc: 0.8156 - val_loss: 1.5195 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1944 - acc: 0.9500 - val_loss: 1.1858 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0917 - acc: 0.9937 - val_loss: 1.2220 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0317 - acc: 1.0000 - val_loss: 1.3916 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.3580 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.3838 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5328 - acc: 0.2969 - val_loss: 1.2565 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2039 - acc: 0.5281 - val_loss: 1.3033 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8574 - acc: 0.6750 - val_loss: 1.1550 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5367 - acc: 0.8156 - val_loss: 1.0920 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2920 - acc: 0.9094 - val_loss: 1.1648 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1276 - acc: 0.9750 - val_loss: 1.3939 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0434 - acc: 0.9969 - val_loss: 1.2475 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 1.4542 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 1.4676 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 1.4419 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_113 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_223 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_113 (MaxPoolin (None, 1, 64, 15)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 1, 32, 64)         47104     \n",
            "_________________________________________________________________\n",
            "activation_224 (Activation)  (None, 1, 32, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_114 (MaxPoolin (None, 1, 32, 31)         0         \n",
            "_________________________________________________________________\n",
            "flatten_56 (Flatten)         (None, 992)               0         \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 128)               127104    \n",
            "_________________________________________________________________\n",
            "activation_225 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_226 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,197,605\n",
            "Trainable params: 2,197,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(1, 2), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(1, 2), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 18ms/step - loss: 11.9109 - acc: 0.1906 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.6482 - acc: 0.2125 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.8383 - acc: 0.2250 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.9941 - acc: 0.2156 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.6665 - acc: 0.2531 - val_loss: 8.9329 - val_acc: 0.1500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.8869 - acc: 0.3031 - val_loss: 1.6594 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4116 - acc: 0.4000 - val_loss: 1.0617 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1319 - acc: 0.5344 - val_loss: 1.1110 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9499 - acc: 0.6344 - val_loss: 1.0329 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7383 - acc: 0.6781 - val_loss: 1.2189 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5990 - acc: 0.7750 - val_loss: 1.2657 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4909 - acc: 0.7875 - val_loss: 1.4483 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3812 - acc: 0.8469 - val_loss: 1.2902 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2143 - acc: 0.9219 - val_loss: 1.3439 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.0229 - acc: 0.2687 - val_loss: 3.6749 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.5211 - acc: 0.3188 - val_loss: 1.2453 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1824 - acc: 0.5531 - val_loss: 1.6868 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9225 - acc: 0.6281 - val_loss: 0.8868 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7261 - acc: 0.7188 - val_loss: 0.8692 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5697 - acc: 0.7969 - val_loss: 0.8093 - val_acc: 0.7000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4793 - acc: 0.8406 - val_loss: 1.0156 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3358 - acc: 0.8875 - val_loss: 0.8884 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2578 - acc: 0.9062 - val_loss: 1.0251 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1793 - acc: 0.9625 - val_loss: 1.1013 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2114 - acc: 0.3062 - val_loss: 6.2106 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.0593 - acc: 0.4281 - val_loss: 1.4498 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1514 - acc: 0.5438 - val_loss: 1.0953 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0627 - acc: 0.6156 - val_loss: 1.0665 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7463 - acc: 0.7219 - val_loss: 0.9062 - val_acc: 0.6750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5329 - acc: 0.7937 - val_loss: 1.1771 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4058 - acc: 0.8406 - val_loss: 1.2290 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2454 - acc: 0.9156 - val_loss: 1.4224 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1041 - acc: 0.9719 - val_loss: 1.2580 - val_acc: 0.6750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0550 - acc: 0.9937 - val_loss: 1.4348 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.5350 - acc: 0.2594 - val_loss: 3.2627 - val_acc: 0.4375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.3141 - acc: 0.3063 - val_loss: 1.7989 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4717 - acc: 0.3937 - val_loss: 1.2925 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1942 - acc: 0.5312 - val_loss: 1.0176 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0726 - acc: 0.5469 - val_loss: 0.9741 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8390 - acc: 0.6813 - val_loss: 0.8464 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6800 - acc: 0.7344 - val_loss: 0.7783 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6101 - acc: 0.7656 - val_loss: 1.0114 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5550 - acc: 0.7937 - val_loss: 1.1560 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4294 - acc: 0.8312 - val_loss: 0.9728 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2108 - acc: 0.2719 - val_loss: 2.2126 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1907 - acc: 0.3812 - val_loss: 1.8754 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3067 - acc: 0.4750 - val_loss: 0.9672 - val_acc: 0.6250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0145 - acc: 0.6188 - val_loss: 0.9236 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7560 - acc: 0.7156 - val_loss: 0.7991 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7093 - acc: 0.7344 - val_loss: 0.8339 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4777 - acc: 0.8344 - val_loss: 0.9029 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3058 - acc: 0.9156 - val_loss: 0.8679 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1721 - acc: 0.9594 - val_loss: 0.9577 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1208 - acc: 0.9750 - val_loss: 1.0078 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_115 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_227 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_115 (MaxPoolin (None, 1, 32, 30)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 1, 16, 64)         94144     \n",
            "_________________________________________________________________\n",
            "activation_228 (Activation)  (None, 1, 16, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_116 (MaxPoolin (None, 1, 8, 62)          0         \n",
            "_________________________________________________________________\n",
            "flatten_57 (Flatten)         (None, 496)               0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 128)               63616     \n",
            "_________________________________________________________________\n",
            "activation_229 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_230 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,181,157\n",
            "Trainable params: 2,181,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(2, 1), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(2, 1), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 19ms/step - loss: 11.5397 - acc: 0.2094 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.6909 - acc: 0.1906 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.0707 - acc: 0.2500 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 6.4518 - acc: 0.3281 - val_loss: 9.7319 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.0733 - acc: 0.2406 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.3784 - acc: 0.2750 - val_loss: 6.2775 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.6578 - acc: 0.2750 - val_loss: 6.7240 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.5016 - acc: 0.2688 - val_loss: 1.5419 - val_acc: 0.2875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5341 - acc: 0.3125 - val_loss: 1.5192 - val_acc: 0.2500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3974 - acc: 0.4063 - val_loss: 1.4067 - val_acc: 0.4125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2502 - acc: 0.4656 - val_loss: 1.3161 - val_acc: 0.4500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1282 - acc: 0.5031 - val_loss: 2.0286 - val_acc: 0.3500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0143 - acc: 0.5594 - val_loss: 1.3175 - val_acc: 0.5125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8993 - acc: 0.6125 - val_loss: 1.5664 - val_acc: 0.4875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7512 - acc: 0.6719 - val_loss: 1.4890 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 5.5914 - acc: 0.2500 - val_loss: 9.0910 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.5847 - acc: 0.3531 - val_loss: 10.0343 - val_acc: 0.3500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0815 - acc: 0.3562 - val_loss: 9.4985 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.8264 - acc: 0.3875 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0645 - acc: 0.3094 - val_loss: 9.6593 - val_acc: 0.4000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.9740 - acc: 0.3812 - val_loss: 10.6782 - val_acc: 0.3375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0234 - acc: 0.3781 - val_loss: 10.6215 - val_acc: 0.3375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0234 - acc: 0.3781 - val_loss: 10.5030 - val_acc: 0.3375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0234 - acc: 0.3781 - val_loss: 10.4595 - val_acc: 0.3375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.0234 - acc: 0.3781 - val_loss: 10.4483 - val_acc: 0.3375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8578 - acc: 0.3187 - val_loss: 6.6611 - val_acc: 0.3000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.6058 - acc: 0.4187 - val_loss: 2.0000 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4231 - acc: 0.5031 - val_loss: 1.1097 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9664 - acc: 0.6312 - val_loss: 0.9819 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6764 - acc: 0.7344 - val_loss: 1.2184 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4190 - acc: 0.8625 - val_loss: 1.1515 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2658 - acc: 0.9000 - val_loss: 2.3637 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2612 - acc: 0.9219 - val_loss: 1.4170 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0941 - acc: 0.9750 - val_loss: 1.5314 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0247 - acc: 0.9969 - val_loss: 1.5180 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.7218 - acc: 0.3406 - val_loss: 5.1610 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.1148 - acc: 0.3531 - val_loss: 1.7965 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0885 - acc: 0.5938 - val_loss: 1.4380 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7239 - acc: 0.6938 - val_loss: 1.3489 - val_acc: 0.4875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4307 - acc: 0.8375 - val_loss: 1.2985 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1831 - acc: 0.9375 - val_loss: 1.3862 - val_acc: 0.6125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1718 - acc: 0.9437 - val_loss: 1.5526 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0616 - acc: 0.9875 - val_loss: 1.6706 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 1.5602 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.8632 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2231 - acc: 0.3469 - val_loss: 1.5379 - val_acc: 0.5125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7290 - acc: 0.4219 - val_loss: 1.1749 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2343 - acc: 0.5313 - val_loss: 1.1196 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9916 - acc: 0.6188 - val_loss: 1.2217 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5791 - acc: 0.7594 - val_loss: 1.4342 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2917 - acc: 0.8937 - val_loss: 1.3503 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1399 - acc: 0.9531 - val_loss: 1.4759 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0691 - acc: 0.9750 - val_loss: 1.2985 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0218 - acc: 1.0000 - val_loss: 1.4696 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.4584 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_117 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_231 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_117 (MaxPoolin (None, 1, 22, 30)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 1, 11, 64)         94144     \n",
            "_________________________________________________________________\n",
            "activation_232 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_118 (MaxPoolin (None, 1, 4, 62)          0         \n",
            "_________________________________________________________________\n",
            "flatten_58 (Flatten)         (None, 248)               0         \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 128)               31872     \n",
            "_________________________________________________________________\n",
            "activation_233 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_234 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,149,413\n",
            "Trainable params: 2,149,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 1), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 1), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 19ms/step - loss: 11.5612 - acc: 0.1969 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.1740 - acc: 0.2125 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.5920 - acc: 0.2094 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 3.2042 - acc: 0.2844 - val_loss: 6.9315 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.4589 - acc: 0.3031 - val_loss: 10.9391 - val_acc: 0.3000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.8074 - acc: 0.2594 - val_loss: 11.7085 - val_acc: 0.2625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8850 - val_acc: 0.2625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8888 - val_acc: 0.2625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8903 - val_acc: 0.2625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8909 - val_acc: 0.2625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8910 - val_acc: 0.2625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8910 - val_acc: 0.2625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 11.8910 - val_acc: 0.2625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.7955 - acc: 0.2969 - val_loss: 3.9560 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.7670 - acc: 0.3469 - val_loss: 3.0684 - val_acc: 0.4500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8187 - acc: 0.4562 - val_loss: 1.3016 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0849 - acc: 0.5688 - val_loss: 1.1656 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8131 - acc: 0.6969 - val_loss: 1.0666 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7182 - acc: 0.7094 - val_loss: 1.1433 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4625 - acc: 0.8156 - val_loss: 1.2360 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3562 - acc: 0.8937 - val_loss: 1.0938 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2121 - acc: 0.9469 - val_loss: 1.4621 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1959 - acc: 0.9250 - val_loss: 1.4025 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9720 - acc: 0.3375 - val_loss: 2.9757 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.9643 - acc: 0.4219 - val_loss: 1.8027 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3607 - acc: 0.5688 - val_loss: 1.1127 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8118 - acc: 0.6781 - val_loss: 1.0185 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5860 - acc: 0.8063 - val_loss: 1.0289 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3767 - acc: 0.8562 - val_loss: 1.2371 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1636 - acc: 0.9562 - val_loss: 1.3715 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0766 - acc: 0.9875 - val_loss: 1.4903 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0295 - acc: 0.9969 - val_loss: 1.5369 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0129 - acc: 0.9969 - val_loss: 1.4183 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7172 - acc: 0.3812 - val_loss: 2.5137 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1305 - acc: 0.4563 - val_loss: 1.3028 - val_acc: 0.5750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9737 - acc: 0.6563 - val_loss: 1.1355 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6215 - acc: 0.7594 - val_loss: 0.9144 - val_acc: 0.6875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3306 - acc: 0.8719 - val_loss: 1.2565 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2398 - acc: 0.9187 - val_loss: 1.1526 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0579 - acc: 0.9906 - val_loss: 1.0163 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0213 - acc: 0.9969 - val_loss: 1.3782 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.2414 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.1785 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7066 - acc: 0.3094 - val_loss: 4.6351 - val_acc: 0.3375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2948 - acc: 0.3906 - val_loss: 1.1526 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2435 - acc: 0.5594 - val_loss: 1.3103 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7552 - acc: 0.7031 - val_loss: 0.9648 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5010 - acc: 0.8125 - val_loss: 0.9016 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2394 - acc: 0.9125 - val_loss: 0.9251 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1082 - acc: 0.9719 - val_loss: 0.8869 - val_acc: 0.7000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0496 - acc: 0.9969 - val_loss: 1.0001 - val_acc: 0.7125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.9885 - val_acc: 0.7125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.9493 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5812 - acc: 0.3344 - val_loss: 2.0277 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6314 - acc: 0.5000 - val_loss: 2.5011 - val_acc: 0.3125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1997 - acc: 0.5719 - val_loss: 1.1711 - val_acc: 0.6375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6960 - acc: 0.7438 - val_loss: 0.8805 - val_acc: 0.7000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3185 - acc: 0.9062 - val_loss: 1.6309 - val_acc: 0.5250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1511 - acc: 0.9437 - val_loss: 1.0201 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0451 - acc: 1.0000 - val_loss: 1.1907 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.2390 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.4028 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.3158 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_119 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_235 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_119 (MaxPoolin (None, 1, 64, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 1, 32, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_236 (Activation)  (None, 1, 32, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_120 (MaxPoolin (None, 1, 32, 21)         0         \n",
            "_________________________________________________________________\n",
            "flatten_59 (Flatten)         (None, 672)               0         \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 128)               86144     \n",
            "_________________________________________________________________\n",
            "activation_237 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_238 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,140,965\n",
            "Trainable params: 2,140,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(1, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(1, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 6s 20ms/step - loss: 12.0102 - acc: 0.2156 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.5471 - acc: 0.2125 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.7236 - acc: 0.2656 - val_loss: 11.8890 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.5088 - acc: 0.2687 - val_loss: 12.8366 - val_acc: 0.2000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.4338 - acc: 0.2906 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.8294 - acc: 0.3281 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.8059 - acc: 0.3250 - val_loss: 11.0812 - val_acc: 0.3125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.1116 - acc: 0.3094 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0308 - acc: 0.3156 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0308 - acc: 0.3156 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0308 - acc: 0.3156 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0308 - acc: 0.3156 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.3236 - acc: 0.2281 - val_loss: 4.2210 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6913 - acc: 0.5156 - val_loss: 1.2406 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0765 - acc: 0.5750 - val_loss: 1.2709 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8987 - acc: 0.6500 - val_loss: 0.8075 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6306 - acc: 0.7500 - val_loss: 0.8882 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5361 - acc: 0.7937 - val_loss: 1.0503 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3973 - acc: 0.8469 - val_loss: 1.0300 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3000 - acc: 0.8937 - val_loss: 1.0539 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2135 - acc: 0.9281 - val_loss: 1.0604 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1069 - acc: 0.9719 - val_loss: 1.1026 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2498 - acc: 0.3219 - val_loss: 1.9713 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.2683 - acc: 0.4969 - val_loss: 1.3811 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0959 - acc: 0.5969 - val_loss: 1.1880 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0275 - acc: 0.5688 - val_loss: 1.1594 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6645 - acc: 0.7656 - val_loss: 1.1968 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5478 - acc: 0.8125 - val_loss: 1.0262 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3290 - acc: 0.9125 - val_loss: 1.2328 - val_acc: 0.5250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2104 - acc: 0.9500 - val_loss: 1.0658 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1002 - acc: 0.9750 - val_loss: 1.2401 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0992 - acc: 0.9812 - val_loss: 1.3276 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7006 - acc: 0.3188 - val_loss: 1.5354 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6270 - acc: 0.4312 - val_loss: 1.0681 - val_acc: 0.5375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9323 - acc: 0.6594 - val_loss: 1.3097 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6485 - acc: 0.7750 - val_loss: 1.6273 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4528 - acc: 0.8437 - val_loss: 1.1251 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2388 - acc: 0.9187 - val_loss: 1.5504 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1621 - acc: 0.9344 - val_loss: 1.3562 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0598 - acc: 0.9812 - val_loss: 1.7383 - val_acc: 0.5250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0431 - acc: 0.9844 - val_loss: 1.5659 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0299 - acc: 0.9969 - val_loss: 1.4920 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5323 - acc: 0.3781 - val_loss: 1.7584 - val_acc: 0.3750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6003 - acc: 0.4656 - val_loss: 1.5326 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2525 - acc: 0.5562 - val_loss: 1.2029 - val_acc: 0.6375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9505 - acc: 0.6438 - val_loss: 1.1367 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6024 - acc: 0.7813 - val_loss: 1.2120 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3238 - acc: 0.8906 - val_loss: 0.9700 - val_acc: 0.6875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1657 - acc: 0.9437 - val_loss: 1.1696 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0693 - acc: 0.9844 - val_loss: 1.5086 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0481 - acc: 0.9875 - val_loss: 1.4105 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0321 - acc: 0.9969 - val_loss: 1.8216 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5570 - acc: 0.3719 - val_loss: 3.2308 - val_acc: 0.1750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7169 - acc: 0.4500 - val_loss: 1.5347 - val_acc: 0.4125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2436 - acc: 0.5406 - val_loss: 1.2212 - val_acc: 0.4500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8377 - acc: 0.6938 - val_loss: 1.3972 - val_acc: 0.4625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5698 - acc: 0.7844 - val_loss: 1.4011 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3136 - acc: 0.9000 - val_loss: 1.0666 - val_acc: 0.6500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1689 - acc: 0.9687 - val_loss: 1.2959 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0890 - acc: 0.9781 - val_loss: 1.3677 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0949 - acc: 0.9750 - val_loss: 1.3108 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0643 - acc: 0.9781 - val_loss: 1.6228 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6049 - acc: 0.3438 - val_loss: 1.1658 - val_acc: 0.5625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1488 - acc: 0.5125 - val_loss: 1.4532 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8213 - acc: 0.7000 - val_loss: 1.1184 - val_acc: 0.6125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7942 - acc: 0.6938 - val_loss: 1.0306 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3385 - acc: 0.9031 - val_loss: 0.8740 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2526 - acc: 0.9219 - val_loss: 0.8909 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0694 - acc: 0.9969 - val_loss: 1.0751 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0250 - acc: 0.9969 - val_loss: 1.1009 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1493 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.1553 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsW8Dnpm7sZt",
        "colab_type": "code",
        "outputId": "896e0da1-2aaf-415c-ec2d-81ef08d7e5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "score_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Parameter</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Kernel Size: (3, 3)</td>\n",
              "      <td>0.473333</td>\n",
              "      <td>1.981357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Kernel Size: (5, 5)</td>\n",
              "      <td>0.565556</td>\n",
              "      <td>1.611662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Kernel Size: (7, 7)</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>1.577976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Kernel Size: (1, 5)</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>1.530358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Kernel Size: (5, 1)</td>\n",
              "      <td>0.368889</td>\n",
              "      <td>1.725819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Kernel Size: (1, 7)</td>\n",
              "      <td>0.557778</td>\n",
              "      <td>1.488459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>Kernel Size: (7, 1)</td>\n",
              "      <td>0.407778</td>\n",
              "      <td>1.746344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Conv Strides: (1, 1)</td>\n",
              "      <td>0.504444</td>\n",
              "      <td>5.114644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.0</td>\n",
              "      <td>Conv Strides: (2, 2)</td>\n",
              "      <td>0.595556</td>\n",
              "      <td>1.339987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Conv Strides: (3, 3)</td>\n",
              "      <td>0.602222</td>\n",
              "      <td>1.447754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10.0</td>\n",
              "      <td>Conv Strides: (1, 2)</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>1.342004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11.0</td>\n",
              "      <td>Conv Strides: (2, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.748762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12.0</td>\n",
              "      <td>Conv Strides: (3, 1)</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>3.823076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13.0</td>\n",
              "      <td>Conv Strides: (1, 3)</td>\n",
              "      <td>0.563333</td>\n",
              "      <td>1.780330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x32</td>\n",
              "      <td>0.608889</td>\n",
              "      <td>1.293163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x64</td>\n",
              "      <td>0.596667</td>\n",
              "      <td>1.311897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 32x128</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.443874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x32</td>\n",
              "      <td>0.544444</td>\n",
              "      <td>1.366712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x64</td>\n",
              "      <td>0.521111</td>\n",
              "      <td>3.820026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 64x128</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>3.871442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x32</td>\n",
              "      <td>0.465556</td>\n",
              "      <td>4.841143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x64</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>6.063469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Batch Size: 128x128</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.894476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (1, 1)</td>\n",
              "      <td>0.597778</td>\n",
              "      <td>1.630594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (2, 2)</td>\n",
              "      <td>0.618889</td>\n",
              "      <td>1.368143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (3, 3)</td>\n",
              "      <td>0.597778</td>\n",
              "      <td>1.454984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (1, 2)</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>1.454244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (2, 1)</td>\n",
              "      <td>0.596667</td>\n",
              "      <td>1.507703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (1, 3)</td>\n",
              "      <td>0.625556</td>\n",
              "      <td>1.394259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Size: (3, 1)</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>1.927103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (1, 1)</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>9.156230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (2, 2)</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>5.056599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (3, 3)</td>\n",
              "      <td>0.634444</td>\n",
              "      <td>1.388664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (1, 2)</td>\n",
              "      <td>0.446667</td>\n",
              "      <td>6.416065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (2, 1)</td>\n",
              "      <td>0.394444</td>\n",
              "      <td>7.499729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (3, 1)</td>\n",
              "      <td>0.421111</td>\n",
              "      <td>6.554874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Pool Strides: (1, 3)</td>\n",
              "      <td>0.496667</td>\n",
              "      <td>5.110957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0             Parameter  Accuracy       Loss\n",
              "0          0.0   Kernel Size: (3, 3)  0.473333   1.981357\n",
              "1          1.0   Kernel Size: (5, 5)  0.565556   1.611662\n",
              "2          2.0   Kernel Size: (7, 7)  0.588889   1.577976\n",
              "3          3.0   Kernel Size: (1, 5)  0.533333   1.530358\n",
              "4          4.0   Kernel Size: (5, 1)  0.368889   1.725819\n",
              "5          5.0   Kernel Size: (1, 7)  0.557778   1.488459\n",
              "6          6.0   Kernel Size: (7, 1)  0.407778   1.746344\n",
              "7          7.0  Conv Strides: (1, 1)  0.504444   5.114644\n",
              "8          8.0  Conv Strides: (2, 2)  0.595556   1.339987\n",
              "9          9.0  Conv Strides: (3, 3)  0.602222   1.447754\n",
              "10        10.0  Conv Strides: (1, 2)  0.610000   1.342004\n",
              "11        11.0  Conv Strides: (2, 1)  0.528889   3.748762\n",
              "12        12.0  Conv Strides: (3, 1)  0.528889   3.823076\n",
              "13        13.0  Conv Strides: (1, 3)  0.563333   1.780330\n",
              "14         NaN     Batch Size: 32x32  0.608889   1.293163\n",
              "15         NaN     Batch Size: 32x64  0.596667   1.311897\n",
              "16         NaN    Batch Size: 32x128  0.600000   1.443874\n",
              "17         NaN     Batch Size: 64x32  0.544444   1.366712\n",
              "18         NaN     Batch Size: 64x64  0.521111   3.820026\n",
              "19         NaN    Batch Size: 64x128  0.533333   3.871442\n",
              "20         NaN    Batch Size: 128x32  0.465556   4.841143\n",
              "21         NaN    Batch Size: 128x64  0.472222   6.063469\n",
              "22         NaN   Batch Size: 128x128  0.200000  12.894476\n",
              "23         NaN     Pool Size: (1, 1)  0.597778   1.630594\n",
              "24         NaN     Pool Size: (2, 2)  0.618889   1.368143\n",
              "25         NaN     Pool Size: (3, 3)  0.597778   1.454984\n",
              "26         NaN     Pool Size: (1, 2)  0.613333   1.454244\n",
              "27         NaN     Pool Size: (2, 1)  0.596667   1.507703\n",
              "28         NaN     Pool Size: (1, 3)  0.625556   1.394259\n",
              "29         NaN     Pool Size: (3, 1)  0.573333   1.927103\n",
              "30         NaN  Pool Strides: (1, 1)  0.220000   9.156230\n",
              "31         NaN  Pool Strides: (2, 2)  0.488889   5.056599\n",
              "32         NaN  Pool Strides: (3, 3)  0.634444   1.388664\n",
              "33         NaN  Pool Strides: (1, 2)  0.446667   6.416065\n",
              "34         NaN  Pool Strides: (2, 1)  0.394444   7.499729\n",
              "35         NaN  Pool Strides: (3, 1)  0.421111   6.554874\n",
              "36         NaN  Pool Strides: (1, 3)  0.496667   5.110957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba20fdTvTIwn",
        "colab_type": "code",
        "outputId": "938bb51a-3a35-45d2-fbfa-7e242577309f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pool_stride = (3, 3)\n",
        "\n",
        "parameter = 'Dense: '\n",
        "dense_sizes = [128, 256, 512]\n",
        "\n",
        "for dense in dense_sizes:\n",
        "  train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "  parameter_name = parameter+str(dense)\n",
        "  parameter_acc = np.mean(test_accuracy)\n",
        "  parameter_loss = np.mean(test_loss)\n",
        "  score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_121 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_239 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_121 (MaxPoolin (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_240 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_122 (MaxPoolin (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_60 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 128)               10880     \n",
            "_________________________________________________________________\n",
            "activation_241 (Activation)  (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_242 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,065,701\n",
            "Trainable params: 2,065,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 7s 21ms/step - loss: 6.6372 - acc: 0.2906 - val_loss: 9.3700 - val_acc: 0.2750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 6.4024 - acc: 0.4625 - val_loss: 4.6776 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 4.5879 - acc: 0.5250 - val_loss: 2.5616 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5238 - acc: 0.4719 - val_loss: 1.4839 - val_acc: 0.3625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9034 - acc: 0.6313 - val_loss: 1.3771 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6200 - acc: 0.7563 - val_loss: 1.2664 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4047 - acc: 0.8406 - val_loss: 1.2333 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3588 - acc: 0.8781 - val_loss: 1.2413 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2103 - acc: 0.9500 - val_loss: 1.5303 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0921 - acc: 0.9781 - val_loss: 1.5903 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8931 - acc: 0.3594 - val_loss: 2.0028 - val_acc: 0.4250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3657 - acc: 0.5000 - val_loss: 1.5380 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2163 - acc: 0.5625 - val_loss: 1.4449 - val_acc: 0.4625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6270 - acc: 0.7719 - val_loss: 1.1279 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4723 - acc: 0.8375 - val_loss: 1.0179 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2029 - acc: 0.9375 - val_loss: 1.1660 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1178 - acc: 0.9750 - val_loss: 1.2827 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0560 - acc: 0.9812 - val_loss: 1.3126 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0219 - acc: 0.9969 - val_loss: 1.3528 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.3863 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.7138 - acc: 0.3187 - val_loss: 1.6531 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2929 - acc: 0.5313 - val_loss: 1.2875 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9525 - acc: 0.6188 - val_loss: 1.5457 - val_acc: 0.4375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6679 - acc: 0.7563 - val_loss: 1.2049 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3120 - acc: 0.8969 - val_loss: 1.2217 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1383 - acc: 0.9719 - val_loss: 1.5040 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0595 - acc: 0.9937 - val_loss: 1.5437 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.5098 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.6211 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.6262 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4290 - acc: 0.3687 - val_loss: 1.0916 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0773 - acc: 0.5781 - val_loss: 0.9467 - val_acc: 0.6750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7890 - acc: 0.7000 - val_loss: 0.8729 - val_acc: 0.6500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4516 - acc: 0.8563 - val_loss: 0.9049 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2813 - acc: 0.9031 - val_loss: 0.8644 - val_acc: 0.6875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1271 - acc: 0.9656 - val_loss: 0.8642 - val_acc: 0.7250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0676 - acc: 1.0000 - val_loss: 0.9167 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 1.0256 - val_acc: 0.6750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.9549 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0240 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5045 - acc: 0.2938 - val_loss: 1.2120 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0992 - acc: 0.5781 - val_loss: 1.0427 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8432 - acc: 0.6688 - val_loss: 1.0344 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5676 - acc: 0.8344 - val_loss: 0.9094 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3579 - acc: 0.8875 - val_loss: 0.9266 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1635 - acc: 0.9531 - val_loss: 1.1329 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0815 - acc: 0.9969 - val_loss: 0.9091 - val_acc: 0.6250\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0352 - acc: 1.0000 - val_loss: 1.2203 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.0142 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.1263 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4853 - acc: 0.3406 - val_loss: 2.0072 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4728 - acc: 0.4937 - val_loss: 1.4316 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8695 - acc: 0.6594 - val_loss: 1.2134 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5914 - acc: 0.7813 - val_loss: 0.9471 - val_acc: 0.6625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3396 - acc: 0.9000 - val_loss: 0.9839 - val_acc: 0.6750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1913 - acc: 0.9344 - val_loss: 1.4428 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1862 - acc: 0.9437 - val_loss: 0.9483 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0533 - acc: 0.9906 - val_loss: 0.9703 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 1.0781 - val_acc: 0.6875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1269 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4452 - acc: 0.3500 - val_loss: 1.1056 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0901 - acc: 0.5719 - val_loss: 0.8886 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9474 - acc: 0.6094 - val_loss: 0.9880 - val_acc: 0.6125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5553 - acc: 0.8000 - val_loss: 0.9442 - val_acc: 0.6500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2661 - acc: 0.9344 - val_loss: 0.8939 - val_acc: 0.7250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1223 - acc: 0.9812 - val_loss: 1.2586 - val_acc: 0.5750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0887 - acc: 0.9812 - val_loss: 0.8768 - val_acc: 0.6875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.9672 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.0881 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0201 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4486 - acc: 0.3156 - val_loss: 1.6067 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2734 - acc: 0.5375 - val_loss: 1.1285 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7875 - acc: 0.7000 - val_loss: 1.1439 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6192 - acc: 0.7469 - val_loss: 1.2973 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3162 - acc: 0.9000 - val_loss: 0.9980 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1437 - acc: 0.9656 - val_loss: 0.9591 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0811 - acc: 0.9844 - val_loss: 1.4075 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0467 - acc: 0.9906 - val_loss: 1.0544 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.0372 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.0577 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5039 - acc: 0.2906 - val_loss: 1.5602 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1200 - acc: 0.5469 - val_loss: 1.8249 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8020 - acc: 0.6938 - val_loss: 1.8451 - val_acc: 0.3375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5741 - acc: 0.7625 - val_loss: 1.0969 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2503 - acc: 0.9375 - val_loss: 1.2274 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1153 - acc: 0.9781 - val_loss: 1.3447 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0586 - acc: 0.9875 - val_loss: 1.1099 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0313 - acc: 0.9969 - val_loss: 1.4195 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 1.3513 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.3023 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_123 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_243 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_123 (MaxPoolin (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_244 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_124 (MaxPoolin (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_61 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_245 (Activation)  (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_246 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 7s 21ms/step - loss: 5.1206 - acc: 0.2406 - val_loss: 1.8781 - val_acc: 0.2625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4703 - acc: 0.3906 - val_loss: 1.6975 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5524 - acc: 0.2469 - val_loss: 1.5374 - val_acc: 0.3875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4474 - acc: 0.3656 - val_loss: 1.2798 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3241 - acc: 0.4562 - val_loss: 1.2489 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2471 - acc: 0.4875 - val_loss: 1.2737 - val_acc: 0.4625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2030 - acc: 0.5031 - val_loss: 1.3150 - val_acc: 0.5125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1642 - acc: 0.4969 - val_loss: 1.3445 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1063 - acc: 0.4937 - val_loss: 1.1662 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0370 - acc: 0.5312 - val_loss: 1.2440 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.8550 - acc: 0.3313 - val_loss: 1.7026 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4211 - acc: 0.4531 - val_loss: 1.2963 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9074 - acc: 0.6438 - val_loss: 1.3961 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7206 - acc: 0.7031 - val_loss: 1.3467 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4410 - acc: 0.8406 - val_loss: 1.0938 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1539 - acc: 0.9531 - val_loss: 1.4483 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0419 - acc: 0.9906 - val_loss: 1.4395 - val_acc: 0.5500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 1.5079 - val_acc: 0.5375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 1.5999 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.4560 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5646 - acc: 0.3500 - val_loss: 1.9441 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4477 - acc: 0.4812 - val_loss: 1.6978 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9577 - acc: 0.6094 - val_loss: 1.3887 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6704 - acc: 0.7281 - val_loss: 1.0677 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3828 - acc: 0.8844 - val_loss: 1.1698 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1542 - acc: 0.9563 - val_loss: 1.5424 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1114 - acc: 0.9625 - val_loss: 1.6567 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0287 - acc: 0.9969 - val_loss: 1.4676 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.4577 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.6067 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5432 - acc: 0.3375 - val_loss: 1.1523 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5314 - acc: 0.4812 - val_loss: 1.3328 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9660 - acc: 0.6031 - val_loss: 1.0204 - val_acc: 0.6500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8432 - acc: 0.6844 - val_loss: 0.9378 - val_acc: 0.6750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5527 - acc: 0.7750 - val_loss: 0.8990 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3045 - acc: 0.8906 - val_loss: 0.9894 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1126 - acc: 0.9719 - val_loss: 0.9782 - val_acc: 0.7000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0396 - acc: 0.9906 - val_loss: 1.4704 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 1.2899 - val_acc: 0.7375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.3826 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5386 - acc: 0.3344 - val_loss: 1.5803 - val_acc: 0.3250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0672 - acc: 0.5844 - val_loss: 1.0138 - val_acc: 0.5750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9729 - acc: 0.6594 - val_loss: 1.3583 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7490 - acc: 0.7031 - val_loss: 1.0072 - val_acc: 0.6375\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4816 - acc: 0.8094 - val_loss: 1.1073 - val_acc: 0.5750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2736 - acc: 0.9187 - val_loss: 1.2723 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1130 - acc: 0.9625 - val_loss: 0.9325 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 1.0662 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.1233 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.0947 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5136 - acc: 0.3656 - val_loss: 1.3827 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2836 - acc: 0.4844 - val_loss: 1.0934 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9760 - acc: 0.6063 - val_loss: 1.0410 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6422 - acc: 0.7656 - val_loss: 0.9617 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3866 - acc: 0.8625 - val_loss: 0.8155 - val_acc: 0.7125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2015 - acc: 0.9406 - val_loss: 1.0013 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1158 - acc: 0.9844 - val_loss: 0.8334 - val_acc: 0.6625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0585 - acc: 0.9875 - val_loss: 0.8988 - val_acc: 0.7375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0243 - acc: 0.9969 - val_loss: 0.9535 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.0035 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5033 - acc: 0.3500 - val_loss: 1.4661 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3110 - acc: 0.5406 - val_loss: 1.0096 - val_acc: 0.5625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7995 - acc: 0.6875 - val_loss: 1.0603 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7037 - acc: 0.7312 - val_loss: 1.0653 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3743 - acc: 0.8812 - val_loss: 1.0240 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1545 - acc: 0.9687 - val_loss: 0.9955 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0580 - acc: 0.9937 - val_loss: 1.1996 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0272 - acc: 0.9969 - val_loss: 1.3593 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.2486 - val_acc: 0.5875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.3017 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5396 - acc: 0.3281 - val_loss: 1.3521 - val_acc: 0.3625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0565 - acc: 0.5781 - val_loss: 1.8005 - val_acc: 0.3875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9809 - acc: 0.6031 - val_loss: 1.5949 - val_acc: 0.4875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7215 - acc: 0.7188 - val_loss: 1.1726 - val_acc: 0.5875\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4192 - acc: 0.8562 - val_loss: 0.9801 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2785 - acc: 0.9062 - val_loss: 1.3132 - val_acc: 0.5375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1134 - acc: 0.9719 - val_loss: 1.1392 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0419 - acc: 0.9969 - val_loss: 1.0908 - val_acc: 0.6625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 1.1846 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.0851 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4766 - acc: 0.3406 - val_loss: 1.2681 - val_acc: 0.4625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0962 - acc: 0.5563 - val_loss: 1.2818 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8715 - acc: 0.6594 - val_loss: 1.6582 - val_acc: 0.4000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6947 - acc: 0.7781 - val_loss: 1.3144 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4878 - acc: 0.8031 - val_loss: 1.2264 - val_acc: 0.5375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2896 - acc: 0.9187 - val_loss: 0.9126 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0964 - acc: 0.9906 - val_loss: 1.1012 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0380 - acc: 0.9906 - val_loss: 1.1520 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 1.2840 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.2462 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_125 (Conv2D)          (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_247 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_125 (MaxPoolin (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_126 (Conv2D)          (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_248 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_126 (MaxPoolin (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_62 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 512)               43520     \n",
            "_________________________________________________________________\n",
            "activation_249 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_250 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,100,261\n",
            "Trainable params: 2,100,261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 7s 21ms/step - loss: 2.5304 - acc: 0.2656 - val_loss: 1.5314 - val_acc: 0.2250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5114 - acc: 0.3812 - val_loss: 1.5283 - val_acc: 0.2750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4908 - acc: 0.3312 - val_loss: 1.5414 - val_acc: 0.2750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4351 - acc: 0.3625 - val_loss: 1.4410 - val_acc: 0.3500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3906 - acc: 0.3594 - val_loss: 1.4390 - val_acc: 0.3000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3613 - acc: 0.3750 - val_loss: 1.3836 - val_acc: 0.3125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2655 - acc: 0.4125 - val_loss: 1.4177 - val_acc: 0.4000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2781 - acc: 0.3906 - val_loss: 1.3972 - val_acc: 0.4125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2361 - acc: 0.4312 - val_loss: 1.6134 - val_acc: 0.2875\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2192 - acc: 0.4281 - val_loss: 1.4139 - val_acc: 0.3875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 2.1918 - acc: 0.2875 - val_loss: 1.2043 - val_acc: 0.5125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1878 - acc: 0.4969 - val_loss: 1.2904 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1824 - acc: 0.5312 - val_loss: 1.0931 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9327 - acc: 0.6313 - val_loss: 0.9847 - val_acc: 0.6625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6459 - acc: 0.7375 - val_loss: 0.9072 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3793 - acc: 0.8687 - val_loss: 0.9243 - val_acc: 0.7125\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2257 - acc: 0.9375 - val_loss: 1.0828 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0740 - acc: 0.9812 - val_loss: 1.2598 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0271 - acc: 0.9906 - val_loss: 1.4617 - val_acc: 0.6625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0221 - acc: 0.9969 - val_loss: 1.5272 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.6963 - acc: 0.3062 - val_loss: 1.7999 - val_acc: 0.4125\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5205 - acc: 0.4562 - val_loss: 1.5747 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.1318 - acc: 0.5625 - val_loss: 1.1259 - val_acc: 0.5250\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8797 - acc: 0.6562 - val_loss: 0.9648 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.5377 - acc: 0.8000 - val_loss: 0.9216 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2258 - acc: 0.9406 - val_loss: 0.9422 - val_acc: 0.6625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0779 - acc: 0.9875 - val_loss: 1.0750 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0376 - acc: 0.9937 - val_loss: 1.5445 - val_acc: 0.6875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.5379 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.3669 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4167 - acc: 0.3469 - val_loss: 1.1875 - val_acc: 0.5625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1879 - acc: 0.5375 - val_loss: 1.1965 - val_acc: 0.4750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8315 - acc: 0.6906 - val_loss: 1.4454 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5709 - acc: 0.8000 - val_loss: 1.1911 - val_acc: 0.6125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2246 - acc: 0.9156 - val_loss: 1.3815 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0995 - acc: 0.9719 - val_loss: 1.7308 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0334 - acc: 0.9906 - val_loss: 1.8945 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0397 - acc: 0.9906 - val_loss: 1.8971 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0235 - acc: 0.9938 - val_loss: 2.3438 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 2.1236 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5056 - acc: 0.3031 - val_loss: 1.5690 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1951 - acc: 0.5219 - val_loss: 1.1430 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0857 - acc: 0.6250 - val_loss: 1.5794 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7089 - acc: 0.7281 - val_loss: 0.8132 - val_acc: 0.6625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3239 - acc: 0.8750 - val_loss: 1.3476 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1033 - acc: 0.9750 - val_loss: 0.8670 - val_acc: 0.7000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0352 - acc: 0.9937 - val_loss: 1.0709 - val_acc: 0.6875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1687 - val_acc: 0.7000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.1859 - val_acc: 0.7250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.2763 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5321 - acc: 0.3000 - val_loss: 1.2019 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0929 - acc: 0.5656 - val_loss: 1.5011 - val_acc: 0.4875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8696 - acc: 0.6563 - val_loss: 1.1323 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6091 - acc: 0.7875 - val_loss: 1.4093 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3928 - acc: 0.8844 - val_loss: 1.1725 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1729 - acc: 0.9406 - val_loss: 1.3953 - val_acc: 0.5500\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0919 - acc: 0.9594 - val_loss: 1.2870 - val_acc: 0.6750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0252 - acc: 0.9969 - val_loss: 1.7825 - val_acc: 0.5625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.6066 - val_acc: 0.5750\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.8404 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5371 - acc: 0.3125 - val_loss: 1.1620 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.2032 - acc: 0.5156 - val_loss: 1.3703 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8035 - acc: 0.6625 - val_loss: 1.0497 - val_acc: 0.5875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6452 - acc: 0.7469 - val_loss: 0.8883 - val_acc: 0.5250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.3117 - acc: 0.8937 - val_loss: 1.3032 - val_acc: 0.5125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1563 - acc: 0.9625 - val_loss: 1.1261 - val_acc: 0.6375\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0990 - acc: 0.9875 - val_loss: 1.2657 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0264 - acc: 0.9969 - val_loss: 1.4928 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0426 - acc: 0.9844 - val_loss: 1.5358 - val_acc: 0.6250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.3153 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5276 - acc: 0.3219 - val_loss: 1.2350 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2198 - acc: 0.5375 - val_loss: 1.0067 - val_acc: 0.5250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9341 - acc: 0.6125 - val_loss: 1.7224 - val_acc: 0.3875\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6972 - acc: 0.7344 - val_loss: 1.2308 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4399 - acc: 0.8406 - val_loss: 1.1659 - val_acc: 0.5625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.1307 - acc: 0.9719 - val_loss: 1.3448 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0437 - acc: 0.9906 - val_loss: 1.4614 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0160 - acc: 0.9969 - val_loss: 1.5769 - val_acc: 0.5750\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.5559 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.5706 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 1.5020 - acc: 0.3344 - val_loss: 1.1722 - val_acc: 0.5625\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1779 - acc: 0.5500 - val_loss: 1.3805 - val_acc: 0.4625\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9574 - acc: 0.6313 - val_loss: 1.1561 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6893 - acc: 0.7281 - val_loss: 1.3206 - val_acc: 0.4750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6212 - acc: 0.7781 - val_loss: 1.4271 - val_acc: 0.4875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2828 - acc: 0.9000 - val_loss: 1.5234 - val_acc: 0.5250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1099 - acc: 0.9656 - val_loss: 1.5374 - val_acc: 0.5375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0376 - acc: 0.9937 - val_loss: 1.6819 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0157 - acc: 0.9969 - val_loss: 1.6059 - val_acc: 0.5250\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 0s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.7564 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G_i6f_rdbJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_df = pd.read_csv('score_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rikj-ycR7scK",
        "colab_type": "code",
        "outputId": "57155749-be47-4394-a6e6-2522692ff21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dense = 256\n",
        "\n",
        "parameter = 'Epochs, Batch Size, Learning Rate: '\n",
        "epochs = [8, 12, 16]\n",
        "batch_sizes = [10, 25, 50]\n",
        "learning_rates = [0.0001, 0.001, 0.01]\n",
        "\n",
        "for n_epoch in epochs:\n",
        "  for batch_size in batch_sizes:\n",
        "    for lr in learning_rates:\n",
        "      optimizer = Adam(lr)\n",
        "      train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "      parameter_name = parameter+str(n_epoch)+\" \"+str(batch_size)+\" \"+str(lr)\n",
        "      parameter_acc = np.mean(test_accuracy)\n",
        "      parameter_loss = np.mean(test_loss)\n",
        "      score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)\n",
        "\n",
        "score_df.to_csv('score_df.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 7s 22ms/step - loss: 1.5345 - acc: 0.2781 - val_loss: 1.4304 - val_acc: 0.4250\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2662 - acc: 0.4906 - val_loss: 1.2112 - val_acc: 0.5375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0556 - acc: 0.5969 - val_loss: 1.1101 - val_acc: 0.5750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8972 - acc: 0.6844 - val_loss: 1.0155 - val_acc: 0.5625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7810 - acc: 0.7156 - val_loss: 0.9903 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6991 - acc: 0.7281 - val_loss: 0.9424 - val_acc: 0.6000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5937 - acc: 0.8031 - val_loss: 0.9202 - val_acc: 0.6125\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5119 - acc: 0.8531 - val_loss: 0.9319 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 3ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5535 - acc: 0.2281 - val_loss: 1.4488 - val_acc: 0.4000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2828 - acc: 0.4438 - val_loss: 1.2372 - val_acc: 0.4500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0583 - acc: 0.5531 - val_loss: 1.1055 - val_acc: 0.5250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9036 - acc: 0.6625 - val_loss: 1.1276 - val_acc: 0.4750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8157 - acc: 0.7063 - val_loss: 1.0728 - val_acc: 0.5750\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7387 - acc: 0.7313 - val_loss: 0.9992 - val_acc: 0.5875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5919 - acc: 0.8156 - val_loss: 0.9876 - val_acc: 0.6125\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5109 - acc: 0.8656 - val_loss: 0.9412 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5626 - acc: 0.2531 - val_loss: 1.4777 - val_acc: 0.3750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3493 - acc: 0.4188 - val_loss: 1.1873 - val_acc: 0.6125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1119 - acc: 0.5531 - val_loss: 1.0408 - val_acc: 0.6375\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9436 - acc: 0.6188 - val_loss: 0.9482 - val_acc: 0.6750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7989 - acc: 0.7156 - val_loss: 0.9452 - val_acc: 0.6000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7012 - acc: 0.7500 - val_loss: 0.9132 - val_acc: 0.6250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6149 - acc: 0.8156 - val_loss: 0.8718 - val_acc: 0.6750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5196 - acc: 0.8687 - val_loss: 0.8829 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5639 - acc: 0.2563 - val_loss: 1.5436 - val_acc: 0.2625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3887 - acc: 0.4688 - val_loss: 1.4076 - val_acc: 0.4000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1658 - acc: 0.5625 - val_loss: 1.2339 - val_acc: 0.5125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9703 - acc: 0.6563 - val_loss: 1.2224 - val_acc: 0.5000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8419 - acc: 0.7063 - val_loss: 1.1255 - val_acc: 0.5250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7103 - acc: 0.7531 - val_loss: 1.0055 - val_acc: 0.5375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6133 - acc: 0.7844 - val_loss: 1.0599 - val_acc: 0.5750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5414 - acc: 0.8125 - val_loss: 1.0360 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5773 - acc: 0.2406 - val_loss: 1.5124 - val_acc: 0.3000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4155 - acc: 0.4094 - val_loss: 1.3476 - val_acc: 0.4125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1856 - acc: 0.5500 - val_loss: 1.2065 - val_acc: 0.5000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9802 - acc: 0.6531 - val_loss: 1.1879 - val_acc: 0.5000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8405 - acc: 0.6844 - val_loss: 1.1798 - val_acc: 0.4875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7305 - acc: 0.7750 - val_loss: 1.0995 - val_acc: 0.5500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6264 - acc: 0.7750 - val_loss: 1.0835 - val_acc: 0.5625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5275 - acc: 0.8031 - val_loss: 1.1060 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5661 - acc: 0.2656 - val_loss: 1.5063 - val_acc: 0.3875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3806 - acc: 0.4844 - val_loss: 1.3543 - val_acc: 0.4125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1650 - acc: 0.5563 - val_loss: 1.1966 - val_acc: 0.4875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9748 - acc: 0.6813 - val_loss: 1.1314 - val_acc: 0.5250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8277 - acc: 0.7250 - val_loss: 1.0394 - val_acc: 0.5625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7071 - acc: 0.7687 - val_loss: 1.0008 - val_acc: 0.5500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5969 - acc: 0.8250 - val_loss: 1.0407 - val_acc: 0.5375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5274 - acc: 0.8500 - val_loss: 1.0574 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5494 - acc: 0.3219 - val_loss: 1.4731 - val_acc: 0.3000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3493 - acc: 0.4500 - val_loss: 1.2593 - val_acc: 0.4625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1232 - acc: 0.5656 - val_loss: 1.1086 - val_acc: 0.5625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9448 - acc: 0.6469 - val_loss: 0.9911 - val_acc: 0.6000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8367 - acc: 0.6844 - val_loss: 0.8849 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7184 - acc: 0.7563 - val_loss: 0.8229 - val_acc: 0.6750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6018 - acc: 0.8250 - val_loss: 0.9327 - val_acc: 0.6250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5589 - acc: 0.8500 - val_loss: 0.8283 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5622 - acc: 0.2063 - val_loss: 1.5290 - val_acc: 0.3125\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3830 - acc: 0.4188 - val_loss: 1.3572 - val_acc: 0.4000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1661 - acc: 0.5219 - val_loss: 1.2236 - val_acc: 0.4875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0364 - acc: 0.5875 - val_loss: 1.1612 - val_acc: 0.5000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8967 - acc: 0.6813 - val_loss: 1.0227 - val_acc: 0.6375\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7684 - acc: 0.7562 - val_loss: 1.0749 - val_acc: 0.5750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6736 - acc: 0.7969 - val_loss: 0.9314 - val_acc: 0.6500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5662 - acc: 0.8375 - val_loss: 0.9682 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5769 - acc: 0.1844 - val_loss: 1.4878 - val_acc: 0.3125\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3830 - acc: 0.4094 - val_loss: 1.3125 - val_acc: 0.4750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1156 - acc: 0.6031 - val_loss: 1.2082 - val_acc: 0.4750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9545 - acc: 0.6188 - val_loss: 1.0638 - val_acc: 0.5000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8258 - acc: 0.7063 - val_loss: 1.0226 - val_acc: 0.5375\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7036 - acc: 0.7719 - val_loss: 1.0887 - val_acc: 0.4750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6778 - acc: 0.7438 - val_loss: 1.0942 - val_acc: 0.5500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5989 - acc: 0.7812 - val_loss: 0.9393 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 1.4026 - acc: 0.3719 - val_loss: 1.2031 - val_acc: 0.4750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8583 - acc: 0.6656 - val_loss: 1.4364 - val_acc: 0.4875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5547 - acc: 0.7844 - val_loss: 1.1120 - val_acc: 0.6125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2949 - acc: 0.8969 - val_loss: 1.4640 - val_acc: 0.6500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1032 - acc: 0.9687 - val_loss: 1.5387 - val_acc: 0.6000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0356 - acc: 0.9969 - val_loss: 1.4705 - val_acc: 0.6125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.7130 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.7978 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5421 - acc: 0.3656 - val_loss: 1.0156 - val_acc: 0.6000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1999 - acc: 0.5594 - val_loss: 0.8062 - val_acc: 0.6500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7022 - acc: 0.7156 - val_loss: 0.7984 - val_acc: 0.7250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3447 - acc: 0.8812 - val_loss: 0.7866 - val_acc: 0.7125\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1094 - acc: 0.9750 - val_loss: 0.7855 - val_acc: 0.7500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.7708 - val_acc: 0.7625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8026 - val_acc: 0.7750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.8340 - val_acc: 0.7750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4365 - acc: 0.3813 - val_loss: 1.1337 - val_acc: 0.5625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0794 - acc: 0.5781 - val_loss: 1.3249 - val_acc: 0.4750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7930 - acc: 0.7031 - val_loss: 1.1416 - val_acc: 0.5750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5419 - acc: 0.7906 - val_loss: 1.0455 - val_acc: 0.6500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1407 - acc: 0.9531 - val_loss: 1.1396 - val_acc: 0.6375\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0358 - acc: 0.9969 - val_loss: 1.3611 - val_acc: 0.6500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.2002 - val_acc: 0.6500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.1472 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5878 - acc: 0.3563 - val_loss: 1.4170 - val_acc: 0.3750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2243 - acc: 0.5156 - val_loss: 1.5942 - val_acc: 0.4625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9037 - acc: 0.6438 - val_loss: 1.1448 - val_acc: 0.5375\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5151 - acc: 0.8062 - val_loss: 1.1382 - val_acc: 0.5375\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1940 - acc: 0.9375 - val_loss: 1.2400 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0739 - acc: 0.9844 - val_loss: 1.4004 - val_acc: 0.6000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0240 - acc: 0.9969 - val_loss: 1.6110 - val_acc: 0.6250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0198 - acc: 0.9969 - val_loss: 1.5179 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5590 - acc: 0.4094 - val_loss: 1.1951 - val_acc: 0.4625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0858 - acc: 0.5531 - val_loss: 1.3210 - val_acc: 0.5625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8493 - acc: 0.6500 - val_loss: 1.0543 - val_acc: 0.6250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5117 - acc: 0.8031 - val_loss: 1.2274 - val_acc: 0.5750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3259 - acc: 0.8875 - val_loss: 1.5377 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2640 - acc: 0.9344 - val_loss: 1.2524 - val_acc: 0.6375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0549 - acc: 0.9875 - val_loss: 1.6100 - val_acc: 0.6250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.6281 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4273 - acc: 0.3813 - val_loss: 1.3638 - val_acc: 0.4625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2437 - acc: 0.5563 - val_loss: 1.1114 - val_acc: 0.5625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8692 - acc: 0.6531 - val_loss: 1.1936 - val_acc: 0.5625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5414 - acc: 0.8094 - val_loss: 1.6453 - val_acc: 0.5000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2904 - acc: 0.8844 - val_loss: 1.3074 - val_acc: 0.5625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0716 - acc: 0.9875 - val_loss: 1.4817 - val_acc: 0.6375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 1.4880 - val_acc: 0.5625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.5932 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4075 - acc: 0.3813 - val_loss: 1.1863 - val_acc: 0.4625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9670 - acc: 0.6281 - val_loss: 1.2395 - val_acc: 0.5750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6789 - acc: 0.7437 - val_loss: 1.0278 - val_acc: 0.6125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2604 - acc: 0.9281 - val_loss: 1.5341 - val_acc: 0.5625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1057 - acc: 0.9719 - val_loss: 1.2409 - val_acc: 0.6125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0479 - acc: 0.9875 - val_loss: 1.3036 - val_acc: 0.6125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.3603 - val_acc: 0.6250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.4711 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6069 - acc: 0.3656 - val_loss: 1.1567 - val_acc: 0.5625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2880 - acc: 0.5188 - val_loss: 0.9672 - val_acc: 0.6000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8425 - acc: 0.6563 - val_loss: 1.0178 - val_acc: 0.5625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4858 - acc: 0.8250 - val_loss: 1.6497 - val_acc: 0.5625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2204 - acc: 0.9250 - val_loss: 1.4307 - val_acc: 0.6000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0814 - acc: 0.9875 - val_loss: 1.3099 - val_acc: 0.6125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.1122 - val_acc: 0.6375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.2292 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5397 - acc: 0.4063 - val_loss: 1.4027 - val_acc: 0.4625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2452 - acc: 0.5281 - val_loss: 1.0559 - val_acc: 0.5875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9169 - acc: 0.6156 - val_loss: 0.8158 - val_acc: 0.7000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5487 - acc: 0.7938 - val_loss: 0.8546 - val_acc: 0.7125\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2015 - acc: 0.9437 - val_loss: 1.0948 - val_acc: 0.7125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1075 - acc: 0.9594 - val_loss: 1.0701 - val_acc: 0.7000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0443 - acc: 0.9906 - val_loss: 1.1117 - val_acc: 0.7000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0334 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 12.9837 - acc: 0.1688 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.2471 - acc: 0.1781 - val_loss: 11.4841 - val_acc: 0.2875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8947 - acc: 0.1719 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.2774 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3765 - acc: 0.2063 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3343 - acc: 0.2063 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5352 - acc: 0.1844 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3673 - acc: 0.2063 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4899 - acc: 0.1813 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3527 - acc: 0.1906 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 5ms/step - loss: 1.5965 - acc: 0.2406 - val_loss: 1.5981 - val_acc: 0.2625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4680 - acc: 0.4375 - val_loss: 1.5521 - val_acc: 0.2375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3022 - acc: 0.5031 - val_loss: 1.4493 - val_acc: 0.3000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1499 - acc: 0.5344 - val_loss: 1.3382 - val_acc: 0.3750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0202 - acc: 0.5906 - val_loss: 1.2529 - val_acc: 0.4000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9070 - acc: 0.6594 - val_loss: 1.1649 - val_acc: 0.4750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8100 - acc: 0.7469 - val_loss: 1.1567 - val_acc: 0.5000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7371 - acc: 0.7875 - val_loss: 1.0727 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6017 - acc: 0.2625 - val_loss: 1.5943 - val_acc: 0.3250\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5412 - acc: 0.3469 - val_loss: 1.4765 - val_acc: 0.3625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4286 - acc: 0.4594 - val_loss: 1.3310 - val_acc: 0.5750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2663 - acc: 0.6031 - val_loss: 1.1535 - val_acc: 0.6125\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1144 - acc: 0.6313 - val_loss: 1.0062 - val_acc: 0.6125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9799 - acc: 0.6781 - val_loss: 0.9548 - val_acc: 0.6500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8886 - acc: 0.7125 - val_loss: 0.8620 - val_acc: 0.6375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7836 - acc: 0.7844 - val_loss: 0.8304 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5990 - acc: 0.2375 - val_loss: 1.5876 - val_acc: 0.2500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5408 - acc: 0.3031 - val_loss: 1.4923 - val_acc: 0.4000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4305 - acc: 0.3875 - val_loss: 1.4114 - val_acc: 0.4375\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2914 - acc: 0.5469 - val_loss: 1.2320 - val_acc: 0.5375\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1295 - acc: 0.6219 - val_loss: 1.1036 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9798 - acc: 0.6656 - val_loss: 1.0204 - val_acc: 0.6125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8727 - acc: 0.7000 - val_loss: 0.9521 - val_acc: 0.6375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7794 - acc: 0.7531 - val_loss: 0.8711 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6098 - acc: 0.2344 - val_loss: 1.5840 - val_acc: 0.3000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5449 - acc: 0.3437 - val_loss: 1.5283 - val_acc: 0.3125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4411 - acc: 0.4031 - val_loss: 1.4344 - val_acc: 0.4125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2783 - acc: 0.5687 - val_loss: 1.3166 - val_acc: 0.3750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1088 - acc: 0.6281 - val_loss: 1.1942 - val_acc: 0.4500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9656 - acc: 0.6719 - val_loss: 1.1233 - val_acc: 0.5375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8511 - acc: 0.7281 - val_loss: 1.0349 - val_acc: 0.5750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7549 - acc: 0.7531 - val_loss: 1.0254 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6061 - acc: 0.2187 - val_loss: 1.5736 - val_acc: 0.2625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5399 - acc: 0.3438 - val_loss: 1.5256 - val_acc: 0.3125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4303 - acc: 0.5062 - val_loss: 1.4403 - val_acc: 0.4750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2794 - acc: 0.5781 - val_loss: 1.3332 - val_acc: 0.4875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1043 - acc: 0.6062 - val_loss: 1.2105 - val_acc: 0.5250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9486 - acc: 0.7219 - val_loss: 1.1575 - val_acc: 0.5125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8237 - acc: 0.7594 - val_loss: 1.0712 - val_acc: 0.5500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7376 - acc: 0.7594 - val_loss: 1.0542 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6059 - acc: 0.2188 - val_loss: 1.5892 - val_acc: 0.3000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5491 - acc: 0.3156 - val_loss: 1.5407 - val_acc: 0.2750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4694 - acc: 0.3469 - val_loss: 1.4731 - val_acc: 0.4250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3577 - acc: 0.5000 - val_loss: 1.3731 - val_acc: 0.4375\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2271 - acc: 0.5531 - val_loss: 1.2498 - val_acc: 0.4875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0816 - acc: 0.6531 - val_loss: 1.1296 - val_acc: 0.5375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9580 - acc: 0.6875 - val_loss: 1.0334 - val_acc: 0.6125\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8429 - acc: 0.7750 - val_loss: 0.9599 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5992 - acc: 0.2156 - val_loss: 1.5856 - val_acc: 0.2625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5171 - acc: 0.3937 - val_loss: 1.4845 - val_acc: 0.3125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3879 - acc: 0.4625 - val_loss: 1.3408 - val_acc: 0.4750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2250 - acc: 0.5656 - val_loss: 1.2101 - val_acc: 0.5875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0796 - acc: 0.6062 - val_loss: 1.1095 - val_acc: 0.5500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9529 - acc: 0.6969 - val_loss: 1.0642 - val_acc: 0.5875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8502 - acc: 0.6625 - val_loss: 1.0180 - val_acc: 0.5375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7569 - acc: 0.7844 - val_loss: 0.9724 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5970 - acc: 0.2562 - val_loss: 1.5902 - val_acc: 0.2125\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5171 - acc: 0.3688 - val_loss: 1.5574 - val_acc: 0.2875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3986 - acc: 0.4531 - val_loss: 1.4880 - val_acc: 0.3125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2558 - acc: 0.5250 - val_loss: 1.3761 - val_acc: 0.3750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1298 - acc: 0.5625 - val_loss: 1.3181 - val_acc: 0.4000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0259 - acc: 0.6031 - val_loss: 1.3526 - val_acc: 0.3750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9281 - acc: 0.6469 - val_loss: 1.2016 - val_acc: 0.4875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8511 - acc: 0.6906 - val_loss: 1.1589 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5987 - acc: 0.2344 - val_loss: 1.5811 - val_acc: 0.2500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5376 - acc: 0.2875 - val_loss: 1.5256 - val_acc: 0.3500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4346 - acc: 0.4875 - val_loss: 1.4131 - val_acc: 0.4750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2755 - acc: 0.6375 - val_loss: 1.2901 - val_acc: 0.5125\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1139 - acc: 0.6188 - val_loss: 1.1811 - val_acc: 0.5125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9737 - acc: 0.6906 - val_loss: 1.1240 - val_acc: 0.5000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8694 - acc: 0.6969 - val_loss: 1.0421 - val_acc: 0.5250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7773 - acc: 0.7500 - val_loss: 1.0562 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 1.5034 - acc: 0.3063 - val_loss: 1.0379 - val_acc: 0.5875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0511 - acc: 0.5719 - val_loss: 1.0427 - val_acc: 0.5500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8165 - acc: 0.6875 - val_loss: 0.9123 - val_acc: 0.6625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6161 - acc: 0.7656 - val_loss: 0.9985 - val_acc: 0.6000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4576 - acc: 0.8188 - val_loss: 1.1427 - val_acc: 0.6125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2040 - acc: 0.9656 - val_loss: 0.9066 - val_acc: 0.7000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0971 - acc: 0.9906 - val_loss: 0.8518 - val_acc: 0.6875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0424 - acc: 0.9969 - val_loss: 0.9688 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5224 - acc: 0.3156 - val_loss: 1.2463 - val_acc: 0.3750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1122 - acc: 0.5344 - val_loss: 1.9912 - val_acc: 0.4625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9370 - acc: 0.6500 - val_loss: 1.0209 - val_acc: 0.5500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5735 - acc: 0.8125 - val_loss: 1.0056 - val_acc: 0.6000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3552 - acc: 0.8719 - val_loss: 0.8731 - val_acc: 0.6625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1994 - acc: 0.9625 - val_loss: 1.3670 - val_acc: 0.5750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1111 - acc: 0.9687 - val_loss: 1.0624 - val_acc: 0.6375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 1.1001 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4880 - acc: 0.3562 - val_loss: 1.2162 - val_acc: 0.5375\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0833 - acc: 0.5469 - val_loss: 1.1783 - val_acc: 0.5250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6654 - acc: 0.7344 - val_loss: 1.1250 - val_acc: 0.5125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4759 - acc: 0.8250 - val_loss: 1.0251 - val_acc: 0.5875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2733 - acc: 0.9219 - val_loss: 1.2934 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1425 - acc: 0.9625 - val_loss: 1.3828 - val_acc: 0.5500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0591 - acc: 0.9937 - val_loss: 1.1449 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.1906 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5355 - acc: 0.3250 - val_loss: 1.2436 - val_acc: 0.4750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1611 - acc: 0.5219 - val_loss: 1.0776 - val_acc: 0.5625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8176 - acc: 0.6969 - val_loss: 1.1817 - val_acc: 0.5000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6163 - acc: 0.7656 - val_loss: 1.0422 - val_acc: 0.5625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2607 - acc: 0.9344 - val_loss: 1.1040 - val_acc: 0.5500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1024 - acc: 0.9875 - val_loss: 1.1427 - val_acc: 0.5875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0396 - acc: 1.0000 - val_loss: 1.2107 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 1.2583 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4881 - acc: 0.3000 - val_loss: 1.3201 - val_acc: 0.3750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2262 - acc: 0.4969 - val_loss: 1.1801 - val_acc: 0.5000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8379 - acc: 0.6656 - val_loss: 0.9561 - val_acc: 0.5625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6336 - acc: 0.7688 - val_loss: 0.8949 - val_acc: 0.6500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3496 - acc: 0.9000 - val_loss: 1.1367 - val_acc: 0.6000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2276 - acc: 0.9313 - val_loss: 1.1016 - val_acc: 0.6250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1335 - acc: 0.9594 - val_loss: 1.0597 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0646 - acc: 0.9844 - val_loss: 1.0814 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5466 - acc: 0.3125 - val_loss: 1.3306 - val_acc: 0.3500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3379 - acc: 0.4656 - val_loss: 1.5463 - val_acc: 0.5000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0766 - acc: 0.5781 - val_loss: 1.2256 - val_acc: 0.3625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7015 - acc: 0.7344 - val_loss: 1.0875 - val_acc: 0.6000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4649 - acc: 0.8250 - val_loss: 1.1237 - val_acc: 0.5625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2519 - acc: 0.9281 - val_loss: 1.3467 - val_acc: 0.5500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1774 - acc: 0.9531 - val_loss: 1.4596 - val_acc: 0.5750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0610 - acc: 0.9906 - val_loss: 1.5152 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5185 - acc: 0.3500 - val_loss: 1.2909 - val_acc: 0.3750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1475 - acc: 0.5625 - val_loss: 1.4876 - val_acc: 0.4625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8314 - acc: 0.6875 - val_loss: 1.1989 - val_acc: 0.5250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5711 - acc: 0.7844 - val_loss: 1.0327 - val_acc: 0.5500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4134 - acc: 0.8656 - val_loss: 1.2988 - val_acc: 0.5375\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1885 - acc: 0.9500 - val_loss: 1.1713 - val_acc: 0.6250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0766 - acc: 0.9937 - val_loss: 1.2209 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0326 - acc: 1.0000 - val_loss: 1.3659 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5359 - acc: 0.3125 - val_loss: 1.3397 - val_acc: 0.3875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0834 - acc: 0.5219 - val_loss: 1.1423 - val_acc: 0.5500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9235 - acc: 0.6250 - val_loss: 1.1213 - val_acc: 0.5500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5818 - acc: 0.8000 - val_loss: 1.0370 - val_acc: 0.5750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2587 - acc: 0.9437 - val_loss: 1.0089 - val_acc: 0.5750\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1182 - acc: 0.9812 - val_loss: 1.1278 - val_acc: 0.5750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0455 - acc: 0.9969 - val_loss: 1.1778 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5743 - acc: 0.2656 - val_loss: 1.4821 - val_acc: 0.4000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2778 - acc: 0.4781 - val_loss: 1.0763 - val_acc: 0.5500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8728 - acc: 0.6625 - val_loss: 1.2243 - val_acc: 0.5375\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6302 - acc: 0.7406 - val_loss: 1.2663 - val_acc: 0.5500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4157 - acc: 0.8625 - val_loss: 1.1123 - val_acc: 0.6250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1802 - acc: 0.9625 - val_loss: 1.2268 - val_acc: 0.6250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0910 - acc: 0.9750 - val_loss: 1.3214 - val_acc: 0.5500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0570 - acc: 0.9937 - val_loss: 1.8996 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 11.5198 - acc: 0.2094 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.1983 - acc: 0.1750 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.2616 - acc: 0.1750 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.8918 - acc: 0.2125 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.8138 - acc: 0.1719 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.2974 - acc: 0.1750 - val_loss: 11.2827 - val_acc: 0.3000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.3096 - acc: 0.2125 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.2635 - acc: 0.1750 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.5904 - acc: 0.2188 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.3912 - acc: 0.1875 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 2s 5ms/step - loss: 1.6006 - acc: 0.2688 - val_loss: 1.5798 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5255 - acc: 0.2969 - val_loss: 1.5102 - val_acc: 0.3125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4171 - acc: 0.4719 - val_loss: 1.4232 - val_acc: 0.3875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2901 - acc: 0.5625 - val_loss: 1.3257 - val_acc: 0.4500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1581 - acc: 0.6094 - val_loss: 1.2336 - val_acc: 0.5125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0421 - acc: 0.6656 - val_loss: 1.1580 - val_acc: 0.5125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9471 - acc: 0.6781 - val_loss: 1.1097 - val_acc: 0.5375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8632 - acc: 0.7063 - val_loss: 1.0924 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5976 - acc: 0.1937 - val_loss: 1.5916 - val_acc: 0.2125\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5379 - acc: 0.3750 - val_loss: 1.5427 - val_acc: 0.3375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4564 - acc: 0.5125 - val_loss: 1.4849 - val_acc: 0.3750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3549 - acc: 0.5500 - val_loss: 1.4064 - val_acc: 0.4500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2352 - acc: 0.5750 - val_loss: 1.3181 - val_acc: 0.4875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1104 - acc: 0.6344 - val_loss: 1.2457 - val_acc: 0.5250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0027 - acc: 0.6750 - val_loss: 1.1797 - val_acc: 0.5250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9160 - acc: 0.6937 - val_loss: 1.1265 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6029 - acc: 0.2344 - val_loss: 1.5778 - val_acc: 0.2750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5516 - acc: 0.3188 - val_loss: 1.5241 - val_acc: 0.3750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4813 - acc: 0.4438 - val_loss: 1.4609 - val_acc: 0.4375\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4030 - acc: 0.4656 - val_loss: 1.3880 - val_acc: 0.4500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2986 - acc: 0.5656 - val_loss: 1.3198 - val_acc: 0.4875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1811 - acc: 0.6063 - val_loss: 1.2416 - val_acc: 0.4750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0822 - acc: 0.6313 - val_loss: 1.1822 - val_acc: 0.5125\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9919 - acc: 0.6937 - val_loss: 1.1427 - val_acc: 0.4625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5914 - acc: 0.1969 - val_loss: 1.5726 - val_acc: 0.2250\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5210 - acc: 0.4219 - val_loss: 1.5028 - val_acc: 0.4750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4267 - acc: 0.5219 - val_loss: 1.4365 - val_acc: 0.4250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3173 - acc: 0.5188 - val_loss: 1.3484 - val_acc: 0.5000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1964 - acc: 0.5437 - val_loss: 1.2629 - val_acc: 0.4875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0743 - acc: 0.6125 - val_loss: 1.1901 - val_acc: 0.5375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9737 - acc: 0.6719 - val_loss: 1.1221 - val_acc: 0.5375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8869 - acc: 0.6813 - val_loss: 1.0830 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5982 - acc: 0.2156 - val_loss: 1.5650 - val_acc: 0.3000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5353 - acc: 0.4125 - val_loss: 1.4915 - val_acc: 0.5375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4446 - acc: 0.6000 - val_loss: 1.4082 - val_acc: 0.5125\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3251 - acc: 0.6281 - val_loss: 1.3074 - val_acc: 0.5500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1970 - acc: 0.6156 - val_loss: 1.2096 - val_acc: 0.5625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0732 - acc: 0.6500 - val_loss: 1.1135 - val_acc: 0.5750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9650 - acc: 0.6750 - val_loss: 1.0559 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8613 - acc: 0.7188 - val_loss: 0.9953 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6005 - acc: 0.2344 - val_loss: 1.5636 - val_acc: 0.3750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5432 - acc: 0.3781 - val_loss: 1.5049 - val_acc: 0.4625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4631 - acc: 0.5344 - val_loss: 1.4339 - val_acc: 0.5000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3624 - acc: 0.6094 - val_loss: 1.3359 - val_acc: 0.6250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2459 - acc: 0.6469 - val_loss: 1.2283 - val_acc: 0.6250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1140 - acc: 0.6313 - val_loss: 1.1235 - val_acc: 0.5500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9993 - acc: 0.6625 - val_loss: 1.0472 - val_acc: 0.6375\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9189 - acc: 0.6781 - val_loss: 0.9736 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6053 - acc: 0.2563 - val_loss: 1.5578 - val_acc: 0.4000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5488 - acc: 0.3469 - val_loss: 1.4916 - val_acc: 0.3375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4818 - acc: 0.3000 - val_loss: 1.4208 - val_acc: 0.3875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3869 - acc: 0.5062 - val_loss: 1.3193 - val_acc: 0.6125\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2801 - acc: 0.6281 - val_loss: 1.2136 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1628 - acc: 0.6219 - val_loss: 1.0967 - val_acc: 0.6375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0444 - acc: 0.6781 - val_loss: 1.0069 - val_acc: 0.6750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9418 - acc: 0.7031 - val_loss: 0.9307 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5960 - acc: 0.2063 - val_loss: 1.5694 - val_acc: 0.1875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5258 - acc: 0.2688 - val_loss: 1.5049 - val_acc: 0.2375\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4427 - acc: 0.3438 - val_loss: 1.4215 - val_acc: 0.4000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3377 - acc: 0.5719 - val_loss: 1.3182 - val_acc: 0.5750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2153 - acc: 0.6437 - val_loss: 1.2204 - val_acc: 0.5750\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0951 - acc: 0.6500 - val_loss: 1.1176 - val_acc: 0.5750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9865 - acc: 0.6719 - val_loss: 1.0382 - val_acc: 0.6125\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8894 - acc: 0.7063 - val_loss: 0.9737 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5981 - acc: 0.2375 - val_loss: 1.5790 - val_acc: 0.2000\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5263 - acc: 0.3094 - val_loss: 1.5333 - val_acc: 0.3125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4362 - acc: 0.4625 - val_loss: 1.4702 - val_acc: 0.4500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3227 - acc: 0.5563 - val_loss: 1.3971 - val_acc: 0.4000\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1944 - acc: 0.5781 - val_loss: 1.3185 - val_acc: 0.4125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0688 - acc: 0.6125 - val_loss: 1.2324 - val_acc: 0.4375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9512 - acc: 0.7000 - val_loss: 1.1725 - val_acc: 0.5000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8624 - acc: 0.7156 - val_loss: 1.1354 - val_acc: 0.5125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 1.5228 - acc: 0.2437 - val_loss: 1.2867 - val_acc: 0.4500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1203 - acc: 0.5563 - val_loss: 1.0316 - val_acc: 0.6250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9753 - acc: 0.6187 - val_loss: 0.9470 - val_acc: 0.6500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7922 - acc: 0.6781 - val_loss: 0.8923 - val_acc: 0.6250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6570 - acc: 0.7562 - val_loss: 0.8644 - val_acc: 0.6875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5168 - acc: 0.8125 - val_loss: 0.9210 - val_acc: 0.6125\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4414 - acc: 0.8219 - val_loss: 0.8746 - val_acc: 0.6500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3259 - acc: 0.9000 - val_loss: 0.8228 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5945 - acc: 0.2563 - val_loss: 1.4986 - val_acc: 0.3625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2567 - acc: 0.4688 - val_loss: 1.1655 - val_acc: 0.5500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9601 - acc: 0.5906 - val_loss: 1.2100 - val_acc: 0.5500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7923 - acc: 0.6719 - val_loss: 1.1393 - val_acc: 0.4625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5509 - acc: 0.7812 - val_loss: 1.0406 - val_acc: 0.5125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4159 - acc: 0.8500 - val_loss: 1.0689 - val_acc: 0.5625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3031 - acc: 0.9094 - val_loss: 0.9975 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1726 - acc: 0.9719 - val_loss: 1.2169 - val_acc: 0.5000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6134 - acc: 0.1625 - val_loss: 1.5107 - val_acc: 0.3375\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3861 - acc: 0.4344 - val_loss: 1.2384 - val_acc: 0.4500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9807 - acc: 0.5813 - val_loss: 1.1936 - val_acc: 0.4625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8699 - acc: 0.6563 - val_loss: 1.0600 - val_acc: 0.5625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6377 - acc: 0.7312 - val_loss: 0.8402 - val_acc: 0.7125\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4931 - acc: 0.8250 - val_loss: 0.9451 - val_acc: 0.6375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3455 - acc: 0.8937 - val_loss: 0.8562 - val_acc: 0.6000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1962 - acc: 0.9594 - val_loss: 0.8364 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6030 - acc: 0.1469 - val_loss: 1.5708 - val_acc: 0.2500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4099 - acc: 0.3719 - val_loss: 1.3556 - val_acc: 0.4250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0811 - acc: 0.6094 - val_loss: 0.9963 - val_acc: 0.5750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8732 - acc: 0.6406 - val_loss: 0.9362 - val_acc: 0.6375\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6595 - acc: 0.7438 - val_loss: 0.8232 - val_acc: 0.6625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4577 - acc: 0.8625 - val_loss: 0.7701 - val_acc: 0.6500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3269 - acc: 0.8969 - val_loss: 0.7874 - val_acc: 0.7000\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2223 - acc: 0.9562 - val_loss: 0.7701 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5943 - acc: 0.1688 - val_loss: 1.5293 - val_acc: 0.2875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3302 - acc: 0.4563 - val_loss: 1.2852 - val_acc: 0.4250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0020 - acc: 0.6031 - val_loss: 1.1234 - val_acc: 0.5500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7981 - acc: 0.6937 - val_loss: 0.9768 - val_acc: 0.5625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6519 - acc: 0.7469 - val_loss: 1.0231 - val_acc: 0.5875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4732 - acc: 0.8344 - val_loss: 1.2186 - val_acc: 0.5375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4076 - acc: 0.8563 - val_loss: 0.9380 - val_acc: 0.5875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2486 - acc: 0.9531 - val_loss: 0.9423 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6230 - acc: 0.2031 - val_loss: 1.5524 - val_acc: 0.2125\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4428 - acc: 0.4000 - val_loss: 1.3059 - val_acc: 0.4250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0762 - acc: 0.6219 - val_loss: 0.9509 - val_acc: 0.5875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7538 - acc: 0.7500 - val_loss: 1.0005 - val_acc: 0.6250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5718 - acc: 0.8187 - val_loss: 1.3643 - val_acc: 0.4375\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4827 - acc: 0.8125 - val_loss: 1.0894 - val_acc: 0.5375\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3430 - acc: 0.8969 - val_loss: 1.0138 - val_acc: 0.5625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1973 - acc: 0.9469 - val_loss: 0.8989 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6019 - acc: 0.1969 - val_loss: 1.5337 - val_acc: 0.3375\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3869 - acc: 0.4375 - val_loss: 1.3011 - val_acc: 0.4875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0433 - acc: 0.5969 - val_loss: 1.1652 - val_acc: 0.5250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8303 - acc: 0.6625 - val_loss: 1.1619 - val_acc: 0.5500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6491 - acc: 0.7687 - val_loss: 1.0522 - val_acc: 0.5500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4905 - acc: 0.8437 - val_loss: 1.0590 - val_acc: 0.5500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2904 - acc: 0.9437 - val_loss: 1.1698 - val_acc: 0.5500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1519 - acc: 0.9750 - val_loss: 1.0396 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5962 - acc: 0.2125 - val_loss: 1.5091 - val_acc: 0.3625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3438 - acc: 0.4625 - val_loss: 1.0805 - val_acc: 0.5750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0108 - acc: 0.5813 - val_loss: 1.0410 - val_acc: 0.6000\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8688 - acc: 0.6562 - val_loss: 0.9521 - val_acc: 0.5750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8181 - acc: 0.6906 - val_loss: 0.8291 - val_acc: 0.6500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5704 - acc: 0.7875 - val_loss: 0.8514 - val_acc: 0.6500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3857 - acc: 0.9000 - val_loss: 0.9626 - val_acc: 0.6250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2277 - acc: 0.9375 - val_loss: 0.8181 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5987 - acc: 0.2063 - val_loss: 1.5167 - val_acc: 0.2750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3762 - acc: 0.4625 - val_loss: 1.2151 - val_acc: 0.5125\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0294 - acc: 0.6219 - val_loss: 1.3104 - val_acc: 0.4875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8796 - acc: 0.6531 - val_loss: 1.0090 - val_acc: 0.5875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6731 - acc: 0.7656 - val_loss: 1.1069 - val_acc: 0.5750\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4433 - acc: 0.9062 - val_loss: 0.8954 - val_acc: 0.6500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2811 - acc: 0.9188 - val_loss: 0.9023 - val_acc: 0.6625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2162 - acc: 0.9312 - val_loss: 1.0818 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 2s 5ms/step - loss: 11.3340 - acc: 0.1875 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.3306 - acc: 0.2094 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0960 - acc: 0.1875 - val_loss: 12.0886 - val_acc: 0.2500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.3175 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.7132 - acc: 0.2156 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.2903 - acc: 0.2219 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.6598 - acc: 0.2156 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 6.6520 - acc: 0.2469 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.0142 - acc: 0.2125 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 7.7057 - acc: 0.2313 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/8\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.5776 - acc: 0.2969 - val_loss: 1.5426 - val_acc: 0.4125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3392 - acc: 0.4719 - val_loss: 1.3161 - val_acc: 0.4875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0852 - acc: 0.5656 - val_loss: 1.1090 - val_acc: 0.4875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9079 - acc: 0.6563 - val_loss: 1.0167 - val_acc: 0.5875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7808 - acc: 0.7437 - val_loss: 0.9525 - val_acc: 0.6375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6957 - acc: 0.7625 - val_loss: 0.8978 - val_acc: 0.7000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5984 - acc: 0.8187 - val_loss: 0.8766 - val_acc: 0.6625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5510 - acc: 0.8375 - val_loss: 0.8755 - val_acc: 0.6750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4576 - acc: 0.8750 - val_loss: 0.8773 - val_acc: 0.6625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3970 - acc: 0.8969 - val_loss: 0.8557 - val_acc: 0.6750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3286 - acc: 0.9281 - val_loss: 0.9013 - val_acc: 0.6500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2816 - acc: 0.9406 - val_loss: 0.8190 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5987 - acc: 0.2875 - val_loss: 1.5396 - val_acc: 0.4750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4281 - acc: 0.4594 - val_loss: 1.3211 - val_acc: 0.5375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1223 - acc: 0.6313 - val_loss: 1.1870 - val_acc: 0.4500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9292 - acc: 0.6438 - val_loss: 1.0332 - val_acc: 0.5875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8097 - acc: 0.6938 - val_loss: 1.0466 - val_acc: 0.5375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6836 - acc: 0.7781 - val_loss: 0.9665 - val_acc: 0.6125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5813 - acc: 0.8375 - val_loss: 0.9758 - val_acc: 0.6000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5100 - acc: 0.8500 - val_loss: 0.9192 - val_acc: 0.6625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4415 - acc: 0.8750 - val_loss: 0.9985 - val_acc: 0.6125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3886 - acc: 0.8844 - val_loss: 0.8980 - val_acc: 0.6500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3181 - acc: 0.9281 - val_loss: 0.9769 - val_acc: 0.6375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2701 - acc: 0.9437 - val_loss: 0.9099 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6054 - acc: 0.2594 - val_loss: 1.5631 - val_acc: 0.2625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5061 - acc: 0.4281 - val_loss: 1.4381 - val_acc: 0.5625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3288 - acc: 0.5563 - val_loss: 1.2595 - val_acc: 0.5500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1087 - acc: 0.6281 - val_loss: 1.0996 - val_acc: 0.5875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9106 - acc: 0.7312 - val_loss: 1.0105 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7770 - acc: 0.7406 - val_loss: 1.0078 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6855 - acc: 0.7750 - val_loss: 1.0208 - val_acc: 0.5625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6033 - acc: 0.7969 - val_loss: 0.9679 - val_acc: 0.5750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4817 - acc: 0.8719 - val_loss: 1.0430 - val_acc: 0.5625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4243 - acc: 0.8781 - val_loss: 0.9538 - val_acc: 0.6125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3824 - acc: 0.8937 - val_loss: 1.0274 - val_acc: 0.5750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3360 - acc: 0.9219 - val_loss: 0.9526 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5861 - acc: 0.2656 - val_loss: 1.5586 - val_acc: 0.2625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4085 - acc: 0.4594 - val_loss: 1.3375 - val_acc: 0.4500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1386 - acc: 0.5969 - val_loss: 1.4186 - val_acc: 0.4750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9738 - acc: 0.6000 - val_loss: 1.0832 - val_acc: 0.5250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8242 - acc: 0.6719 - val_loss: 1.0821 - val_acc: 0.5375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7740 - acc: 0.7375 - val_loss: 1.0620 - val_acc: 0.4875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6580 - acc: 0.7687 - val_loss: 1.0652 - val_acc: 0.5875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5968 - acc: 0.8156 - val_loss: 0.9788 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5157 - acc: 0.8406 - val_loss: 0.9585 - val_acc: 0.6000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4416 - acc: 0.8812 - val_loss: 0.9218 - val_acc: 0.6125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3994 - acc: 0.9062 - val_loss: 0.9843 - val_acc: 0.5750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3531 - acc: 0.9219 - val_loss: 1.0167 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6143 - acc: 0.2250 - val_loss: 1.5854 - val_acc: 0.2375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5230 - acc: 0.4344 - val_loss: 1.5390 - val_acc: 0.3750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3546 - acc: 0.5156 - val_loss: 1.3887 - val_acc: 0.3500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1380 - acc: 0.5406 - val_loss: 1.2576 - val_acc: 0.4500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9850 - acc: 0.6281 - val_loss: 1.1569 - val_acc: 0.4750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8166 - acc: 0.7125 - val_loss: 1.0449 - val_acc: 0.5500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7053 - acc: 0.7594 - val_loss: 1.0318 - val_acc: 0.5500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6221 - acc: 0.8094 - val_loss: 1.1099 - val_acc: 0.5000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5510 - acc: 0.8437 - val_loss: 1.0607 - val_acc: 0.4875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4628 - acc: 0.8812 - val_loss: 0.9357 - val_acc: 0.6250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4266 - acc: 0.8969 - val_loss: 1.0502 - val_acc: 0.5500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3587 - acc: 0.9250 - val_loss: 0.9795 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5817 - acc: 0.3281 - val_loss: 1.5135 - val_acc: 0.4625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4415 - acc: 0.4438 - val_loss: 1.3893 - val_acc: 0.4625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2347 - acc: 0.5469 - val_loss: 1.2014 - val_acc: 0.4875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0433 - acc: 0.6063 - val_loss: 1.0798 - val_acc: 0.5125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8925 - acc: 0.7000 - val_loss: 0.9792 - val_acc: 0.5875\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7691 - acc: 0.7406 - val_loss: 0.9096 - val_acc: 0.6125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6817 - acc: 0.7625 - val_loss: 0.8813 - val_acc: 0.6625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6060 - acc: 0.8156 - val_loss: 0.8505 - val_acc: 0.6750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5288 - acc: 0.8500 - val_loss: 0.8396 - val_acc: 0.6750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4608 - acc: 0.8719 - val_loss: 0.8198 - val_acc: 0.6500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4057 - acc: 0.8812 - val_loss: 0.8392 - val_acc: 0.7000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3685 - acc: 0.9094 - val_loss: 0.8087 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5933 - acc: 0.2406 - val_loss: 1.6568 - val_acc: 0.2375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4962 - acc: 0.4250 - val_loss: 1.6389 - val_acc: 0.2500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3409 - acc: 0.4656 - val_loss: 1.4495 - val_acc: 0.2875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1451 - acc: 0.5313 - val_loss: 1.3203 - val_acc: 0.4250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9990 - acc: 0.6094 - val_loss: 1.2141 - val_acc: 0.4375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8566 - acc: 0.7156 - val_loss: 1.2518 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7340 - acc: 0.7437 - val_loss: 1.2789 - val_acc: 0.5125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6534 - acc: 0.8000 - val_loss: 1.1181 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5765 - acc: 0.8312 - val_loss: 1.1148 - val_acc: 0.6250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4763 - acc: 0.9062 - val_loss: 1.1012 - val_acc: 0.5875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3882 - acc: 0.9312 - val_loss: 1.0274 - val_acc: 0.6000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3640 - acc: 0.9375 - val_loss: 1.2536 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6004 - acc: 0.2281 - val_loss: 1.5670 - val_acc: 0.3500\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5011 - acc: 0.4531 - val_loss: 1.4449 - val_acc: 0.4750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2919 - acc: 0.5406 - val_loss: 1.2765 - val_acc: 0.5250\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0466 - acc: 0.6188 - val_loss: 1.1023 - val_acc: 0.5375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8819 - acc: 0.6687 - val_loss: 1.1329 - val_acc: 0.4750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7783 - acc: 0.6938 - val_loss: 1.0188 - val_acc: 0.6125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6923 - acc: 0.7625 - val_loss: 0.9733 - val_acc: 0.5750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6106 - acc: 0.8031 - val_loss: 0.9045 - val_acc: 0.6375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5233 - acc: 0.8594 - val_loss: 0.9092 - val_acc: 0.6500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4259 - acc: 0.9156 - val_loss: 0.8879 - val_acc: 0.6250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3672 - acc: 0.9344 - val_loss: 0.9101 - val_acc: 0.6625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3526 - acc: 0.9219 - val_loss: 0.9330 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6096 - acc: 0.2375 - val_loss: 1.5608 - val_acc: 0.4000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4691 - acc: 0.4813 - val_loss: 1.3410 - val_acc: 0.4750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2130 - acc: 0.5688 - val_loss: 1.1579 - val_acc: 0.5125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0045 - acc: 0.6250 - val_loss: 1.0380 - val_acc: 0.5625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8707 - acc: 0.6906 - val_loss: 0.9553 - val_acc: 0.6250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8013 - acc: 0.7125 - val_loss: 0.9647 - val_acc: 0.6250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6890 - acc: 0.7750 - val_loss: 0.9253 - val_acc: 0.6500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5981 - acc: 0.8031 - val_loss: 0.9179 - val_acc: 0.6500\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5254 - acc: 0.8344 - val_loss: 0.9290 - val_acc: 0.5875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4892 - acc: 0.8625 - val_loss: 0.9098 - val_acc: 0.6500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4084 - acc: 0.9000 - val_loss: 0.9227 - val_acc: 0.6000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3604 - acc: 0.9156 - val_loss: 1.0250 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.4165 - acc: 0.3844 - val_loss: 1.0421 - val_acc: 0.5625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9262 - acc: 0.6438 - val_loss: 1.4824 - val_acc: 0.5000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7097 - acc: 0.7250 - val_loss: 1.5469 - val_acc: 0.4375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3981 - acc: 0.8500 - val_loss: 1.0270 - val_acc: 0.5875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1228 - acc: 0.9656 - val_loss: 1.1141 - val_acc: 0.6000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0628 - acc: 0.9875 - val_loss: 1.2353 - val_acc: 0.5500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0324 - acc: 0.9969 - val_loss: 1.4259 - val_acc: 0.5875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0367 - acc: 0.9937 - val_loss: 1.4080 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.7559 - val_acc: 0.6000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.5663 - val_acc: 0.5750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.5722 - val_acc: 0.5750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.5808 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5736 - acc: 0.3656 - val_loss: 1.0819 - val_acc: 0.4625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1166 - acc: 0.5563 - val_loss: 1.2235 - val_acc: 0.5000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7841 - acc: 0.6688 - val_loss: 0.8937 - val_acc: 0.6750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4489 - acc: 0.8500 - val_loss: 1.7213 - val_acc: 0.4625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2776 - acc: 0.9125 - val_loss: 1.2317 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0927 - acc: 0.9719 - val_loss: 1.3042 - val_acc: 0.6375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 1.3244 - val_acc: 0.5750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.3353 - val_acc: 0.6250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.3259 - val_acc: 0.6375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.3469 - val_acc: 0.6250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3632 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5516 - acc: 0.3750 - val_loss: 1.8326 - val_acc: 0.4000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4431 - acc: 0.5031 - val_loss: 1.4606 - val_acc: 0.4250\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9250 - acc: 0.6094 - val_loss: 1.1882 - val_acc: 0.5625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5864 - acc: 0.7594 - val_loss: 1.3620 - val_acc: 0.5750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3225 - acc: 0.8687 - val_loss: 1.2664 - val_acc: 0.5375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1118 - acc: 0.9750 - val_loss: 1.6028 - val_acc: 0.5500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0295 - acc: 1.0000 - val_loss: 1.6122 - val_acc: 0.5375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.6392 - val_acc: 0.5250\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.8058 - val_acc: 0.5625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.7851 - val_acc: 0.5375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.8072 - val_acc: 0.5500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.8466 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5562 - acc: 0.3750 - val_loss: 1.6819 - val_acc: 0.4375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0443 - acc: 0.5875 - val_loss: 1.1450 - val_acc: 0.5750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6225 - acc: 0.7406 - val_loss: 1.0756 - val_acc: 0.5750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3984 - acc: 0.8469 - val_loss: 1.3373 - val_acc: 0.6000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2045 - acc: 0.9156 - val_loss: 1.8125 - val_acc: 0.5500\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0643 - acc: 0.9812 - val_loss: 1.8920 - val_acc: 0.5750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.0758 - val_acc: 0.5750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.0507 - val_acc: 0.5500\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.1640 - val_acc: 0.5625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.1987 - val_acc: 0.5625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.2148 - val_acc: 0.5625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.2485 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5665 - acc: 0.3500 - val_loss: 1.1609 - val_acc: 0.4625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0188 - acc: 0.5906 - val_loss: 1.1833 - val_acc: 0.5500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8692 - acc: 0.6562 - val_loss: 1.0959 - val_acc: 0.5750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4545 - acc: 0.8250 - val_loss: 1.0168 - val_acc: 0.6375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1191 - acc: 0.9625 - val_loss: 1.3532 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0363 - acc: 0.9937 - val_loss: 1.4527 - val_acc: 0.6000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0303 - acc: 0.9906 - val_loss: 1.7166 - val_acc: 0.6500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0210 - acc: 0.9906 - val_loss: 1.3733 - val_acc: 0.6000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.5240 - val_acc: 0.6375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.5171 - val_acc: 0.6125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.5308 - val_acc: 0.6250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.2703e-04 - acc: 1.0000 - val_loss: 1.5369 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5733 - acc: 0.3469 - val_loss: 1.0717 - val_acc: 0.5125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1768 - acc: 0.5656 - val_loss: 1.4416 - val_acc: 0.4375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8319 - acc: 0.6719 - val_loss: 1.1186 - val_acc: 0.6125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7300 - acc: 0.7281 - val_loss: 0.8814 - val_acc: 0.6375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2502 - acc: 0.9156 - val_loss: 1.1052 - val_acc: 0.6750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1267 - acc: 0.9687 - val_loss: 1.0194 - val_acc: 0.6875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.1332 - val_acc: 0.7250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.1557 - val_acc: 0.7125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.1421 - val_acc: 0.7125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.1898 - val_acc: 0.7125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.2074 - val_acc: 0.7125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.2101 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5886 - acc: 0.3500 - val_loss: 1.3647 - val_acc: 0.5000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2263 - acc: 0.4906 - val_loss: 1.0473 - val_acc: 0.5500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7402 - acc: 0.6937 - val_loss: 1.0155 - val_acc: 0.5375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3865 - acc: 0.8656 - val_loss: 0.8580 - val_acc: 0.6625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1833 - acc: 0.9500 - val_loss: 1.1660 - val_acc: 0.5875\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0611 - acc: 0.9844 - val_loss: 1.0183 - val_acc: 0.6750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0282 - acc: 0.9969 - val_loss: 1.0235 - val_acc: 0.6750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.9539 - val_acc: 0.7000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9689 - val_acc: 0.7000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9634 - val_acc: 0.7125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9710 - val_acc: 0.7250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.8503e-04 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.7250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5027 - acc: 0.3813 - val_loss: 1.1903 - val_acc: 0.5500\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0315 - acc: 0.6000 - val_loss: 0.9851 - val_acc: 0.6125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8239 - acc: 0.7031 - val_loss: 0.9685 - val_acc: 0.6000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5291 - acc: 0.8375 - val_loss: 1.0434 - val_acc: 0.6500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2895 - acc: 0.8937 - val_loss: 1.2182 - val_acc: 0.6500\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1272 - acc: 0.9594 - val_loss: 1.2751 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0413 - acc: 0.9937 - val_loss: 1.3314 - val_acc: 0.6750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0129 - acc: 0.9969 - val_loss: 0.9749 - val_acc: 0.7000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.1149 - val_acc: 0.6750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.1283 - val_acc: 0.6750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.1208 - val_acc: 0.6500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.1362 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6387 - acc: 0.3250 - val_loss: 1.3389 - val_acc: 0.3750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2536 - acc: 0.5094 - val_loss: 1.4509 - val_acc: 0.3875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1534 - acc: 0.5625 - val_loss: 1.3347 - val_acc: 0.4625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6081 - acc: 0.7562 - val_loss: 1.2168 - val_acc: 0.5375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3426 - acc: 0.8937 - val_loss: 1.3692 - val_acc: 0.5250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1428 - acc: 0.9625 - val_loss: 1.5700 - val_acc: 0.5500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0315 - acc: 0.9969 - val_loss: 1.3176 - val_acc: 0.6250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.3934 - val_acc: 0.6125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.5606 - val_acc: 0.6375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.4963 - val_acc: 0.6375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.5601 - val_acc: 0.6375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.5944 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 12.5107 - acc: 0.1906 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5690 - acc: 0.1969 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 5ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8438 - acc: 0.1781 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.2385 - acc: 0.2156 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5419 - acc: 0.2219 - val_loss: 14.3048 - val_acc: 0.1125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5272 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4636 - acc: 0.2063 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3565 - acc: 0.1938 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3780 - acc: 0.1875 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.1930 - acc: 0.1563 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.3982 - acc: 0.1688 - val_loss: 10.8797 - val_acc: 0.3250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.5951 - acc: 0.3062 - val_loss: 1.5586 - val_acc: 0.3875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4915 - acc: 0.4844 - val_loss: 1.4527 - val_acc: 0.4750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3508 - acc: 0.5687 - val_loss: 1.3249 - val_acc: 0.5500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1829 - acc: 0.6531 - val_loss: 1.1803 - val_acc: 0.5750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0334 - acc: 0.6875 - val_loss: 1.0848 - val_acc: 0.5875\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9157 - acc: 0.6969 - val_loss: 1.0253 - val_acc: 0.6125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8142 - acc: 0.7125 - val_loss: 0.9793 - val_acc: 0.6500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7537 - acc: 0.7656 - val_loss: 0.9639 - val_acc: 0.6375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6773 - acc: 0.7969 - val_loss: 0.9614 - val_acc: 0.6125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6200 - acc: 0.7969 - val_loss: 0.9282 - val_acc: 0.6625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5656 - acc: 0.8531 - val_loss: 0.9112 - val_acc: 0.6625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5070 - acc: 0.8656 - val_loss: 0.9201 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5988 - acc: 0.2187 - val_loss: 1.5783 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5252 - acc: 0.3813 - val_loss: 1.4992 - val_acc: 0.4875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3915 - acc: 0.5531 - val_loss: 1.3886 - val_acc: 0.5000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2266 - acc: 0.5938 - val_loss: 1.2594 - val_acc: 0.5000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0437 - acc: 0.6750 - val_loss: 1.1428 - val_acc: 0.5250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9046 - acc: 0.7250 - val_loss: 1.0985 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8036 - acc: 0.7469 - val_loss: 1.0227 - val_acc: 0.5625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7134 - acc: 0.7781 - val_loss: 1.0525 - val_acc: 0.5125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6489 - acc: 0.8000 - val_loss: 1.0182 - val_acc: 0.5500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5895 - acc: 0.8219 - val_loss: 0.9565 - val_acc: 0.5875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5258 - acc: 0.8625 - val_loss: 0.9522 - val_acc: 0.6250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4620 - acc: 0.8937 - val_loss: 0.9410 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6009 - acc: 0.2344 - val_loss: 1.5900 - val_acc: 0.2250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5474 - acc: 0.3156 - val_loss: 1.5521 - val_acc: 0.3000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4552 - acc: 0.4844 - val_loss: 1.5060 - val_acc: 0.3750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3416 - acc: 0.5844 - val_loss: 1.4092 - val_acc: 0.4875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1867 - acc: 0.6406 - val_loss: 1.2880 - val_acc: 0.5250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0321 - acc: 0.6563 - val_loss: 1.1669 - val_acc: 0.5125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8945 - acc: 0.7125 - val_loss: 1.0447 - val_acc: 0.5875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7831 - acc: 0.7469 - val_loss: 0.9980 - val_acc: 0.5625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7064 - acc: 0.7781 - val_loss: 0.9288 - val_acc: 0.6375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6302 - acc: 0.8000 - val_loss: 0.9356 - val_acc: 0.5750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5718 - acc: 0.8062 - val_loss: 0.9224 - val_acc: 0.6000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5123 - acc: 0.8687 - val_loss: 0.8588 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5945 - acc: 0.2156 - val_loss: 1.5728 - val_acc: 0.2875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5300 - acc: 0.3625 - val_loss: 1.5244 - val_acc: 0.4000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4149 - acc: 0.5000 - val_loss: 1.4341 - val_acc: 0.4375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2561 - acc: 0.5625 - val_loss: 1.2948 - val_acc: 0.5000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0679 - acc: 0.6219 - val_loss: 1.1800 - val_acc: 0.5000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9182 - acc: 0.7219 - val_loss: 1.0848 - val_acc: 0.5500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8047 - acc: 0.7219 - val_loss: 1.0377 - val_acc: 0.6125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7161 - acc: 0.8000 - val_loss: 1.0127 - val_acc: 0.5625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6645 - acc: 0.7781 - val_loss: 1.0223 - val_acc: 0.6125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5939 - acc: 0.8125 - val_loss: 0.9953 - val_acc: 0.5750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5367 - acc: 0.8469 - val_loss: 0.9925 - val_acc: 0.6125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4836 - acc: 0.8750 - val_loss: 0.9831 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6038 - acc: 0.1844 - val_loss: 1.5756 - val_acc: 0.1875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5592 - acc: 0.3469 - val_loss: 1.5304 - val_acc: 0.3500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4989 - acc: 0.4563 - val_loss: 1.4780 - val_acc: 0.4875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4153 - acc: 0.6125 - val_loss: 1.3967 - val_acc: 0.5250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3066 - acc: 0.6250 - val_loss: 1.2799 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1835 - acc: 0.6750 - val_loss: 1.1574 - val_acc: 0.6375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0490 - acc: 0.6938 - val_loss: 1.0421 - val_acc: 0.6375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9290 - acc: 0.7125 - val_loss: 0.9577 - val_acc: 0.6750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8362 - acc: 0.7344 - val_loss: 0.9028 - val_acc: 0.6500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7616 - acc: 0.7750 - val_loss: 0.8498 - val_acc: 0.6875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7143 - acc: 0.7656 - val_loss: 0.8353 - val_acc: 0.6500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6156 - acc: 0.8313 - val_loss: 0.8232 - val_acc: 0.7125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5952 - acc: 0.2437 - val_loss: 1.5589 - val_acc: 0.3000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5297 - acc: 0.3812 - val_loss: 1.5071 - val_acc: 0.3500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4320 - acc: 0.4875 - val_loss: 1.4492 - val_acc: 0.4625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3061 - acc: 0.6063 - val_loss: 1.3602 - val_acc: 0.5500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1511 - acc: 0.6969 - val_loss: 1.2545 - val_acc: 0.5625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9927 - acc: 0.7250 - val_loss: 1.1486 - val_acc: 0.6250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8558 - acc: 0.7625 - val_loss: 1.0223 - val_acc: 0.6375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7521 - acc: 0.7969 - val_loss: 0.9872 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6641 - acc: 0.8094 - val_loss: 0.9534 - val_acc: 0.5875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5798 - acc: 0.8375 - val_loss: 0.8881 - val_acc: 0.6250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5137 - acc: 0.8625 - val_loss: 0.8753 - val_acc: 0.6250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4694 - acc: 0.8687 - val_loss: 0.8686 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5976 - acc: 0.2313 - val_loss: 1.5946 - val_acc: 0.2250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5595 - acc: 0.3156 - val_loss: 1.5770 - val_acc: 0.3125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4947 - acc: 0.4156 - val_loss: 1.5123 - val_acc: 0.4375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4113 - acc: 0.5344 - val_loss: 1.4550 - val_acc: 0.4500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3010 - acc: 0.6031 - val_loss: 1.3710 - val_acc: 0.5125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1686 - acc: 0.6125 - val_loss: 1.2492 - val_acc: 0.5875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0272 - acc: 0.6719 - val_loss: 1.1238 - val_acc: 0.6000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9230 - acc: 0.7187 - val_loss: 1.0248 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7934 - acc: 0.7719 - val_loss: 0.9749 - val_acc: 0.6000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6950 - acc: 0.7937 - val_loss: 0.9167 - val_acc: 0.6375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6277 - acc: 0.8219 - val_loss: 0.8921 - val_acc: 0.6250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5611 - acc: 0.8375 - val_loss: 0.9425 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5927 - acc: 0.2531 - val_loss: 1.5856 - val_acc: 0.3125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5462 - acc: 0.4031 - val_loss: 1.5544 - val_acc: 0.4000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4594 - acc: 0.5469 - val_loss: 1.5065 - val_acc: 0.4375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3500 - acc: 0.6281 - val_loss: 1.4319 - val_acc: 0.3750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2133 - acc: 0.6500 - val_loss: 1.3350 - val_acc: 0.4625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0630 - acc: 0.7156 - val_loss: 1.2834 - val_acc: 0.4500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9227 - acc: 0.7437 - val_loss: 1.1722 - val_acc: 0.5125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8250 - acc: 0.7375 - val_loss: 1.1377 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7366 - acc: 0.7500 - val_loss: 1.0787 - val_acc: 0.5625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6655 - acc: 0.7781 - val_loss: 1.0594 - val_acc: 0.6000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5940 - acc: 0.8094 - val_loss: 1.0342 - val_acc: 0.6250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5356 - acc: 0.8375 - val_loss: 1.0256 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5994 - acc: 0.1969 - val_loss: 1.6092 - val_acc: 0.2875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5542 - acc: 0.4281 - val_loss: 1.5583 - val_acc: 0.3500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4763 - acc: 0.4625 - val_loss: 1.5172 - val_acc: 0.4375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3666 - acc: 0.5281 - val_loss: 1.3986 - val_acc: 0.4250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2312 - acc: 0.6625 - val_loss: 1.3104 - val_acc: 0.4875\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0910 - acc: 0.6219 - val_loss: 1.2134 - val_acc: 0.5750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9380 - acc: 0.7344 - val_loss: 1.1141 - val_acc: 0.5500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8300 - acc: 0.7156 - val_loss: 1.0058 - val_acc: 0.6000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7678 - acc: 0.7281 - val_loss: 0.9295 - val_acc: 0.6000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6821 - acc: 0.8000 - val_loss: 0.9109 - val_acc: 0.6125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6011 - acc: 0.8094 - val_loss: 0.8532 - val_acc: 0.6875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5465 - acc: 0.8344 - val_loss: 0.8482 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_54 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.4540 - acc: 0.3625 - val_loss: 1.2505 - val_acc: 0.4500\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0691 - acc: 0.5844 - val_loss: 1.0166 - val_acc: 0.5750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8535 - acc: 0.6469 - val_loss: 0.9465 - val_acc: 0.6500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5691 - acc: 0.8063 - val_loss: 0.9330 - val_acc: 0.6125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3624 - acc: 0.8937 - val_loss: 0.9700 - val_acc: 0.6125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2031 - acc: 0.9625 - val_loss: 1.0230 - val_acc: 0.5625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0977 - acc: 0.9844 - val_loss: 1.0398 - val_acc: 0.5750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0819 - acc: 0.9719 - val_loss: 1.0496 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 1.2605 - val_acc: 0.5500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.1073 - val_acc: 0.6250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.2771 - val_acc: 0.5875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.2038 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5270 - acc: 0.3719 - val_loss: 1.2328 - val_acc: 0.4250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2420 - acc: 0.5344 - val_loss: 1.1066 - val_acc: 0.6250\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8370 - acc: 0.6781 - val_loss: 1.0942 - val_acc: 0.6125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6129 - acc: 0.7406 - val_loss: 0.9668 - val_acc: 0.6750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3990 - acc: 0.8688 - val_loss: 1.0704 - val_acc: 0.6125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2214 - acc: 0.9313 - val_loss: 1.3269 - val_acc: 0.5625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1488 - acc: 0.9719 - val_loss: 1.3403 - val_acc: 0.6500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0734 - acc: 0.9906 - val_loss: 1.1710 - val_acc: 0.6000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 1.3049 - val_acc: 0.5750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.3324 - val_acc: 0.5875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.3392 - val_acc: 0.5875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.3770 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4665 - acc: 0.3344 - val_loss: 1.1045 - val_acc: 0.5625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3674 - acc: 0.4750 - val_loss: 1.0198 - val_acc: 0.5500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8246 - acc: 0.6594 - val_loss: 1.1234 - val_acc: 0.5875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6742 - acc: 0.7344 - val_loss: 0.8525 - val_acc: 0.7000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3952 - acc: 0.8781 - val_loss: 0.7788 - val_acc: 0.6750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1664 - acc: 0.9719 - val_loss: 0.7822 - val_acc: 0.6625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0736 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.6250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0465 - acc: 0.9906 - val_loss: 0.8941 - val_acc: 0.6750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.8794 - val_acc: 0.7000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.9672 - val_acc: 0.6375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.9010 - val_acc: 0.6750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.9758 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4891 - acc: 0.3375 - val_loss: 1.0809 - val_acc: 0.5625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1426 - acc: 0.5656 - val_loss: 1.3261 - val_acc: 0.4500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7964 - acc: 0.7156 - val_loss: 0.8544 - val_acc: 0.6750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5259 - acc: 0.8094 - val_loss: 0.9253 - val_acc: 0.6250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3514 - acc: 0.8750 - val_loss: 0.8947 - val_acc: 0.6125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1567 - acc: 0.9687 - val_loss: 0.8936 - val_acc: 0.6625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0642 - acc: 0.9969 - val_loss: 0.8537 - val_acc: 0.6750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0311 - acc: 0.9969 - val_loss: 0.9960 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0244 - acc: 0.9969 - val_loss: 1.4128 - val_acc: 0.6500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.1670 - val_acc: 0.6500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.6625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.1798 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4804 - acc: 0.3687 - val_loss: 1.1772 - val_acc: 0.5750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1731 - acc: 0.5500 - val_loss: 1.1586 - val_acc: 0.5000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9358 - acc: 0.6563 - val_loss: 1.1822 - val_acc: 0.5625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6606 - acc: 0.7594 - val_loss: 1.0754 - val_acc: 0.5500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4868 - acc: 0.8125 - val_loss: 1.1228 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1641 - acc: 0.9625 - val_loss: 1.0664 - val_acc: 0.6000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0535 - acc: 0.9969 - val_loss: 1.6508 - val_acc: 0.5875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0306 - acc: 0.9969 - val_loss: 1.3710 - val_acc: 0.6250\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0199 - acc: 0.9937 - val_loss: 1.6519 - val_acc: 0.6250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.3824 - val_acc: 0.6375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.4351 - val_acc: 0.5750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.4368 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5023 - acc: 0.3656 - val_loss: 1.3540 - val_acc: 0.4625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1935 - acc: 0.5313 - val_loss: 1.6863 - val_acc: 0.3750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9886 - acc: 0.6281 - val_loss: 1.3595 - val_acc: 0.4625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6866 - acc: 0.7250 - val_loss: 1.2056 - val_acc: 0.5750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3612 - acc: 0.8969 - val_loss: 1.0434 - val_acc: 0.5625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1608 - acc: 0.9563 - val_loss: 1.3306 - val_acc: 0.5875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0576 - acc: 0.9937 - val_loss: 1.4773 - val_acc: 0.5375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 1.4613 - val_acc: 0.5750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.5031 - val_acc: 0.5750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.5405 - val_acc: 0.5875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.5843 - val_acc: 0.5875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.6317 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4490 - acc: 0.3844 - val_loss: 1.1963 - val_acc: 0.4625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1094 - acc: 0.6000 - val_loss: 0.8588 - val_acc: 0.6625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9049 - acc: 0.6344 - val_loss: 1.0354 - val_acc: 0.5625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5517 - acc: 0.8031 - val_loss: 0.8849 - val_acc: 0.6875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2854 - acc: 0.9219 - val_loss: 1.1222 - val_acc: 0.6250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2206 - acc: 0.9219 - val_loss: 1.0962 - val_acc: 0.6625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1036 - acc: 0.9750 - val_loss: 1.1524 - val_acc: 0.5875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0369 - acc: 1.0000 - val_loss: 1.0297 - val_acc: 0.7500\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.7750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.7500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.0091 - val_acc: 0.7625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.7625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4716 - acc: 0.3813 - val_loss: 1.4592 - val_acc: 0.4000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1721 - acc: 0.5687 - val_loss: 1.7877 - val_acc: 0.4125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1373 - acc: 0.5844 - val_loss: 1.3610 - val_acc: 0.4750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7943 - acc: 0.6719 - val_loss: 1.1875 - val_acc: 0.5000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5673 - acc: 0.8031 - val_loss: 1.0858 - val_acc: 0.4750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2705 - acc: 0.9344 - val_loss: 1.3434 - val_acc: 0.5125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1498 - acc: 0.9656 - val_loss: 1.3969 - val_acc: 0.5750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0821 - acc: 0.9750 - val_loss: 1.5103 - val_acc: 0.5625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0526 - acc: 0.9906 - val_loss: 1.5780 - val_acc: 0.5375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 1.3115 - val_acc: 0.6000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.7594 - val_acc: 0.5750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.4436 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4986 - acc: 0.3156 - val_loss: 1.2075 - val_acc: 0.4625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1219 - acc: 0.5531 - val_loss: 1.0264 - val_acc: 0.5500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0269 - acc: 0.6000 - val_loss: 0.9715 - val_acc: 0.5125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6231 - acc: 0.7906 - val_loss: 1.0527 - val_acc: 0.5750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4953 - acc: 0.8219 - val_loss: 1.1650 - val_acc: 0.5625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2927 - acc: 0.9187 - val_loss: 1.1511 - val_acc: 0.5625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1126 - acc: 0.9812 - val_loss: 1.0731 - val_acc: 0.6000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.6125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.9725 - val_acc: 0.6875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.0171 - val_acc: 0.6250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0649 - val_acc: 0.6625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.0674 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 11.6856 - acc: 0.2031 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.9436 - acc: 0.2062 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.4293 - acc: 0.1812 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.4444 - acc: 0.1875 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.5604 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.6615 - acc: 0.2187 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 10.9689 - acc: 0.1750 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.4452 - acc: 0.2250 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.0238 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.4670 - acc: 0.1594 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1463 - acc: 0.1844 - val_loss: 11.8871 - val_acc: 0.2625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.6035 - acc: 0.1844 - val_loss: 1.5434 - val_acc: 0.3125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5441 - acc: 0.2188 - val_loss: 1.4665 - val_acc: 0.4125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4577 - acc: 0.4469 - val_loss: 1.3878 - val_acc: 0.6000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3527 - acc: 0.5781 - val_loss: 1.2728 - val_acc: 0.6000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2316 - acc: 0.5750 - val_loss: 1.1523 - val_acc: 0.6125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1119 - acc: 0.6156 - val_loss: 1.0396 - val_acc: 0.6125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0167 - acc: 0.6125 - val_loss: 0.9817 - val_acc: 0.6125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9401 - acc: 0.6656 - val_loss: 0.9326 - val_acc: 0.6375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8680 - acc: 0.6906 - val_loss: 0.8843 - val_acc: 0.6875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8057 - acc: 0.7219 - val_loss: 0.8692 - val_acc: 0.6625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7656 - acc: 0.7281 - val_loss: 0.8168 - val_acc: 0.6875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7057 - acc: 0.7594 - val_loss: 0.8161 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6007 - acc: 0.1875 - val_loss: 1.5947 - val_acc: 0.2875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5664 - acc: 0.2438 - val_loss: 1.5741 - val_acc: 0.2625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5141 - acc: 0.4219 - val_loss: 1.5470 - val_acc: 0.2875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4404 - acc: 0.4437 - val_loss: 1.5080 - val_acc: 0.3500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3441 - acc: 0.5875 - val_loss: 1.4599 - val_acc: 0.4000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2335 - acc: 0.6281 - val_loss: 1.3765 - val_acc: 0.4750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1219 - acc: 0.7000 - val_loss: 1.3145 - val_acc: 0.4875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0040 - acc: 0.7062 - val_loss: 1.2061 - val_acc: 0.5750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9181 - acc: 0.6750 - val_loss: 1.1422 - val_acc: 0.5875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8387 - acc: 0.7469 - val_loss: 1.1222 - val_acc: 0.5750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7747 - acc: 0.7312 - val_loss: 1.0669 - val_acc: 0.6125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7184 - acc: 0.7562 - val_loss: 1.0590 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6027 - acc: 0.1844 - val_loss: 1.5759 - val_acc: 0.2625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5682 - acc: 0.3219 - val_loss: 1.5553 - val_acc: 0.2625\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5223 - acc: 0.2969 - val_loss: 1.5088 - val_acc: 0.2875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4656 - acc: 0.4562 - val_loss: 1.4594 - val_acc: 0.4625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3941 - acc: 0.6063 - val_loss: 1.3932 - val_acc: 0.5625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3054 - acc: 0.6969 - val_loss: 1.2948 - val_acc: 0.5875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1932 - acc: 0.7344 - val_loss: 1.2094 - val_acc: 0.5625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0819 - acc: 0.6938 - val_loss: 1.1479 - val_acc: 0.5875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9828 - acc: 0.7219 - val_loss: 1.0653 - val_acc: 0.6250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8868 - acc: 0.7281 - val_loss: 1.0589 - val_acc: 0.6000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8163 - acc: 0.7500 - val_loss: 0.9872 - val_acc: 0.6625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7441 - acc: 0.7719 - val_loss: 1.0142 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5975 - acc: 0.1813 - val_loss: 1.5838 - val_acc: 0.2625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5569 - acc: 0.2313 - val_loss: 1.5642 - val_acc: 0.3375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5036 - acc: 0.3594 - val_loss: 1.5214 - val_acc: 0.3625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4375 - acc: 0.3906 - val_loss: 1.4711 - val_acc: 0.3875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3495 - acc: 0.5750 - val_loss: 1.4196 - val_acc: 0.4625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2462 - acc: 0.6594 - val_loss: 1.3666 - val_acc: 0.4375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1369 - acc: 0.6250 - val_loss: 1.2950 - val_acc: 0.4125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0199 - acc: 0.6969 - val_loss: 1.1832 - val_acc: 0.5000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9274 - acc: 0.7219 - val_loss: 1.1378 - val_acc: 0.5000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8455 - acc: 0.7125 - val_loss: 1.0709 - val_acc: 0.5250\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7742 - acc: 0.7375 - val_loss: 1.0476 - val_acc: 0.5625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7283 - acc: 0.7625 - val_loss: 1.0231 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6013 - acc: 0.2062 - val_loss: 1.5831 - val_acc: 0.2500\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5659 - acc: 0.2469 - val_loss: 1.5469 - val_acc: 0.3000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5132 - acc: 0.3812 - val_loss: 1.4961 - val_acc: 0.3375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4486 - acc: 0.4938 - val_loss: 1.4336 - val_acc: 0.5500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3620 - acc: 0.6125 - val_loss: 1.3542 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2550 - acc: 0.6437 - val_loss: 1.2576 - val_acc: 0.5875\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1541 - acc: 0.6125 - val_loss: 1.1694 - val_acc: 0.6125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0558 - acc: 0.6375 - val_loss: 1.1076 - val_acc: 0.6500\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9644 - acc: 0.6969 - val_loss: 1.0555 - val_acc: 0.6375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8958 - acc: 0.7219 - val_loss: 1.0035 - val_acc: 0.6500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8338 - acc: 0.7281 - val_loss: 0.9655 - val_acc: 0.6125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7773 - acc: 0.7531 - val_loss: 0.9425 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5988 - acc: 0.2031 - val_loss: 1.5774 - val_acc: 0.2000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5584 - acc: 0.2375 - val_loss: 1.5416 - val_acc: 0.1875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5105 - acc: 0.2594 - val_loss: 1.4950 - val_acc: 0.2750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4466 - acc: 0.4719 - val_loss: 1.4228 - val_acc: 0.5625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3670 - acc: 0.6406 - val_loss: 1.3254 - val_acc: 0.6375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2657 - acc: 0.6219 - val_loss: 1.2172 - val_acc: 0.6125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1628 - acc: 0.6375 - val_loss: 1.1205 - val_acc: 0.6500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0656 - acc: 0.6656 - val_loss: 1.0307 - val_acc: 0.6875\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9702 - acc: 0.7000 - val_loss: 0.9569 - val_acc: 0.7125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8846 - acc: 0.7313 - val_loss: 0.8975 - val_acc: 0.7125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8188 - acc: 0.7281 - val_loss: 0.8525 - val_acc: 0.7500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7532 - acc: 0.7719 - val_loss: 0.8157 - val_acc: 0.7500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6003 - acc: 0.2031 - val_loss: 1.5973 - val_acc: 0.1875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5688 - acc: 0.2031 - val_loss: 1.5761 - val_acc: 0.1875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5235 - acc: 0.2469 - val_loss: 1.5416 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4646 - acc: 0.3188 - val_loss: 1.5026 - val_acc: 0.2750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3980 - acc: 0.4250 - val_loss: 1.4521 - val_acc: 0.3375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3082 - acc: 0.5437 - val_loss: 1.3788 - val_acc: 0.4625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2092 - acc: 0.6500 - val_loss: 1.2940 - val_acc: 0.5000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1006 - acc: 0.6688 - val_loss: 1.2158 - val_acc: 0.5625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0011 - acc: 0.7063 - val_loss: 1.1431 - val_acc: 0.5875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9169 - acc: 0.7250 - val_loss: 1.0923 - val_acc: 0.6000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8421 - acc: 0.7406 - val_loss: 1.0337 - val_acc: 0.5875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7770 - acc: 0.7562 - val_loss: 1.0087 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6008 - acc: 0.2156 - val_loss: 1.5766 - val_acc: 0.1875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5591 - acc: 0.2219 - val_loss: 1.5349 - val_acc: 0.2250\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5110 - acc: 0.2906 - val_loss: 1.4910 - val_acc: 0.3375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4455 - acc: 0.3656 - val_loss: 1.4421 - val_acc: 0.4000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3706 - acc: 0.5406 - val_loss: 1.3616 - val_acc: 0.5625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2771 - acc: 0.6438 - val_loss: 1.2788 - val_acc: 0.5500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1798 - acc: 0.6531 - val_loss: 1.2033 - val_acc: 0.5250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0814 - acc: 0.6688 - val_loss: 1.1218 - val_acc: 0.5625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9901 - acc: 0.6875 - val_loss: 1.0599 - val_acc: 0.5750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9069 - acc: 0.6813 - val_loss: 1.0135 - val_acc: 0.5750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8297 - acc: 0.7250 - val_loss: 0.9924 - val_acc: 0.5750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7663 - acc: 0.7594 - val_loss: 0.9589 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5994 - acc: 0.2187 - val_loss: 1.6112 - val_acc: 0.1250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5548 - acc: 0.2219 - val_loss: 1.5648 - val_acc: 0.1500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4962 - acc: 0.2781 - val_loss: 1.5332 - val_acc: 0.1625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4291 - acc: 0.3000 - val_loss: 1.4742 - val_acc: 0.3000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3403 - acc: 0.4937 - val_loss: 1.3933 - val_acc: 0.4625\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2314 - acc: 0.6219 - val_loss: 1.2888 - val_acc: 0.5625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1127 - acc: 0.6844 - val_loss: 1.2088 - val_acc: 0.5875\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9949 - acc: 0.7063 - val_loss: 1.1133 - val_acc: 0.5750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9016 - acc: 0.7063 - val_loss: 1.0484 - val_acc: 0.5625\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8210 - acc: 0.7219 - val_loss: 1.0229 - val_acc: 0.5625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7420 - acc: 0.7531 - val_loss: 0.9900 - val_acc: 0.5625\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6811 - acc: 0.7625 - val_loss: 0.9603 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 1.5555 - acc: 0.2500 - val_loss: 1.2693 - val_acc: 0.3875\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0709 - acc: 0.5469 - val_loss: 0.9352 - val_acc: 0.6125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8817 - acc: 0.6219 - val_loss: 0.7686 - val_acc: 0.6750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6762 - acc: 0.7313 - val_loss: 0.9775 - val_acc: 0.6375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4440 - acc: 0.8688 - val_loss: 0.7181 - val_acc: 0.7000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2979 - acc: 0.9219 - val_loss: 0.7626 - val_acc: 0.6750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1765 - acc: 0.9563 - val_loss: 0.8128 - val_acc: 0.6750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0919 - acc: 0.9844 - val_loss: 0.8672 - val_acc: 0.6625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.8306 - val_acc: 0.6375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.7000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.8848 - val_acc: 0.7000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8385 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5637 - acc: 0.2875 - val_loss: 1.4188 - val_acc: 0.4250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1945 - acc: 0.5125 - val_loss: 1.5914 - val_acc: 0.3750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0034 - acc: 0.5750 - val_loss: 1.3246 - val_acc: 0.4625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8498 - acc: 0.6594 - val_loss: 1.2808 - val_acc: 0.5125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6023 - acc: 0.7562 - val_loss: 1.0911 - val_acc: 0.5375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3771 - acc: 0.8687 - val_loss: 1.2509 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2367 - acc: 0.9281 - val_loss: 1.2771 - val_acc: 0.5500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1160 - acc: 0.9844 - val_loss: 1.3854 - val_acc: 0.5125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0644 - acc: 0.9969 - val_loss: 1.5281 - val_acc: 0.5375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0403 - acc: 0.9938 - val_loss: 1.3451 - val_acc: 0.5875\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 1.5632 - val_acc: 0.5375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.4936 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6177 - acc: 0.2187 - val_loss: 1.5374 - val_acc: 0.2750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3711 - acc: 0.4594 - val_loss: 1.3436 - val_acc: 0.3500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1048 - acc: 0.5625 - val_loss: 1.3010 - val_acc: 0.4750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9393 - acc: 0.6219 - val_loss: 1.1466 - val_acc: 0.5375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7109 - acc: 0.7219 - val_loss: 1.2875 - val_acc: 0.4125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5079 - acc: 0.8312 - val_loss: 1.1207 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3252 - acc: 0.8875 - val_loss: 1.1849 - val_acc: 0.6125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1981 - acc: 0.9438 - val_loss: 1.0141 - val_acc: 0.6625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1045 - acc: 0.9844 - val_loss: 1.0804 - val_acc: 0.6125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0514 - acc: 0.9969 - val_loss: 1.1721 - val_acc: 0.5625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 1.4116 - val_acc: 0.5875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.1435 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6029 - acc: 0.2469 - val_loss: 1.5982 - val_acc: 0.4125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3804 - acc: 0.5062 - val_loss: 1.1616 - val_acc: 0.5375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0175 - acc: 0.5625 - val_loss: 1.1245 - val_acc: 0.5500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7840 - acc: 0.6875 - val_loss: 0.8832 - val_acc: 0.6250\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6102 - acc: 0.7906 - val_loss: 0.8374 - val_acc: 0.6375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4080 - acc: 0.8875 - val_loss: 0.8527 - val_acc: 0.6625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2469 - acc: 0.9281 - val_loss: 0.8800 - val_acc: 0.6375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1375 - acc: 0.9938 - val_loss: 0.9085 - val_acc: 0.6250\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0927 - acc: 0.9938 - val_loss: 0.9535 - val_acc: 0.6500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0666 - acc: 0.9875 - val_loss: 0.9638 - val_acc: 0.6750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0429 - acc: 0.9969 - val_loss: 0.9400 - val_acc: 0.6750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.9461 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5944 - acc: 0.2625 - val_loss: 1.5415 - val_acc: 0.2750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3556 - acc: 0.4500 - val_loss: 1.1537 - val_acc: 0.6000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0220 - acc: 0.6125 - val_loss: 0.8732 - val_acc: 0.5875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7024 - acc: 0.7313 - val_loss: 0.8878 - val_acc: 0.6000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5772 - acc: 0.7719 - val_loss: 1.0433 - val_acc: 0.5750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3669 - acc: 0.8719 - val_loss: 0.8908 - val_acc: 0.6500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2292 - acc: 0.9469 - val_loss: 0.7840 - val_acc: 0.6625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1230 - acc: 0.9812 - val_loss: 0.7930 - val_acc: 0.7000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0527 - acc: 1.0000 - val_loss: 0.8642 - val_acc: 0.6750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.9673 - val_acc: 0.6500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.9281 - val_acc: 0.6875\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.9570 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6090 - acc: 0.2594 - val_loss: 1.5434 - val_acc: 0.1625\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4416 - acc: 0.3719 - val_loss: 1.2974 - val_acc: 0.4250\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0757 - acc: 0.5531 - val_loss: 1.2065 - val_acc: 0.4875\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8733 - acc: 0.6469 - val_loss: 1.0338 - val_acc: 0.5750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6962 - acc: 0.7094 - val_loss: 1.2923 - val_acc: 0.5500\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5955 - acc: 0.7813 - val_loss: 1.1694 - val_acc: 0.5250\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3855 - acc: 0.9156 - val_loss: 1.0924 - val_acc: 0.6000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2666 - acc: 0.9250 - val_loss: 1.2490 - val_acc: 0.6000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1282 - acc: 0.9750 - val_loss: 1.2192 - val_acc: 0.6250\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0731 - acc: 0.9844 - val_loss: 0.9545 - val_acc: 0.6750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0490 - acc: 0.9938 - val_loss: 1.5760 - val_acc: 0.5500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0278 - acc: 0.9969 - val_loss: 1.1244 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5860 - acc: 0.2312 - val_loss: 1.5508 - val_acc: 0.3750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3349 - acc: 0.4656 - val_loss: 1.2371 - val_acc: 0.4750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0167 - acc: 0.5969 - val_loss: 1.3403 - val_acc: 0.5625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7776 - acc: 0.7000 - val_loss: 1.2665 - val_acc: 0.5625\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5438 - acc: 0.7719 - val_loss: 1.2883 - val_acc: 0.4750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4254 - acc: 0.8469 - val_loss: 1.2629 - val_acc: 0.5625\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2682 - acc: 0.9250 - val_loss: 1.3172 - val_acc: 0.6125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1939 - acc: 0.9375 - val_loss: 1.3219 - val_acc: 0.4625\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1207 - acc: 0.9781 - val_loss: 1.4770 - val_acc: 0.5875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0472 - acc: 0.9969 - val_loss: 1.3423 - val_acc: 0.5750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 1.4151 - val_acc: 0.6000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.6952 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5873 - acc: 0.2875 - val_loss: 1.5800 - val_acc: 0.3375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3357 - acc: 0.4750 - val_loss: 1.3032 - val_acc: 0.5000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0931 - acc: 0.5531 - val_loss: 1.1532 - val_acc: 0.4625\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8306 - acc: 0.6813 - val_loss: 1.2542 - val_acc: 0.4750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7094 - acc: 0.7125 - val_loss: 1.7414 - val_acc: 0.4250\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5610 - acc: 0.8094 - val_loss: 1.1434 - val_acc: 0.5125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3278 - acc: 0.9219 - val_loss: 1.0150 - val_acc: 0.5625\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2114 - acc: 0.9469 - val_loss: 1.2503 - val_acc: 0.5750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1224 - acc: 0.9781 - val_loss: 1.1947 - val_acc: 0.5750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0617 - acc: 1.0000 - val_loss: 1.1163 - val_acc: 0.6625\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0519 - acc: 0.9875 - val_loss: 1.2569 - val_acc: 0.6000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0423 - acc: 0.9938 - val_loss: 1.5343 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5921 - acc: 0.2531 - val_loss: 1.7266 - val_acc: 0.1250\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4380 - acc: 0.3281 - val_loss: 1.2745 - val_acc: 0.4875\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0393 - acc: 0.5938 - val_loss: 1.3066 - val_acc: 0.4750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8251 - acc: 0.6687 - val_loss: 1.5110 - val_acc: 0.3875\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7771 - acc: 0.6844 - val_loss: 1.5667 - val_acc: 0.5125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5706 - acc: 0.8156 - val_loss: 1.0395 - val_acc: 0.5750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3452 - acc: 0.8969 - val_loss: 0.9732 - val_acc: 0.6250\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2202 - acc: 0.9437 - val_loss: 0.9341 - val_acc: 0.6000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1283 - acc: 0.9812 - val_loss: 1.2243 - val_acc: 0.5875\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0964 - acc: 0.9750 - val_loss: 0.8926 - val_acc: 0.6125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0385 - acc: 0.9969 - val_loss: 0.8947 - val_acc: 0.6500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.9319 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_70 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_71 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_72 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 2s 7ms/step - loss: 10.9974 - acc: 0.1813 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.9538 - acc: 0.2219 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1813 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1813 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1813 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1813 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 13.1967 - acc: 0.1812 - val_loss: 11.6856 - val_acc: 0.2750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.9171 - acc: 0.1562 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.3655 - acc: 0.1813 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.9814 - acc: 0.1906 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.2632 - acc: 0.1594 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.0988 - acc: 0.2344 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.0515 - acc: 0.2344 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.1850 - acc: 0.2094 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/12\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_73 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_74 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_75 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_76 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.5485 - acc: 0.3188 - val_loss: 1.4351 - val_acc: 0.3125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3218 - acc: 0.4688 - val_loss: 1.2049 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1172 - acc: 0.5719 - val_loss: 1.0804 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9633 - acc: 0.6719 - val_loss: 1.0114 - val_acc: 0.5500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8375 - acc: 0.7156 - val_loss: 0.9837 - val_acc: 0.5625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7288 - acc: 0.7562 - val_loss: 0.9143 - val_acc: 0.6625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6241 - acc: 0.8156 - val_loss: 0.9183 - val_acc: 0.6500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5347 - acc: 0.8594 - val_loss: 0.8759 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4569 - acc: 0.8656 - val_loss: 0.8581 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3681 - acc: 0.9219 - val_loss: 0.8734 - val_acc: 0.6625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2971 - acc: 0.9469 - val_loss: 0.8925 - val_acc: 0.6000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2443 - acc: 0.9531 - val_loss: 0.8556 - val_acc: 0.6375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1872 - acc: 0.9812 - val_loss: 0.9163 - val_acc: 0.6250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1468 - acc: 0.9969 - val_loss: 0.8709 - val_acc: 0.6500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1069 - acc: 1.0000 - val_loss: 0.9225 - val_acc: 0.6125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0900 - acc: 1.0000 - val_loss: 0.9147 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5597 - acc: 0.2594 - val_loss: 1.4705 - val_acc: 0.4625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2638 - acc: 0.5031 - val_loss: 1.2520 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0246 - acc: 0.6219 - val_loss: 1.1051 - val_acc: 0.5125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8678 - acc: 0.7031 - val_loss: 0.9985 - val_acc: 0.5625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7397 - acc: 0.7094 - val_loss: 1.0044 - val_acc: 0.5250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6311 - acc: 0.7812 - val_loss: 1.0694 - val_acc: 0.5375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5469 - acc: 0.8562 - val_loss: 0.9433 - val_acc: 0.6000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4460 - acc: 0.8937 - val_loss: 0.9174 - val_acc: 0.5875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3831 - acc: 0.9187 - val_loss: 0.8825 - val_acc: 0.6250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3040 - acc: 0.9562 - val_loss: 0.8321 - val_acc: 0.7250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2509 - acc: 0.9656 - val_loss: 0.9074 - val_acc: 0.6375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1997 - acc: 0.9812 - val_loss: 0.8443 - val_acc: 0.6750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1484 - acc: 0.9875 - val_loss: 0.8353 - val_acc: 0.6875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1235 - acc: 0.9937 - val_loss: 0.8334 - val_acc: 0.7000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1017 - acc: 0.9969 - val_loss: 0.8465 - val_acc: 0.6500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0790 - acc: 1.0000 - val_loss: 0.8263 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5500 - acc: 0.2781 - val_loss: 1.4757 - val_acc: 0.3875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2805 - acc: 0.5656 - val_loss: 1.2620 - val_acc: 0.4500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0714 - acc: 0.5906 - val_loss: 1.1761 - val_acc: 0.5875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9188 - acc: 0.6875 - val_loss: 1.1642 - val_acc: 0.5375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7659 - acc: 0.7500 - val_loss: 0.9977 - val_acc: 0.5625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6401 - acc: 0.8062 - val_loss: 1.1042 - val_acc: 0.5375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5737 - acc: 0.8344 - val_loss: 1.0101 - val_acc: 0.6000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4661 - acc: 0.8937 - val_loss: 0.9283 - val_acc: 0.6250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3885 - acc: 0.9156 - val_loss: 0.8998 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3043 - acc: 0.9469 - val_loss: 0.9616 - val_acc: 0.6125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2389 - acc: 0.9687 - val_loss: 0.9902 - val_acc: 0.6500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2038 - acc: 0.9719 - val_loss: 0.9397 - val_acc: 0.6500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1508 - acc: 0.9906 - val_loss: 1.0105 - val_acc: 0.6625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1244 - acc: 0.9969 - val_loss: 0.9478 - val_acc: 0.6500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0977 - acc: 1.0000 - val_loss: 0.9792 - val_acc: 0.6125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0805 - acc: 1.0000 - val_loss: 0.9815 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5781 - acc: 0.2750 - val_loss: 1.4404 - val_acc: 0.4375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3561 - acc: 0.4844 - val_loss: 1.2685 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1211 - acc: 0.5469 - val_loss: 1.1150 - val_acc: 0.4750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9497 - acc: 0.6500 - val_loss: 1.0127 - val_acc: 0.5250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8239 - acc: 0.7156 - val_loss: 1.0530 - val_acc: 0.5375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7285 - acc: 0.7406 - val_loss: 1.0011 - val_acc: 0.5375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5803 - acc: 0.8250 - val_loss: 0.9992 - val_acc: 0.5625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4943 - acc: 0.8844 - val_loss: 0.9896 - val_acc: 0.5750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4020 - acc: 0.9281 - val_loss: 0.8394 - val_acc: 0.6750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3294 - acc: 0.9344 - val_loss: 0.9365 - val_acc: 0.5875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2660 - acc: 0.9531 - val_loss: 0.8986 - val_acc: 0.6625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2074 - acc: 0.9687 - val_loss: 0.8408 - val_acc: 0.7000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1704 - acc: 0.9781 - val_loss: 0.8825 - val_acc: 0.6750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1362 - acc: 0.9875 - val_loss: 0.8723 - val_acc: 0.6875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1010 - acc: 1.0000 - val_loss: 0.8916 - val_acc: 0.7250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0762 - acc: 1.0000 - val_loss: 0.8999 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5617 - acc: 0.2375 - val_loss: 1.4222 - val_acc: 0.4125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3511 - acc: 0.4594 - val_loss: 1.2114 - val_acc: 0.5500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1260 - acc: 0.5438 - val_loss: 1.0763 - val_acc: 0.6250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9612 - acc: 0.6781 - val_loss: 0.9384 - val_acc: 0.6750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8115 - acc: 0.7281 - val_loss: 0.8776 - val_acc: 0.6500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7061 - acc: 0.7844 - val_loss: 0.8209 - val_acc: 0.7000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5908 - acc: 0.8156 - val_loss: 0.7841 - val_acc: 0.7000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4837 - acc: 0.8812 - val_loss: 0.7925 - val_acc: 0.7000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4304 - acc: 0.8906 - val_loss: 0.8097 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3360 - acc: 0.9469 - val_loss: 0.6968 - val_acc: 0.7750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2541 - acc: 0.9656 - val_loss: 0.7007 - val_acc: 0.7625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2403 - acc: 0.9562 - val_loss: 0.6901 - val_acc: 0.7250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1653 - acc: 0.9937 - val_loss: 0.7071 - val_acc: 0.7125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1293 - acc: 0.9969 - val_loss: 0.6842 - val_acc: 0.7250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1115 - acc: 0.9937 - val_loss: 0.7173 - val_acc: 0.7375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0926 - acc: 0.9969 - val_loss: 0.6761 - val_acc: 0.7375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5359 - acc: 0.3188 - val_loss: 1.4501 - val_acc: 0.3750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2855 - acc: 0.5219 - val_loss: 1.2671 - val_acc: 0.4500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0656 - acc: 0.6250 - val_loss: 1.0783 - val_acc: 0.5375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8982 - acc: 0.7031 - val_loss: 0.9890 - val_acc: 0.5875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7702 - acc: 0.7469 - val_loss: 0.8360 - val_acc: 0.6875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6544 - acc: 0.8125 - val_loss: 0.8468 - val_acc: 0.7250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5385 - acc: 0.8500 - val_loss: 0.7476 - val_acc: 0.7500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4475 - acc: 0.9031 - val_loss: 0.8265 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3690 - acc: 0.9187 - val_loss: 0.6769 - val_acc: 0.7500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3005 - acc: 0.9500 - val_loss: 0.7434 - val_acc: 0.7000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2488 - acc: 0.9625 - val_loss: 0.8082 - val_acc: 0.6875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2031 - acc: 0.9781 - val_loss: 0.7834 - val_acc: 0.6875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1590 - acc: 0.9844 - val_loss: 0.7123 - val_acc: 0.7375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1281 - acc: 0.9906 - val_loss: 0.6914 - val_acc: 0.7500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1023 - acc: 1.0000 - val_loss: 0.6930 - val_acc: 0.7375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0835 - acc: 1.0000 - val_loss: 0.7700 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5492 - acc: 0.3000 - val_loss: 1.4244 - val_acc: 0.5375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3125 - acc: 0.4906 - val_loss: 1.1858 - val_acc: 0.5625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1132 - acc: 0.5688 - val_loss: 1.0657 - val_acc: 0.5875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9586 - acc: 0.6469 - val_loss: 0.9678 - val_acc: 0.5750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7907 - acc: 0.7625 - val_loss: 0.9385 - val_acc: 0.6250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7059 - acc: 0.7500 - val_loss: 0.8893 - val_acc: 0.6500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5913 - acc: 0.8469 - val_loss: 0.8270 - val_acc: 0.6625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4920 - acc: 0.9000 - val_loss: 0.8069 - val_acc: 0.6875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3950 - acc: 0.9281 - val_loss: 0.8398 - val_acc: 0.6250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3206 - acc: 0.9594 - val_loss: 0.8155 - val_acc: 0.6625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2764 - acc: 0.9656 - val_loss: 0.8004 - val_acc: 0.7125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2107 - acc: 0.9875 - val_loss: 0.7674 - val_acc: 0.7000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1683 - acc: 0.9875 - val_loss: 0.7614 - val_acc: 0.7375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1317 - acc: 0.9875 - val_loss: 0.7994 - val_acc: 0.7500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1060 - acc: 0.9906 - val_loss: 0.7785 - val_acc: 0.7125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0878 - acc: 0.9969 - val_loss: 0.7724 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5540 - acc: 0.2969 - val_loss: 1.3918 - val_acc: 0.3875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3478 - acc: 0.4469 - val_loss: 1.2177 - val_acc: 0.5250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1346 - acc: 0.5938 - val_loss: 1.0851 - val_acc: 0.5625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9623 - acc: 0.6594 - val_loss: 0.9722 - val_acc: 0.6375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8049 - acc: 0.7406 - val_loss: 0.8931 - val_acc: 0.6375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6833 - acc: 0.7781 - val_loss: 0.9354 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5827 - acc: 0.8312 - val_loss: 0.8675 - val_acc: 0.6625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4476 - acc: 0.9156 - val_loss: 0.8135 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3790 - acc: 0.9187 - val_loss: 0.8721 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2902 - acc: 0.9625 - val_loss: 0.7815 - val_acc: 0.6750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2385 - acc: 0.9656 - val_loss: 0.8004 - val_acc: 0.7000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1821 - acc: 0.9812 - val_loss: 0.8079 - val_acc: 0.6875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1625 - acc: 0.9875 - val_loss: 0.8008 - val_acc: 0.6875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1168 - acc: 0.9969 - val_loss: 0.8098 - val_acc: 0.7000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1004 - acc: 0.9937 - val_loss: 0.8685 - val_acc: 0.6625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0754 - acc: 0.9969 - val_loss: 0.8587 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5235 - acc: 0.3406 - val_loss: 1.5045 - val_acc: 0.4250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2700 - acc: 0.5156 - val_loss: 1.3421 - val_acc: 0.4875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0501 - acc: 0.6375 - val_loss: 1.2013 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8902 - acc: 0.6906 - val_loss: 1.1307 - val_acc: 0.5750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7415 - acc: 0.7375 - val_loss: 1.1622 - val_acc: 0.5625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6374 - acc: 0.7844 - val_loss: 1.0569 - val_acc: 0.5750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5360 - acc: 0.8500 - val_loss: 1.1293 - val_acc: 0.5625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4826 - acc: 0.8812 - val_loss: 1.1044 - val_acc: 0.6250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3847 - acc: 0.8875 - val_loss: 1.0813 - val_acc: 0.5750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3224 - acc: 0.9250 - val_loss: 1.0130 - val_acc: 0.6375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2520 - acc: 0.9562 - val_loss: 1.0640 - val_acc: 0.6125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1911 - acc: 0.9875 - val_loss: 0.9851 - val_acc: 0.6000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1539 - acc: 0.9875 - val_loss: 0.9791 - val_acc: 0.6000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1192 - acc: 0.9969 - val_loss: 1.0338 - val_acc: 0.6125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0958 - acc: 1.0000 - val_loss: 1.0220 - val_acc: 0.6000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0804 - acc: 1.0000 - val_loss: 1.0199 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_39 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_77 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_78 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3121 - acc: 0.4406 - val_loss: 1.1404 - val_acc: 0.5500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0035 - acc: 0.5719 - val_loss: 1.1859 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7165 - acc: 0.7594 - val_loss: 0.9409 - val_acc: 0.6125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3982 - acc: 0.8625 - val_loss: 0.7030 - val_acc: 0.6625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2260 - acc: 0.9125 - val_loss: 1.1961 - val_acc: 0.5500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0881 - acc: 0.9812 - val_loss: 1.0193 - val_acc: 0.6625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0391 - acc: 0.9937 - val_loss: 0.9044 - val_acc: 0.7125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.0366 - val_acc: 0.6500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.6500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.1073 - val_acc: 0.6625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.6500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.1103 - val_acc: 0.6625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.1209 - val_acc: 0.6625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.1151 - val_acc: 0.6625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.6584e-04 - acc: 1.0000 - val_loss: 1.1462 - val_acc: 0.6625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.4709e-04 - acc: 1.0000 - val_loss: 1.1425 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5788 - acc: 0.4219 - val_loss: 2.1092 - val_acc: 0.3875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1118 - acc: 0.5781 - val_loss: 1.7618 - val_acc: 0.4250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8278 - acc: 0.6813 - val_loss: 1.4812 - val_acc: 0.4750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4727 - acc: 0.8187 - val_loss: 1.2504 - val_acc: 0.5500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1966 - acc: 0.9406 - val_loss: 1.7094 - val_acc: 0.5125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0850 - acc: 0.9719 - val_loss: 1.4750 - val_acc: 0.5375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 1.5864 - val_acc: 0.5875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.5594 - val_acc: 0.5750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.6236 - val_acc: 0.5750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.6520 - val_acc: 0.5750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.6815 - val_acc: 0.5750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.7049 - val_acc: 0.5875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.7267 - val_acc: 0.5750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.9762e-04 - acc: 1.0000 - val_loss: 1.7439 - val_acc: 0.5750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.8253e-04 - acc: 1.0000 - val_loss: 1.7603 - val_acc: 0.5875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.8065e-04 - acc: 1.0000 - val_loss: 1.7771 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6360 - acc: 0.3875 - val_loss: 1.1432 - val_acc: 0.5375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4915 - acc: 0.4344 - val_loss: 0.9737 - val_acc: 0.6500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8809 - acc: 0.6437 - val_loss: 1.0520 - val_acc: 0.6125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5138 - acc: 0.8219 - val_loss: 1.1697 - val_acc: 0.6250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2748 - acc: 0.8906 - val_loss: 1.0607 - val_acc: 0.6375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0553 - acc: 0.9937 - val_loss: 1.4500 - val_acc: 0.5875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 1.5117 - val_acc: 0.6500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.3736 - val_acc: 0.6875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.4048 - val_acc: 0.6250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.4071 - val_acc: 0.6250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.4534 - val_acc: 0.6500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.4634 - val_acc: 0.6375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.4846 - val_acc: 0.6250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.2245e-04 - acc: 1.0000 - val_loss: 1.4922 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.3478e-04 - acc: 1.0000 - val_loss: 1.5105 - val_acc: 0.6375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.5360e-04 - acc: 1.0000 - val_loss: 1.5249 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5971 - acc: 0.3031 - val_loss: 1.7425 - val_acc: 0.5125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1095 - acc: 0.5438 - val_loss: 1.1757 - val_acc: 0.5125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8761 - acc: 0.6969 - val_loss: 0.9954 - val_acc: 0.5750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4856 - acc: 0.8187 - val_loss: 1.2626 - val_acc: 0.5625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2096 - acc: 0.9281 - val_loss: 1.1762 - val_acc: 0.6000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0789 - acc: 0.9812 - val_loss: 1.5227 - val_acc: 0.5750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0217 - acc: 1.0000 - val_loss: 1.7984 - val_acc: 0.5375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.4683 - val_acc: 0.5750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.7010 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0082 - acc: 0.9969 - val_loss: 1.6177 - val_acc: 0.5875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0064 - acc: 0.9969 - val_loss: 1.5218 - val_acc: 0.5750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.7270 - val_acc: 0.5875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.6832 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.8914e-04 - acc: 1.0000 - val_loss: 1.6900 - val_acc: 0.5750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.5788e-04 - acc: 1.0000 - val_loss: 1.7021 - val_acc: 0.5625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 6.6679e-04 - acc: 1.0000 - val_loss: 1.7099 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4354 - acc: 0.4375 - val_loss: 1.3902 - val_acc: 0.5625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1378 - acc: 0.5406 - val_loss: 1.6073 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7256 - acc: 0.7156 - val_loss: 1.1286 - val_acc: 0.5875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5155 - acc: 0.8156 - val_loss: 1.6963 - val_acc: 0.5125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3237 - acc: 0.8625 - val_loss: 1.9338 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1586 - acc: 0.9562 - val_loss: 2.4795 - val_acc: 0.4750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0473 - acc: 0.9906 - val_loss: 1.5929 - val_acc: 0.6125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0296 - acc: 0.9906 - val_loss: 2.6219 - val_acc: 0.5125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0146 - acc: 0.9969 - val_loss: 1.5394 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.8317 - val_acc: 0.5625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.7831 - val_acc: 0.5875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.4623e-04 - acc: 1.0000 - val_loss: 1.7514 - val_acc: 0.6000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.8069e-04 - acc: 1.0000 - val_loss: 1.7546 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 6.8044e-04 - acc: 1.0000 - val_loss: 1.7708 - val_acc: 0.6125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 6.0136e-04 - acc: 1.0000 - val_loss: 1.7792 - val_acc: 0.6125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 5.4209e-04 - acc: 1.0000 - val_loss: 1.7952 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5579 - acc: 0.3844 - val_loss: 1.8382 - val_acc: 0.4500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2864 - acc: 0.5000 - val_loss: 1.1862 - val_acc: 0.4625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8556 - acc: 0.6469 - val_loss: 1.1095 - val_acc: 0.5250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5966 - acc: 0.7625 - val_loss: 1.6869 - val_acc: 0.4625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3594 - acc: 0.8719 - val_loss: 1.3923 - val_acc: 0.4250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1432 - acc: 0.9562 - val_loss: 2.1603 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0523 - acc: 0.9812 - val_loss: 1.8240 - val_acc: 0.5375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.9076 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.0740 - val_acc: 0.5500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.0977 - val_acc: 0.5250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0720 - val_acc: 0.5375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.1080 - val_acc: 0.5250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.1506e-04 - acc: 1.0000 - val_loss: 2.1350 - val_acc: 0.5250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.8583e-04 - acc: 1.0000 - val_loss: 2.1445 - val_acc: 0.5250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.0098e-04 - acc: 1.0000 - val_loss: 2.1622 - val_acc: 0.5250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 6.3675e-04 - acc: 1.0000 - val_loss: 2.1880 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5748 - acc: 0.3969 - val_loss: 1.5650 - val_acc: 0.2750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2811 - acc: 0.4781 - val_loss: 1.3080 - val_acc: 0.4875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8594 - acc: 0.6656 - val_loss: 1.1283 - val_acc: 0.6750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4711 - acc: 0.8375 - val_loss: 1.4134 - val_acc: 0.5625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2503 - acc: 0.9219 - val_loss: 1.4985 - val_acc: 0.6000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1783 - acc: 0.9219 - val_loss: 1.1560 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0480 - acc: 0.9844 - val_loss: 1.4979 - val_acc: 0.6125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0297 - acc: 0.9875 - val_loss: 1.2898 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.3483 - val_acc: 0.7125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.3866 - val_acc: 0.6875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.2545e-04 - acc: 1.0000 - val_loss: 1.3741 - val_acc: 0.7125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 6.7452e-04 - acc: 1.0000 - val_loss: 1.3847 - val_acc: 0.7125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 5.8782e-04 - acc: 1.0000 - val_loss: 1.3903 - val_acc: 0.7125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 5.1580e-04 - acc: 1.0000 - val_loss: 1.3997 - val_acc: 0.7125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 4.6662e-04 - acc: 1.0000 - val_loss: 1.4111 - val_acc: 0.7000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 4.2211e-04 - acc: 1.0000 - val_loss: 1.4219 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6055 - acc: 0.3281 - val_loss: 1.3592 - val_acc: 0.5375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1559 - acc: 0.5469 - val_loss: 1.4276 - val_acc: 0.4625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8425 - acc: 0.6531 - val_loss: 1.3575 - val_acc: 0.4875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4792 - acc: 0.8281 - val_loss: 1.2042 - val_acc: 0.5750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1997 - acc: 0.9375 - val_loss: 1.3375 - val_acc: 0.6000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0332 - acc: 0.9937 - val_loss: 1.3173 - val_acc: 0.6000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 1.4564 - val_acc: 0.6000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.5022 - val_acc: 0.6000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.5390 - val_acc: 0.6000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.5703 - val_acc: 0.6125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.5954 - val_acc: 0.6000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.6162 - val_acc: 0.6000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.6455 - val_acc: 0.6000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.6573 - val_acc: 0.6000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.4291e-04 - acc: 1.0000 - val_loss: 1.6761 - val_acc: 0.6000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 8.5593e-04 - acc: 1.0000 - val_loss: 1.6850 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5740 - acc: 0.3188 - val_loss: 1.3344 - val_acc: 0.4125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2125 - acc: 0.5750 - val_loss: 1.2321 - val_acc: 0.5125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8507 - acc: 0.6438 - val_loss: 1.3216 - val_acc: 0.5500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4706 - acc: 0.8062 - val_loss: 1.4322 - val_acc: 0.5625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2076 - acc: 0.9281 - val_loss: 1.2838 - val_acc: 0.5625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0674 - acc: 0.9781 - val_loss: 1.3767 - val_acc: 0.6375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0220 - acc: 0.9969 - val_loss: 1.8979 - val_acc: 0.6375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.7550 - val_acc: 0.5750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.6037 - val_acc: 0.5875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.6433 - val_acc: 0.6250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.6382 - val_acc: 0.6125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 9.0762e-04 - acc: 1.0000 - val_loss: 1.6666 - val_acc: 0.6250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.9073e-04 - acc: 1.0000 - val_loss: 1.6881 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 7.0480e-04 - acc: 1.0000 - val_loss: 1.7086 - val_acc: 0.6125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 6.4059e-04 - acc: 1.0000 - val_loss: 1.7264 - val_acc: 0.6000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 5.8218e-04 - acc: 1.0000 - val_loss: 1.7339 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_81 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_82 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_83 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_84 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 12.6412 - acc: 0.1969 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.6064 - acc: 0.1969 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5924 - acc: 0.1906 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.3410 - acc: 0.2094 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5923 - acc: 0.2188 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.2391 - acc: 0.2219 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4915 - acc: 0.2250 - val_loss: 14.5063 - val_acc: 0.1000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5414 - acc: 0.2000 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7929 - acc: 0.1844 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 13.0456 - acc: 0.1906 - val_loss: 12.2900 - val_acc: 0.2375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.4401 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.5421 - acc: 0.2000 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_43 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_85 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_86 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_87 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_88 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.5828 - acc: 0.3844 - val_loss: 1.5692 - val_acc: 0.3625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4877 - acc: 0.4219 - val_loss: 1.4872 - val_acc: 0.3875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3640 - acc: 0.4781 - val_loss: 1.3746 - val_acc: 0.4375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2266 - acc: 0.5312 - val_loss: 1.2627 - val_acc: 0.5250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0898 - acc: 0.6188 - val_loss: 1.1717 - val_acc: 0.5875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9860 - acc: 0.6531 - val_loss: 1.1087 - val_acc: 0.6000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8957 - acc: 0.6813 - val_loss: 1.0776 - val_acc: 0.6000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8040 - acc: 0.7531 - val_loss: 1.0453 - val_acc: 0.6000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7366 - acc: 0.7750 - val_loss: 1.0205 - val_acc: 0.5875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6699 - acc: 0.7719 - val_loss: 1.0211 - val_acc: 0.6250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5988 - acc: 0.8469 - val_loss: 1.0327 - val_acc: 0.6125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5476 - acc: 0.8406 - val_loss: 0.9976 - val_acc: 0.6250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4818 - acc: 0.8875 - val_loss: 1.0286 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4477 - acc: 0.8750 - val_loss: 0.9948 - val_acc: 0.6250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3906 - acc: 0.9000 - val_loss: 0.9583 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3534 - acc: 0.9312 - val_loss: 0.9732 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6072 - acc: 0.3281 - val_loss: 1.6119 - val_acc: 0.2625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5499 - acc: 0.4125 - val_loss: 1.5697 - val_acc: 0.3625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4808 - acc: 0.4563 - val_loss: 1.5164 - val_acc: 0.3750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3794 - acc: 0.4625 - val_loss: 1.4259 - val_acc: 0.4250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2471 - acc: 0.5750 - val_loss: 1.3330 - val_acc: 0.4875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0969 - acc: 0.6062 - val_loss: 1.2080 - val_acc: 0.5125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9549 - acc: 0.7063 - val_loss: 1.1487 - val_acc: 0.5125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8513 - acc: 0.7313 - val_loss: 1.0752 - val_acc: 0.5125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7543 - acc: 0.7656 - val_loss: 1.0270 - val_acc: 0.5375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6770 - acc: 0.7937 - val_loss: 0.9912 - val_acc: 0.5375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5885 - acc: 0.8250 - val_loss: 1.0071 - val_acc: 0.5375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5432 - acc: 0.8438 - val_loss: 0.9700 - val_acc: 0.5500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4811 - acc: 0.8656 - val_loss: 0.9459 - val_acc: 0.5750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4221 - acc: 0.8844 - val_loss: 0.9215 - val_acc: 0.6125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3828 - acc: 0.8906 - val_loss: 0.9353 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3420 - acc: 0.9187 - val_loss: 0.9428 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5898 - acc: 0.3594 - val_loss: 1.6190 - val_acc: 0.3125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5409 - acc: 0.4188 - val_loss: 1.5948 - val_acc: 0.3125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4718 - acc: 0.4312 - val_loss: 1.5368 - val_acc: 0.3375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3925 - acc: 0.4344 - val_loss: 1.4752 - val_acc: 0.3375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2704 - acc: 0.4844 - val_loss: 1.3846 - val_acc: 0.3750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1513 - acc: 0.5250 - val_loss: 1.2970 - val_acc: 0.4500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0684 - acc: 0.6031 - val_loss: 1.2587 - val_acc: 0.4625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9711 - acc: 0.6094 - val_loss: 1.1921 - val_acc: 0.5125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9058 - acc: 0.6781 - val_loss: 1.1337 - val_acc: 0.5500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8257 - acc: 0.7219 - val_loss: 1.1219 - val_acc: 0.5375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7655 - acc: 0.7250 - val_loss: 1.0629 - val_acc: 0.5625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7221 - acc: 0.7750 - val_loss: 1.0592 - val_acc: 0.6000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6660 - acc: 0.7906 - val_loss: 1.0422 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5996 - acc: 0.8312 - val_loss: 0.9992 - val_acc: 0.5625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5341 - acc: 0.8437 - val_loss: 0.9872 - val_acc: 0.6000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4883 - acc: 0.8906 - val_loss: 0.9560 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5868 - acc: 0.3406 - val_loss: 1.6341 - val_acc: 0.2500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5357 - acc: 0.4125 - val_loss: 1.6277 - val_acc: 0.3000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4807 - acc: 0.4344 - val_loss: 1.5891 - val_acc: 0.3125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3982 - acc: 0.4500 - val_loss: 1.5210 - val_acc: 0.3125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2978 - acc: 0.4719 - val_loss: 1.4331 - val_acc: 0.3250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1943 - acc: 0.5250 - val_loss: 1.3523 - val_acc: 0.4250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0797 - acc: 0.5781 - val_loss: 1.2528 - val_acc: 0.4500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9872 - acc: 0.6531 - val_loss: 1.2253 - val_acc: 0.4500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9027 - acc: 0.6281 - val_loss: 1.1155 - val_acc: 0.5375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8321 - acc: 0.7281 - val_loss: 1.0855 - val_acc: 0.5375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7493 - acc: 0.7969 - val_loss: 1.1036 - val_acc: 0.5000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6857 - acc: 0.8063 - val_loss: 1.0166 - val_acc: 0.5750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6289 - acc: 0.8188 - val_loss: 0.9804 - val_acc: 0.5750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5644 - acc: 0.8594 - val_loss: 1.0269 - val_acc: 0.5750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5079 - acc: 0.8781 - val_loss: 0.9913 - val_acc: 0.5625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4660 - acc: 0.8937 - val_loss: 0.9678 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5973 - acc: 0.3594 - val_loss: 1.5654 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5549 - acc: 0.4531 - val_loss: 1.5248 - val_acc: 0.4875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4878 - acc: 0.4844 - val_loss: 1.4367 - val_acc: 0.5500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3877 - acc: 0.5062 - val_loss: 1.3386 - val_acc: 0.5375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2639 - acc: 0.5344 - val_loss: 1.2179 - val_acc: 0.5500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1341 - acc: 0.5500 - val_loss: 1.1165 - val_acc: 0.5500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0315 - acc: 0.6219 - val_loss: 1.1143 - val_acc: 0.5375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9013 - acc: 0.6594 - val_loss: 0.9736 - val_acc: 0.6375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8199 - acc: 0.7094 - val_loss: 0.9464 - val_acc: 0.6750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7756 - acc: 0.7469 - val_loss: 0.9151 - val_acc: 0.6125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6778 - acc: 0.7937 - val_loss: 0.8520 - val_acc: 0.6875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6071 - acc: 0.8375 - val_loss: 0.8730 - val_acc: 0.6500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5407 - acc: 0.8594 - val_loss: 0.8002 - val_acc: 0.7125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5115 - acc: 0.8469 - val_loss: 0.7928 - val_acc: 0.7000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4477 - acc: 0.8937 - val_loss: 0.7913 - val_acc: 0.7000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3915 - acc: 0.9344 - val_loss: 0.8102 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5965 - acc: 0.3500 - val_loss: 1.5878 - val_acc: 0.3500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5507 - acc: 0.4156 - val_loss: 1.5555 - val_acc: 0.3625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4740 - acc: 0.4250 - val_loss: 1.5014 - val_acc: 0.3625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3720 - acc: 0.4375 - val_loss: 1.4408 - val_acc: 0.3750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2517 - acc: 0.4531 - val_loss: 1.3521 - val_acc: 0.3875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1292 - acc: 0.5625 - val_loss: 1.2678 - val_acc: 0.4875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0257 - acc: 0.6375 - val_loss: 1.2259 - val_acc: 0.4625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9313 - acc: 0.6594 - val_loss: 1.1772 - val_acc: 0.4875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8589 - acc: 0.7375 - val_loss: 1.1884 - val_acc: 0.4125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8153 - acc: 0.7031 - val_loss: 1.1098 - val_acc: 0.4500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7425 - acc: 0.7687 - val_loss: 1.1208 - val_acc: 0.5000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6545 - acc: 0.8187 - val_loss: 1.0941 - val_acc: 0.4625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6048 - acc: 0.8125 - val_loss: 1.0707 - val_acc: 0.5125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5661 - acc: 0.8437 - val_loss: 1.0446 - val_acc: 0.5000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4926 - acc: 0.8844 - val_loss: 1.0675 - val_acc: 0.5375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4436 - acc: 0.9031 - val_loss: 1.0044 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5965 - acc: 0.3062 - val_loss: 1.5818 - val_acc: 0.2375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5599 - acc: 0.3312 - val_loss: 1.5647 - val_acc: 0.3000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5087 - acc: 0.4187 - val_loss: 1.5313 - val_acc: 0.4375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4529 - acc: 0.4438 - val_loss: 1.4935 - val_acc: 0.4250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3773 - acc: 0.4688 - val_loss: 1.4327 - val_acc: 0.4625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2837 - acc: 0.5219 - val_loss: 1.3591 - val_acc: 0.4625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1853 - acc: 0.5563 - val_loss: 1.2959 - val_acc: 0.4250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0834 - acc: 0.6219 - val_loss: 1.2182 - val_acc: 0.5500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9848 - acc: 0.6969 - val_loss: 1.1786 - val_acc: 0.5250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8998 - acc: 0.7219 - val_loss: 1.1277 - val_acc: 0.5500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8254 - acc: 0.7375 - val_loss: 1.1236 - val_acc: 0.5500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7404 - acc: 0.8000 - val_loss: 1.1022 - val_acc: 0.5500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6860 - acc: 0.8094 - val_loss: 1.0673 - val_acc: 0.5375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6176 - acc: 0.8500 - val_loss: 1.0324 - val_acc: 0.5625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5468 - acc: 0.8719 - val_loss: 1.0445 - val_acc: 0.5750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4961 - acc: 0.8937 - val_loss: 0.9967 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6067 - acc: 0.3375 - val_loss: 1.5511 - val_acc: 0.4875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5581 - acc: 0.3906 - val_loss: 1.5145 - val_acc: 0.4875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4881 - acc: 0.4188 - val_loss: 1.4454 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3948 - acc: 0.4875 - val_loss: 1.3453 - val_acc: 0.5000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2669 - acc: 0.5000 - val_loss: 1.2413 - val_acc: 0.4250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1290 - acc: 0.5719 - val_loss: 1.1375 - val_acc: 0.4625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0303 - acc: 0.6250 - val_loss: 1.0500 - val_acc: 0.5250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9420 - acc: 0.6469 - val_loss: 1.0252 - val_acc: 0.5375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8646 - acc: 0.7000 - val_loss: 0.9761 - val_acc: 0.5625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7975 - acc: 0.6906 - val_loss: 0.9590 - val_acc: 0.5625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7336 - acc: 0.7656 - val_loss: 0.9266 - val_acc: 0.5375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6766 - acc: 0.7906 - val_loss: 0.9197 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6383 - acc: 0.7938 - val_loss: 0.9015 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5612 - acc: 0.8375 - val_loss: 0.8405 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5131 - acc: 0.8500 - val_loss: 0.8287 - val_acc: 0.6125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4789 - acc: 0.8875 - val_loss: 0.8003 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6004 - acc: 0.3312 - val_loss: 1.5527 - val_acc: 0.4375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5627 - acc: 0.3844 - val_loss: 1.5345 - val_acc: 0.4625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5158 - acc: 0.4219 - val_loss: 1.4922 - val_acc: 0.4750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4481 - acc: 0.4500 - val_loss: 1.4376 - val_acc: 0.4750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3795 - acc: 0.4625 - val_loss: 1.3899 - val_acc: 0.4625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2842 - acc: 0.4781 - val_loss: 1.3122 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1824 - acc: 0.5500 - val_loss: 1.2595 - val_acc: 0.5125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0830 - acc: 0.5969 - val_loss: 1.2055 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0027 - acc: 0.6406 - val_loss: 1.1327 - val_acc: 0.5625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9222 - acc: 0.6750 - val_loss: 1.1119 - val_acc: 0.5000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8419 - acc: 0.7094 - val_loss: 1.1054 - val_acc: 0.5750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7659 - acc: 0.7625 - val_loss: 1.0405 - val_acc: 0.5500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6966 - acc: 0.8156 - val_loss: 1.0208 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6257 - acc: 0.8531 - val_loss: 1.0290 - val_acc: 0.5500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5586 - acc: 0.8531 - val_loss: 0.9881 - val_acc: 0.5625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5036 - acc: 0.8812 - val_loss: 0.9766 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_45 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_89 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_90 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_91 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_92 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.4222 - acc: 0.3719 - val_loss: 1.3480 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9532 - acc: 0.6437 - val_loss: 1.1489 - val_acc: 0.5250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7401 - acc: 0.7250 - val_loss: 1.0298 - val_acc: 0.5750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4493 - acc: 0.8625 - val_loss: 1.0981 - val_acc: 0.6250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2964 - acc: 0.8969 - val_loss: 0.7754 - val_acc: 0.7125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1217 - acc: 0.9812 - val_loss: 0.9985 - val_acc: 0.7125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.8377 - val_acc: 0.6875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 1.1112 - val_acc: 0.6500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.0155 - val_acc: 0.6750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0860 - val_acc: 0.6875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.0819 - val_acc: 0.7000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.0557 - val_acc: 0.7125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.0693 - val_acc: 0.7000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.0694 - val_acc: 0.7000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.0924 - val_acc: 0.7000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.1003 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4872 - acc: 0.3344 - val_loss: 1.8910 - val_acc: 0.3125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2489 - acc: 0.5219 - val_loss: 0.9954 - val_acc: 0.6250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8494 - acc: 0.6719 - val_loss: 1.0989 - val_acc: 0.5625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7542 - acc: 0.7250 - val_loss: 1.1229 - val_acc: 0.5875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3920 - acc: 0.8812 - val_loss: 0.9011 - val_acc: 0.6500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1306 - acc: 0.9687 - val_loss: 1.0450 - val_acc: 0.6750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0526 - acc: 1.0000 - val_loss: 1.0418 - val_acc: 0.6625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.0905 - val_acc: 0.7000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.1224 - val_acc: 0.6750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.1222 - val_acc: 0.6750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.1371 - val_acc: 0.6875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.1399 - val_acc: 0.6750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.1436 - val_acc: 0.6750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.1755 - val_acc: 0.6625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.1576 - val_acc: 0.6750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.1667 - val_acc: 0.6875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4258 - acc: 0.3531 - val_loss: 1.2134 - val_acc: 0.5125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3230 - acc: 0.4906 - val_loss: 1.2270 - val_acc: 0.5250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9981 - acc: 0.6156 - val_loss: 1.2986 - val_acc: 0.5250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6178 - acc: 0.7594 - val_loss: 0.9112 - val_acc: 0.6375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2273 - acc: 0.9375 - val_loss: 0.9747 - val_acc: 0.6000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1094 - acc: 0.9750 - val_loss: 1.0307 - val_acc: 0.6625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0449 - acc: 0.9844 - val_loss: 0.9245 - val_acc: 0.7000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.1198 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0402 - val_acc: 0.6500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.0858 - val_acc: 0.6500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.1284 - val_acc: 0.6625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.1182 - val_acc: 0.6500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.1292 - val_acc: 0.6500\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.1194 - val_acc: 0.6500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.1471 - val_acc: 0.6500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.1493 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4782 - acc: 0.3500 - val_loss: 1.2877 - val_acc: 0.4375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1980 - acc: 0.5125 - val_loss: 1.2767 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9142 - acc: 0.6531 - val_loss: 1.0442 - val_acc: 0.5125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5735 - acc: 0.7844 - val_loss: 1.2046 - val_acc: 0.5500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2917 - acc: 0.9031 - val_loss: 1.1556 - val_acc: 0.6125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2060 - acc: 0.9281 - val_loss: 1.2575 - val_acc: 0.6000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0548 - acc: 0.9937 - val_loss: 1.1382 - val_acc: 0.6000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0245 - acc: 0.9969 - val_loss: 1.3120 - val_acc: 0.5625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.2873 - val_acc: 0.5750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.3723 - val_acc: 0.5250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.3392 - val_acc: 0.5500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.3589 - val_acc: 0.5500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.3497 - val_acc: 0.5625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3819 - val_acc: 0.5500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.3948 - val_acc: 0.5500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.4049 - val_acc: 0.5500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4855 - acc: 0.3344 - val_loss: 1.3186 - val_acc: 0.5875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1024 - acc: 0.5844 - val_loss: 1.4349 - val_acc: 0.5625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7973 - acc: 0.7156 - val_loss: 1.2424 - val_acc: 0.4375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5204 - acc: 0.8187 - val_loss: 0.8560 - val_acc: 0.6500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2332 - acc: 0.9344 - val_loss: 1.1061 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0951 - acc: 0.9906 - val_loss: 0.8731 - val_acc: 0.6750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.9678 - val_acc: 0.6375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.8021 - val_acc: 0.6750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0716 - val_acc: 0.6250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9292 - val_acc: 0.6625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9479 - val_acc: 0.6375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9794 - val_acc: 0.6500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.6625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.9683 - val_acc: 0.6500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.6500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0006 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4785 - acc: 0.3281 - val_loss: 1.4399 - val_acc: 0.4375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2284 - acc: 0.5219 - val_loss: 1.9166 - val_acc: 0.4625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8700 - acc: 0.6438 - val_loss: 1.2781 - val_acc: 0.4125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5158 - acc: 0.8031 - val_loss: 1.0868 - val_acc: 0.5875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2551 - acc: 0.9312 - val_loss: 1.3589 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1261 - acc: 0.9562 - val_loss: 1.1486 - val_acc: 0.5750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0537 - acc: 0.9875 - val_loss: 1.0602 - val_acc: 0.6000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0277 - acc: 0.9969 - val_loss: 1.1524 - val_acc: 0.5625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.0570 - val_acc: 0.6125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 1.5844 - val_acc: 0.5250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.1848 - val_acc: 0.6125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.5714 - val_acc: 0.5250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.5550 - val_acc: 0.5500\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.4531 - val_acc: 0.5625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.4209 - val_acc: 0.5750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.4295 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4592 - acc: 0.3500 - val_loss: 1.5161 - val_acc: 0.4500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2032 - acc: 0.5188 - val_loss: 1.5637 - val_acc: 0.4875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0206 - acc: 0.6188 - val_loss: 1.0862 - val_acc: 0.5125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5864 - acc: 0.7875 - val_loss: 0.9939 - val_acc: 0.5750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2903 - acc: 0.9156 - val_loss: 1.2629 - val_acc: 0.5750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1734 - acc: 0.9437 - val_loss: 1.6693 - val_acc: 0.5375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1145 - acc: 0.9594 - val_loss: 1.5121 - val_acc: 0.6250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0321 - acc: 0.9969 - val_loss: 1.4050 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.5314 - val_acc: 0.6250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.4923 - val_acc: 0.6000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.4991 - val_acc: 0.6125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.4786 - val_acc: 0.6250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.4743 - val_acc: 0.6250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.4869 - val_acc: 0.6250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.4955 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.3730e-04 - acc: 1.0000 - val_loss: 1.4957 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4279 - acc: 0.3156 - val_loss: 1.2589 - val_acc: 0.3250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1964 - acc: 0.5219 - val_loss: 1.3071 - val_acc: 0.5875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6887 - acc: 0.7344 - val_loss: 0.9256 - val_acc: 0.6750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4239 - acc: 0.8594 - val_loss: 0.9412 - val_acc: 0.6375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1592 - acc: 0.9687 - val_loss: 0.8047 - val_acc: 0.7750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.8471 - val_acc: 0.7875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.0202 - val_acc: 0.6625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.9269 - val_acc: 0.7375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.9424 - val_acc: 0.7375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9560 - val_acc: 0.7625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9610 - val_acc: 0.7375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.9525 - val_acc: 0.7625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.9740 - val_acc: 0.7625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9729 - val_acc: 0.7500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9768 - val_acc: 0.7500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9770 - val_acc: 0.7500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4943 - acc: 0.3281 - val_loss: 1.5222 - val_acc: 0.4875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2997 - acc: 0.4344 - val_loss: 1.2278 - val_acc: 0.4250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0270 - acc: 0.6000 - val_loss: 1.0709 - val_acc: 0.5500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5978 - acc: 0.7875 - val_loss: 1.4739 - val_acc: 0.6000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4603 - acc: 0.8625 - val_loss: 1.0809 - val_acc: 0.6625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1456 - acc: 0.9562 - val_loss: 1.1001 - val_acc: 0.6250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0668 - acc: 0.9844 - val_loss: 1.4622 - val_acc: 0.6125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0237 - acc: 0.9937 - val_loss: 1.5772 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.4652 - val_acc: 0.5750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.5234 - val_acc: 0.6125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.6112 - val_acc: 0.6375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.5795 - val_acc: 0.6375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.5776 - val_acc: 0.6500\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.5978 - val_acc: 0.6500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.6030 - val_acc: 0.6625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6189e-04 - acc: 1.0000 - val_loss: 1.6156 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_47 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_93 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_94 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_95 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_96 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 10ms/step - loss: 12.1259 - acc: 0.1844 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.8088 - acc: 0.2219 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.3470 - acc: 0.2187 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.5005 - acc: 0.2125 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.4108 - acc: 0.2062 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.3217 - acc: 0.2219 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.5277 - acc: 0.2031 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9448 - acc: 0.1969 - val_loss: 12.6930 - val_acc: 0.2125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.6499 - acc: 0.1781 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8945 - acc: 0.2000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 11.7408 - acc: 0.2187 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_49 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_97 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_98 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_99 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_100 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.6092 - acc: 0.1938 - val_loss: 1.5838 - val_acc: 0.2250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5618 - acc: 0.2156 - val_loss: 1.5500 - val_acc: 0.2625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4997 - acc: 0.4563 - val_loss: 1.4843 - val_acc: 0.4875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4061 - acc: 0.6094 - val_loss: 1.3908 - val_acc: 0.4375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2945 - acc: 0.5656 - val_loss: 1.2849 - val_acc: 0.4875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1810 - acc: 0.5688 - val_loss: 1.1837 - val_acc: 0.5500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0786 - acc: 0.6094 - val_loss: 1.1311 - val_acc: 0.5750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9938 - acc: 0.6281 - val_loss: 1.0716 - val_acc: 0.5625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9133 - acc: 0.6750 - val_loss: 1.0506 - val_acc: 0.5875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8605 - acc: 0.7219 - val_loss: 1.0029 - val_acc: 0.6250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8014 - acc: 0.7406 - val_loss: 0.9933 - val_acc: 0.6250\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7529 - acc: 0.7469 - val_loss: 0.9627 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7089 - acc: 0.7562 - val_loss: 0.9558 - val_acc: 0.6500\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6717 - acc: 0.7937 - val_loss: 0.9493 - val_acc: 0.6250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6211 - acc: 0.8031 - val_loss: 0.9379 - val_acc: 0.6500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5865 - acc: 0.8531 - val_loss: 0.9224 - val_acc: 0.6625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6147 - acc: 0.1719 - val_loss: 1.5840 - val_acc: 0.3125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5931 - acc: 0.1719 - val_loss: 1.5728 - val_acc: 0.3125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5635 - acc: 0.1781 - val_loss: 1.5555 - val_acc: 0.3250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5231 - acc: 0.3313 - val_loss: 1.5349 - val_acc: 0.4625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4749 - acc: 0.5594 - val_loss: 1.5060 - val_acc: 0.4375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4041 - acc: 0.5594 - val_loss: 1.4738 - val_acc: 0.3375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3128 - acc: 0.5437 - val_loss: 1.4187 - val_acc: 0.3375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2129 - acc: 0.6031 - val_loss: 1.3657 - val_acc: 0.3625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0965 - acc: 0.6250 - val_loss: 1.3031 - val_acc: 0.3750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9963 - acc: 0.6625 - val_loss: 1.2446 - val_acc: 0.4250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9208 - acc: 0.6875 - val_loss: 1.2079 - val_acc: 0.4375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8410 - acc: 0.7250 - val_loss: 1.1962 - val_acc: 0.4125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7822 - acc: 0.7031 - val_loss: 1.1463 - val_acc: 0.4750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7217 - acc: 0.7938 - val_loss: 1.1442 - val_acc: 0.4750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6748 - acc: 0.7625 - val_loss: 1.1297 - val_acc: 0.5000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6242 - acc: 0.8281 - val_loss: 1.1225 - val_acc: 0.4875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6122 - acc: 0.1875 - val_loss: 1.5801 - val_acc: 0.2500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5878 - acc: 0.1875 - val_loss: 1.5636 - val_acc: 0.2500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5574 - acc: 0.1938 - val_loss: 1.5404 - val_acc: 0.2500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5129 - acc: 0.2500 - val_loss: 1.5219 - val_acc: 0.2625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4616 - acc: 0.3500 - val_loss: 1.4896 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3927 - acc: 0.6125 - val_loss: 1.4466 - val_acc: 0.4375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3060 - acc: 0.6219 - val_loss: 1.3915 - val_acc: 0.3875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2065 - acc: 0.6344 - val_loss: 1.3407 - val_acc: 0.4000\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1066 - acc: 0.5938 - val_loss: 1.2733 - val_acc: 0.4000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0027 - acc: 0.6844 - val_loss: 1.2013 - val_acc: 0.4125\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9116 - acc: 0.7188 - val_loss: 1.1437 - val_acc: 0.4625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8355 - acc: 0.7281 - val_loss: 1.0909 - val_acc: 0.5125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7662 - acc: 0.7750 - val_loss: 1.0824 - val_acc: 0.5000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6997 - acc: 0.7812 - val_loss: 1.0270 - val_acc: 0.5125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6382 - acc: 0.8500 - val_loss: 1.0185 - val_acc: 0.5125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5839 - acc: 0.8156 - val_loss: 1.0054 - val_acc: 0.5375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6121 - acc: 0.2000 - val_loss: 1.6003 - val_acc: 0.2000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5897 - acc: 0.2000 - val_loss: 1.5844 - val_acc: 0.2000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5620 - acc: 0.2250 - val_loss: 1.5724 - val_acc: 0.2750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5267 - acc: 0.3031 - val_loss: 1.5516 - val_acc: 0.3000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4877 - acc: 0.3687 - val_loss: 1.5145 - val_acc: 0.4125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4341 - acc: 0.5250 - val_loss: 1.4781 - val_acc: 0.4250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3718 - acc: 0.5156 - val_loss: 1.4215 - val_acc: 0.4625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2899 - acc: 0.5750 - val_loss: 1.3503 - val_acc: 0.4625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1997 - acc: 0.6031 - val_loss: 1.2783 - val_acc: 0.4750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1064 - acc: 0.6750 - val_loss: 1.1989 - val_acc: 0.4500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0195 - acc: 0.7250 - val_loss: 1.1430 - val_acc: 0.5500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9407 - acc: 0.7281 - val_loss: 1.0911 - val_acc: 0.5625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8736 - acc: 0.7344 - val_loss: 1.0539 - val_acc: 0.5125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7997 - acc: 0.7313 - val_loss: 1.0216 - val_acc: 0.5625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7360 - acc: 0.8094 - val_loss: 0.9975 - val_acc: 0.5625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6744 - acc: 0.8250 - val_loss: 0.9668 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6076 - acc: 0.2062 - val_loss: 1.6010 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5847 - acc: 0.2062 - val_loss: 1.5915 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5553 - acc: 0.2062 - val_loss: 1.5729 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5225 - acc: 0.2125 - val_loss: 1.5437 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4685 - acc: 0.2313 - val_loss: 1.5052 - val_acc: 0.2125\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4044 - acc: 0.3656 - val_loss: 1.4440 - val_acc: 0.3875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3192 - acc: 0.5969 - val_loss: 1.3551 - val_acc: 0.5250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2163 - acc: 0.6781 - val_loss: 1.2555 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1058 - acc: 0.7156 - val_loss: 1.1568 - val_acc: 0.6125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9939 - acc: 0.7156 - val_loss: 1.0932 - val_acc: 0.6500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9053 - acc: 0.7656 - val_loss: 1.0440 - val_acc: 0.6500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8224 - acc: 0.7375 - val_loss: 1.0009 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7610 - acc: 0.7875 - val_loss: 0.9675 - val_acc: 0.7000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6993 - acc: 0.8094 - val_loss: 0.9754 - val_acc: 0.6000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6323 - acc: 0.8281 - val_loss: 0.9331 - val_acc: 0.7000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5865 - acc: 0.8375 - val_loss: 0.9306 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6106 - acc: 0.2000 - val_loss: 1.6024 - val_acc: 0.2000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5897 - acc: 0.2000 - val_loss: 1.5899 - val_acc: 0.2000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5629 - acc: 0.2000 - val_loss: 1.5729 - val_acc: 0.2000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5299 - acc: 0.2125 - val_loss: 1.5560 - val_acc: 0.2125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4934 - acc: 0.3688 - val_loss: 1.5321 - val_acc: 0.3750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4470 - acc: 0.5031 - val_loss: 1.4970 - val_acc: 0.4375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3913 - acc: 0.6250 - val_loss: 1.4490 - val_acc: 0.4750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3143 - acc: 0.6313 - val_loss: 1.3861 - val_acc: 0.4500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2229 - acc: 0.6375 - val_loss: 1.3036 - val_acc: 0.5250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1263 - acc: 0.6719 - val_loss: 1.2270 - val_acc: 0.5500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0240 - acc: 0.7156 - val_loss: 1.1580 - val_acc: 0.5625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9273 - acc: 0.7250 - val_loss: 1.0978 - val_acc: 0.5375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8421 - acc: 0.7250 - val_loss: 1.0568 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7660 - acc: 0.7969 - val_loss: 1.0123 - val_acc: 0.5875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6932 - acc: 0.8156 - val_loss: 0.9890 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6248 - acc: 0.8344 - val_loss: 0.9663 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6095 - acc: 0.2125 - val_loss: 1.6150 - val_acc: 0.1500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5836 - acc: 0.2156 - val_loss: 1.6025 - val_acc: 0.1500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5615 - acc: 0.2125 - val_loss: 1.5928 - val_acc: 0.1500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5215 - acc: 0.2250 - val_loss: 1.5565 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4730 - acc: 0.3844 - val_loss: 1.5154 - val_acc: 0.2750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4045 - acc: 0.4438 - val_loss: 1.4506 - val_acc: 0.4750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3192 - acc: 0.6156 - val_loss: 1.3538 - val_acc: 0.4375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2157 - acc: 0.6500 - val_loss: 1.2471 - val_acc: 0.5250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1047 - acc: 0.7250 - val_loss: 1.1576 - val_acc: 0.5500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0070 - acc: 0.6781 - val_loss: 1.0849 - val_acc: 0.6000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9107 - acc: 0.7031 - val_loss: 1.0392 - val_acc: 0.5625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8356 - acc: 0.7344 - val_loss: 0.9758 - val_acc: 0.6000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7688 - acc: 0.7688 - val_loss: 0.9608 - val_acc: 0.6000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7051 - acc: 0.7844 - val_loss: 0.9482 - val_acc: 0.5875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6451 - acc: 0.8125 - val_loss: 0.9373 - val_acc: 0.6000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5940 - acc: 0.8375 - val_loss: 0.8954 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6120 - acc: 0.1937 - val_loss: 1.6021 - val_acc: 0.2375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5887 - acc: 0.1969 - val_loss: 1.5878 - val_acc: 0.2500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5649 - acc: 0.2062 - val_loss: 1.5732 - val_acc: 0.2500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5312 - acc: 0.2344 - val_loss: 1.5490 - val_acc: 0.2750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4808 - acc: 0.5125 - val_loss: 1.5148 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4143 - acc: 0.6281 - val_loss: 1.4633 - val_acc: 0.4375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3250 - acc: 0.5719 - val_loss: 1.3885 - val_acc: 0.4375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2078 - acc: 0.6344 - val_loss: 1.3058 - val_acc: 0.4875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0937 - acc: 0.6656 - val_loss: 1.2385 - val_acc: 0.4625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9841 - acc: 0.6875 - val_loss: 1.1866 - val_acc: 0.4750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8942 - acc: 0.7594 - val_loss: 1.1353 - val_acc: 0.4625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8369 - acc: 0.7219 - val_loss: 1.1336 - val_acc: 0.4750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7634 - acc: 0.7563 - val_loss: 1.0880 - val_acc: 0.5125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7158 - acc: 0.7750 - val_loss: 1.0909 - val_acc: 0.4875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6675 - acc: 0.8000 - val_loss: 1.0844 - val_acc: 0.5250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6049 - acc: 0.8375 - val_loss: 1.0498 - val_acc: 0.5250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.6113 - acc: 0.1969 - val_loss: 1.5966 - val_acc: 0.2125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5878 - acc: 0.1969 - val_loss: 1.5845 - val_acc: 0.2125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5609 - acc: 0.2094 - val_loss: 1.5659 - val_acc: 0.2125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5226 - acc: 0.2938 - val_loss: 1.5429 - val_acc: 0.2625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4815 - acc: 0.3313 - val_loss: 1.5092 - val_acc: 0.3500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.4199 - acc: 0.5000 - val_loss: 1.4725 - val_acc: 0.4375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.3538 - acc: 0.5531 - val_loss: 1.4097 - val_acc: 0.4875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2784 - acc: 0.5375 - val_loss: 1.3463 - val_acc: 0.4875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1867 - acc: 0.5969 - val_loss: 1.2749 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1051 - acc: 0.6437 - val_loss: 1.2161 - val_acc: 0.5375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0241 - acc: 0.6813 - val_loss: 1.1573 - val_acc: 0.5625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9549 - acc: 0.6687 - val_loss: 1.1140 - val_acc: 0.5000\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8945 - acc: 0.7312 - val_loss: 1.0721 - val_acc: 0.4750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8255 - acc: 0.7188 - val_loss: 1.0484 - val_acc: 0.5500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7835 - acc: 0.7313 - val_loss: 1.0268 - val_acc: 0.4625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7177 - acc: 0.7937 - val_loss: 0.9895 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_51 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_101 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_102 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_103 (Activation)  (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_104 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 1.5330 - acc: 0.3250 - val_loss: 1.3644 - val_acc: 0.4625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0926 - acc: 0.5344 - val_loss: 1.0398 - val_acc: 0.5375\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8813 - acc: 0.6594 - val_loss: 1.0805 - val_acc: 0.5125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7727 - acc: 0.7094 - val_loss: 0.8347 - val_acc: 0.6750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6537 - acc: 0.7750 - val_loss: 0.9346 - val_acc: 0.5875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5283 - acc: 0.8062 - val_loss: 0.8180 - val_acc: 0.6500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3536 - acc: 0.9156 - val_loss: 0.8659 - val_acc: 0.6500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2246 - acc: 0.9500 - val_loss: 0.8132 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1573 - acc: 0.9750 - val_loss: 0.9869 - val_acc: 0.5875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1036 - acc: 0.9812 - val_loss: 0.9103 - val_acc: 0.6625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0455 - acc: 1.0000 - val_loss: 1.0347 - val_acc: 0.6000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0318 - acc: 1.0000 - val_loss: 1.0132 - val_acc: 0.6375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.9861 - val_acc: 0.6250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 1.0573 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 1.0649 - val_acc: 0.5875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0912 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5632 - acc: 0.3000 - val_loss: 1.4602 - val_acc: 0.3250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2096 - acc: 0.4719 - val_loss: 1.1370 - val_acc: 0.5375\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9092 - acc: 0.6125 - val_loss: 1.5232 - val_acc: 0.5375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8726 - acc: 0.6438 - val_loss: 1.0053 - val_acc: 0.6000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5311 - acc: 0.8188 - val_loss: 0.9854 - val_acc: 0.5875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3821 - acc: 0.8844 - val_loss: 0.9723 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2747 - acc: 0.9281 - val_loss: 1.0984 - val_acc: 0.6125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1852 - acc: 0.9406 - val_loss: 1.1515 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1257 - acc: 0.9656 - val_loss: 1.1677 - val_acc: 0.6000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0675 - acc: 0.9844 - val_loss: 1.3698 - val_acc: 0.6250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0567 - acc: 0.9938 - val_loss: 1.1854 - val_acc: 0.6750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 1.2072 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.2607 - val_acc: 0.7000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.2686 - val_acc: 0.6875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.2576 - val_acc: 0.6750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.2912 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5779 - acc: 0.2656 - val_loss: 1.3134 - val_acc: 0.4750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2539 - acc: 0.4969 - val_loss: 1.3197 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0215 - acc: 0.5750 - val_loss: 1.0778 - val_acc: 0.4750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9022 - acc: 0.6500 - val_loss: 0.9564 - val_acc: 0.6375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6454 - acc: 0.7750 - val_loss: 1.1087 - val_acc: 0.5875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4619 - acc: 0.8438 - val_loss: 0.8664 - val_acc: 0.6625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3621 - acc: 0.8875 - val_loss: 0.8808 - val_acc: 0.6500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2421 - acc: 0.9406 - val_loss: 1.0480 - val_acc: 0.5875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1274 - acc: 0.9781 - val_loss: 1.0648 - val_acc: 0.5750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0749 - acc: 0.9938 - val_loss: 1.0695 - val_acc: 0.6000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0456 - acc: 0.9938 - val_loss: 1.1053 - val_acc: 0.6250\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 1.0839 - val_acc: 0.6625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.2702 - val_acc: 0.5750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.1982 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.1999 - val_acc: 0.6500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5844 - acc: 0.2531 - val_loss: 1.4531 - val_acc: 0.3750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2347 - acc: 0.5125 - val_loss: 1.1498 - val_acc: 0.5625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9664 - acc: 0.6125 - val_loss: 1.0952 - val_acc: 0.6000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7672 - acc: 0.6906 - val_loss: 1.1682 - val_acc: 0.5625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5706 - acc: 0.8000 - val_loss: 1.3427 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4480 - acc: 0.8281 - val_loss: 1.2408 - val_acc: 0.6000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2812 - acc: 0.9344 - val_loss: 1.0423 - val_acc: 0.6250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1299 - acc: 0.9875 - val_loss: 0.9671 - val_acc: 0.6875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0979 - acc: 0.9750 - val_loss: 1.1576 - val_acc: 0.6625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0601 - acc: 0.9906 - val_loss: 1.2524 - val_acc: 0.6500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0452 - acc: 0.9938 - val_loss: 1.2684 - val_acc: 0.5875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0316 - acc: 0.9969 - val_loss: 1.2355 - val_acc: 0.6875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0168 - acc: 0.9969 - val_loss: 1.2124 - val_acc: 0.7000\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.2853 - val_acc: 0.6750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.2989 - val_acc: 0.6750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2819 - val_acc: 0.7000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5900 - acc: 0.2125 - val_loss: 1.5019 - val_acc: 0.4000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2953 - acc: 0.5094 - val_loss: 1.3530 - val_acc: 0.4750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.0279 - acc: 0.5750 - val_loss: 1.1517 - val_acc: 0.5250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7590 - acc: 0.6969 - val_loss: 1.1171 - val_acc: 0.5250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5347 - acc: 0.8125 - val_loss: 1.1760 - val_acc: 0.5625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4055 - acc: 0.8594 - val_loss: 1.1591 - val_acc: 0.6250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2286 - acc: 0.9406 - val_loss: 1.1703 - val_acc: 0.6375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1534 - acc: 0.9531 - val_loss: 1.1524 - val_acc: 0.5750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0959 - acc: 0.9844 - val_loss: 1.3942 - val_acc: 0.5500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0607 - acc: 0.9906 - val_loss: 1.3232 - val_acc: 0.6000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.6161 - val_acc: 0.6125\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.3416 - val_acc: 0.6500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 1.3800 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.5268 - val_acc: 0.6250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.5192 - val_acc: 0.6375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.5139 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5351 - acc: 0.2844 - val_loss: 1.3661 - val_acc: 0.4250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1667 - acc: 0.5500 - val_loss: 1.2607 - val_acc: 0.5375\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9644 - acc: 0.6125 - val_loss: 1.2244 - val_acc: 0.5125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7339 - acc: 0.7000 - val_loss: 1.2847 - val_acc: 0.5125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6433 - acc: 0.7688 - val_loss: 1.1881 - val_acc: 0.5625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4339 - acc: 0.8594 - val_loss: 1.0762 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3063 - acc: 0.9250 - val_loss: 1.0086 - val_acc: 0.5750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1495 - acc: 0.9812 - val_loss: 1.0293 - val_acc: 0.6375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1031 - acc: 0.9750 - val_loss: 1.0567 - val_acc: 0.6500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0598 - acc: 0.9906 - val_loss: 1.2330 - val_acc: 0.5750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0360 - acc: 1.0000 - val_loss: 1.0952 - val_acc: 0.6375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 1.1532 - val_acc: 0.5750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.1788 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.2115 - val_acc: 0.6000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.1802 - val_acc: 0.5500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.1837 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5634 - acc: 0.2688 - val_loss: 1.4487 - val_acc: 0.3625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1811 - acc: 0.5469 - val_loss: 1.2300 - val_acc: 0.4625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9778 - acc: 0.5938 - val_loss: 1.1691 - val_acc: 0.5500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8855 - acc: 0.6344 - val_loss: 1.1142 - val_acc: 0.5375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.8030 - acc: 0.6875 - val_loss: 1.2336 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4953 - acc: 0.8344 - val_loss: 1.2351 - val_acc: 0.5625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3143 - acc: 0.9187 - val_loss: 1.0031 - val_acc: 0.6125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1555 - acc: 0.9750 - val_loss: 1.0962 - val_acc: 0.5625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0921 - acc: 0.9844 - val_loss: 1.1178 - val_acc: 0.6125\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0596 - acc: 0.9938 - val_loss: 1.2480 - val_acc: 0.6000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0384 - acc: 0.9969 - val_loss: 1.3073 - val_acc: 0.5625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0339 - acc: 1.0000 - val_loss: 1.2904 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.4097 - val_acc: 0.6250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.4110 - val_acc: 0.6000\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.3810 - val_acc: 0.6125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.4614 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5513 - acc: 0.2750 - val_loss: 1.4237 - val_acc: 0.3875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.2385 - acc: 0.5000 - val_loss: 1.0953 - val_acc: 0.5250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9476 - acc: 0.6031 - val_loss: 0.9807 - val_acc: 0.6125\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7558 - acc: 0.7156 - val_loss: 1.0826 - val_acc: 0.5500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6526 - acc: 0.7437 - val_loss: 1.2093 - val_acc: 0.5750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.5292 - acc: 0.7750 - val_loss: 1.1393 - val_acc: 0.6000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3297 - acc: 0.8937 - val_loss: 0.9648 - val_acc: 0.6875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2033 - acc: 0.9594 - val_loss: 0.9494 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1239 - acc: 0.9719 - val_loss: 1.0279 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0642 - acc: 0.9969 - val_loss: 1.1254 - val_acc: 0.6375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0405 - acc: 0.9938 - val_loss: 1.2251 - val_acc: 0.6375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 1.0368 - val_acc: 0.6250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.1684 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.2478 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.2502 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.2168 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.5594 - acc: 0.2469 - val_loss: 1.4771 - val_acc: 0.4125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1943 - acc: 0.5281 - val_loss: 1.3430 - val_acc: 0.4500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 1.1495 - acc: 0.5500 - val_loss: 1.3600 - val_acc: 0.4625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.9934 - acc: 0.6000 - val_loss: 1.0728 - val_acc: 0.6000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.7225 - acc: 0.7188 - val_loss: 1.0432 - val_acc: 0.6000\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.4722 - acc: 0.8687 - val_loss: 1.1350 - val_acc: 0.5500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.3055 - acc: 0.9125 - val_loss: 1.0128 - val_acc: 0.5875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.2124 - acc: 0.9469 - val_loss: 1.2559 - val_acc: 0.5250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.1131 - acc: 0.9937 - val_loss: 1.2863 - val_acc: 0.5625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0719 - acc: 0.9813 - val_loss: 1.1362 - val_acc: 0.5500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0445 - acc: 1.0000 - val_loss: 1.3299 - val_acc: 0.5750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0260 - acc: 1.0000 - val_loss: 1.2708 - val_acc: 0.5500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.3356 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.4566 - val_acc: 0.5875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.4001 - val_acc: 0.6000\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.4376 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_53 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_105 (Activation)  (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_106 (Activation)  (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_107 (Activation)  (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_108 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 3s 9ms/step - loss: 10.9562 - acc: 0.1906 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.3524 - acc: 0.2188 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1937 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.9952 - acc: 0.1938 - val_loss: 12.4915 - val_acc: 0.2250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.7232 - acc: 0.1969 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.6431 - acc: 0.2094 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.8441 - acc: 0.2031 - val_loss: 13.0960 - val_acc: 0.1875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.3404 - acc: 0.2000 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7434 - acc: 0.2094 - val_loss: 13.4989 - val_acc: 0.1625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.8271 - acc: 0.2187 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.2178 - acc: 0.2344 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2062 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.7937 - acc: 0.2063 - val_loss: 13.2974 - val_acc: 0.1750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 8.9873 - acc: 0.2312 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6426 - acc: 0.2156 - val_loss: 13.9019 - val_acc: 0.1375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 9.0728 - acc: 0.1750 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 12.6930 - acc: 0.2125 - val_loss: 13.7004 - val_acc: 0.1500\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qz74nqi9X1F",
        "colab_type": "code",
        "outputId": "3a3a5b6c-3f31-4443-d5ce-ff31c78a92f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def LeNetTest(input_shape, classes, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense):\n",
        "  model = Sequential()\n",
        "\n",
        "  # CONV => RELU => POOL\n",
        "  model.add(Conv2D(batch1, kernel_size=k_size, strides = conv_stride,  padding=\"same\", input_shape=input_shape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(SpatialDropout2D(0.1))\n",
        "  model.add(MaxPooling2D(pool_size=p_size, strides= pool_stride, dim_ordering=\"th\"))\n",
        "\n",
        "  # CONV => RELU => POOL\n",
        "  model.add(Conv2D(batch2, kernel_size=k_size, strides = conv_stride,  padding=\"same\", input_shape=input_shape))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=p_size, strides= pool_stride, dim_ordering=\"th\"))\n",
        "\n",
        "  # Flatten => RELU layers\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(dense))\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  # a softmax classifier\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  return model\n",
        "\n",
        "print('LeNet class defined.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet class defined.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZK3NM8U8LXi",
        "colab_type": "code",
        "outputId": "28662cf1-68f4-4513-b3d1-facfc9bcc1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epoch = 10\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "optimizer = Adam(lr)\n",
        "\n",
        "\n",
        "parameter = \"Spatial Dropout: \"\n",
        "Model = LeNetTest\n",
        "\n",
        "train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                          optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)\n",
        "parameter_name = parameter+str(0.1)\n",
        "parameter_acc = np.mean(test_accuracy)\n",
        "parameter_loss = np.mean(test_loss)\n",
        "score_df = score_df.append({'Parameter':parameter_name, 'Accuracy':parameter_acc, 'Loss':parameter_loss},ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "spatial_dropout2d_4 (Spatial (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 3s 8ms/step - loss: 1.3830 - acc: 0.4281 - val_loss: 0.8832 - val_acc: 0.6500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0902 - acc: 0.5594 - val_loss: 0.9611 - val_acc: 0.6125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7633 - acc: 0.7000 - val_loss: 1.0228 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5657 - acc: 0.7937 - val_loss: 1.1379 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2967 - acc: 0.9094 - val_loss: 1.0258 - val_acc: 0.6625\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1643 - acc: 0.9531 - val_loss: 1.4248 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0989 - acc: 0.9750 - val_loss: 1.1077 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 1.0953 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0296 - acc: 0.9969 - val_loss: 1.1183 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0862 - acc: 0.9750 - val_loss: 1.3675 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5650 - acc: 0.3875 - val_loss: 1.2287 - val_acc: 0.5250\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1149 - acc: 0.5531 - val_loss: 1.3301 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7962 - acc: 0.6750 - val_loss: 1.1330 - val_acc: 0.5500\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4243 - acc: 0.8469 - val_loss: 1.2133 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2126 - acc: 0.9062 - val_loss: 1.1621 - val_acc: 0.6250\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0904 - acc: 0.9719 - val_loss: 1.2811 - val_acc: 0.5875\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0531 - acc: 0.9844 - val_loss: 1.5652 - val_acc: 0.5625\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 1.4774 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0438 - acc: 0.9844 - val_loss: 1.5181 - val_acc: 0.5500\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 1.4019 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5691 - acc: 0.3938 - val_loss: 1.2430 - val_acc: 0.4750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2351 - acc: 0.5625 - val_loss: 2.2899 - val_acc: 0.4375\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8260 - acc: 0.6906 - val_loss: 1.1173 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4640 - acc: 0.7812 - val_loss: 1.0057 - val_acc: 0.5750\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1991 - acc: 0.9375 - val_loss: 1.2043 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1391 - acc: 0.9437 - val_loss: 1.3972 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0879 - acc: 0.9719 - val_loss: 1.2630 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.3549 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0180 - acc: 0.9937 - val_loss: 1.2873 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0131 - acc: 0.9969 - val_loss: 1.4258 - val_acc: 0.5750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4102 - acc: 0.4281 - val_loss: 1.7338 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2469 - acc: 0.5281 - val_loss: 1.3147 - val_acc: 0.5125\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9959 - acc: 0.6281 - val_loss: 1.0932 - val_acc: 0.5750\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6301 - acc: 0.7469 - val_loss: 1.0416 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2652 - acc: 0.9156 - val_loss: 1.3330 - val_acc: 0.5875\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1720 - acc: 0.9437 - val_loss: 1.2053 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1159 - acc: 0.9687 - val_loss: 1.3961 - val_acc: 0.6375\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0256 - acc: 0.9969 - val_loss: 1.5876 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.7036 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0210 - acc: 0.9969 - val_loss: 1.4477 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4774 - acc: 0.4063 - val_loss: 1.1025 - val_acc: 0.5750\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0721 - acc: 0.5906 - val_loss: 1.0335 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7698 - acc: 0.6781 - val_loss: 1.3262 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4290 - acc: 0.8375 - val_loss: 1.0391 - val_acc: 0.6250\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1671 - acc: 0.9406 - val_loss: 1.0572 - val_acc: 0.6125\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0903 - acc: 0.9687 - val_loss: 0.9110 - val_acc: 0.6750\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0483 - acc: 0.9844 - val_loss: 1.0639 - val_acc: 0.6125\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0307 - acc: 0.9969 - val_loss: 1.2475 - val_acc: 0.6375\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0140 - acc: 0.9969 - val_loss: 1.1558 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 1.0916 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5552 - acc: 0.3781 - val_loss: 1.2028 - val_acc: 0.5375\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1368 - acc: 0.5531 - val_loss: 0.9822 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7458 - acc: 0.6969 - val_loss: 1.2366 - val_acc: 0.5125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4388 - acc: 0.8437 - val_loss: 1.0794 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2143 - acc: 0.9312 - val_loss: 1.2648 - val_acc: 0.6375\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0927 - acc: 0.9750 - val_loss: 1.3606 - val_acc: 0.5625\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0290 - acc: 0.9969 - val_loss: 1.3405 - val_acc: 0.5875\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.5875\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.3831 - val_acc: 0.6375\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.4210 - val_acc: 0.6125\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3915 - acc: 0.4563 - val_loss: 1.5651 - val_acc: 0.4500\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1024 - acc: 0.5750 - val_loss: 1.4485 - val_acc: 0.4250\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7563 - acc: 0.7094 - val_loss: 1.1557 - val_acc: 0.5375\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4135 - acc: 0.8531 - val_loss: 1.3184 - val_acc: 0.5125\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1730 - acc: 0.9531 - val_loss: 1.5823 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1402 - acc: 0.9500 - val_loss: 1.8892 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1358 - acc: 0.9437 - val_loss: 2.4682 - val_acc: 0.4750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1045 - acc: 0.9625 - val_loss: 1.7532 - val_acc: 0.4625\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0795 - acc: 0.9750 - val_loss: 2.1529 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0420 - acc: 0.9906 - val_loss: 2.6252 - val_acc: 0.4750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4129 - acc: 0.4125 - val_loss: 1.2556 - val_acc: 0.4875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1296 - acc: 0.5250 - val_loss: 0.9927 - val_acc: 0.5875\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7712 - acc: 0.6719 - val_loss: 1.2884 - val_acc: 0.5625\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4389 - acc: 0.8344 - val_loss: 1.1881 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2379 - acc: 0.9094 - val_loss: 1.4244 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1176 - acc: 0.9687 - val_loss: 1.2269 - val_acc: 0.6250\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.4232 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.2482 - val_acc: 0.6250\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.4236 - val_acc: 0.6125\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0160 - acc: 0.9969 - val_loss: 1.6666 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5018 - acc: 0.3719 - val_loss: 1.3863 - val_acc: 0.3875\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0452 - acc: 0.5719 - val_loss: 1.2178 - val_acc: 0.5750\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7713 - acc: 0.6875 - val_loss: 1.1246 - val_acc: 0.6125\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5037 - acc: 0.8094 - val_loss: 1.3181 - val_acc: 0.5625\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2048 - acc: 0.9375 - val_loss: 1.0024 - val_acc: 0.6750\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1357 - acc: 0.9531 - val_loss: 1.2637 - val_acc: 0.7000\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0753 - acc: 0.9844 - val_loss: 1.3001 - val_acc: 0.5750\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1610 - acc: 0.9562 - val_loss: 1.5124 - val_acc: 0.5500\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0696 - acc: 0.9750 - val_loss: 1.5478 - val_acc: 0.5625\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.0705 - acc: 0.9781 - val_loss: 1.6777 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYtDRI9V_QXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_df.to_csv('score_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECFJ0dtC5J86",
        "colab_type": "text"
      },
      "source": [
        "## Final model training & results (65% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emgTkQ0BBecF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epoch = 16\n",
        "batch_size = 10\n",
        "Model = LeNet\n",
        "lr = 0.0001\n",
        "optimizer = Adam(lr)\n",
        "batch1 = 32\n",
        "batch2 = 64\n",
        "k_size = (7, 7)\n",
        "conv_stride = (1, 2) \n",
        "p_size = (1, 3)\n",
        "pool_stride = (3, 3) \n",
        "dense =  256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zLT73mkBZzA",
        "colab_type": "code",
        "outputId": "72fc362d-4189-494d-bb18-15e266fe9c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy = fit_model(X, y, input_shape, n_classes, Model, n_epoch, batch_size, \n",
        "                                                                                    optimizer, batch1, batch2, k_size, conv_stride, p_size, pool_stride, dense)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(1, 3), strides=(3, 3), data_format=\"channels_first\")`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 1, 64, 32)         2022752   \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 1, 64, 32)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 1, 22, 10)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 11, 64)         31424     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 1, 11, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 1, 4, 21)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 256)               21760     \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 5)                 1285      \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 2,077,221\n",
            "Trainable params: 2,077,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 2s 6ms/step - loss: 1.5799 - acc: 0.2375 - val_loss: 1.5215 - val_acc: 0.2875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3520 - acc: 0.4375 - val_loss: 1.3607 - val_acc: 0.3375\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1120 - acc: 0.5563 - val_loss: 1.2143 - val_acc: 0.4625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9339 - acc: 0.6469 - val_loss: 1.1457 - val_acc: 0.5375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8050 - acc: 0.6688 - val_loss: 1.0615 - val_acc: 0.5750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6678 - acc: 0.7906 - val_loss: 1.0550 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5902 - acc: 0.8063 - val_loss: 1.1177 - val_acc: 0.5750\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5266 - acc: 0.8187 - val_loss: 1.0455 - val_acc: 0.5750\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4355 - acc: 0.8719 - val_loss: 1.0319 - val_acc: 0.6250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3551 - acc: 0.9219 - val_loss: 1.1017 - val_acc: 0.5875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3213 - acc: 0.9219 - val_loss: 1.0644 - val_acc: 0.6000\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2734 - acc: 0.9406 - val_loss: 1.1236 - val_acc: 0.5875\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2264 - acc: 0.9469 - val_loss: 1.1048 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1937 - acc: 0.9625 - val_loss: 1.0774 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1446 - acc: 0.9844 - val_loss: 1.0713 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1186 - acc: 0.9969 - val_loss: 1.1451 - val_acc: 0.6000\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5981 - acc: 0.1969 - val_loss: 1.5822 - val_acc: 0.1500\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4493 - acc: 0.3750 - val_loss: 1.3853 - val_acc: 0.4500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1298 - acc: 0.5813 - val_loss: 1.1687 - val_acc: 0.5750\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9276 - acc: 0.6375 - val_loss: 1.1320 - val_acc: 0.5125\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7889 - acc: 0.6938 - val_loss: 1.0532 - val_acc: 0.5500\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6713 - acc: 0.7500 - val_loss: 1.0404 - val_acc: 0.5250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5952 - acc: 0.8000 - val_loss: 0.9887 - val_acc: 0.6125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5086 - acc: 0.8437 - val_loss: 0.9920 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4324 - acc: 0.8812 - val_loss: 0.9788 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3675 - acc: 0.9312 - val_loss: 0.9261 - val_acc: 0.6750\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3102 - acc: 0.9437 - val_loss: 0.9397 - val_acc: 0.5875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2469 - acc: 0.9625 - val_loss: 0.9286 - val_acc: 0.5375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2152 - acc: 0.9844 - val_loss: 0.9575 - val_acc: 0.6375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1848 - acc: 0.9750 - val_loss: 0.9625 - val_acc: 0.5500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1471 - acc: 0.9875 - val_loss: 0.9649 - val_acc: 0.6125\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1204 - acc: 0.9937 - val_loss: 0.9129 - val_acc: 0.6250\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6070 - acc: 0.1969 - val_loss: 1.5729 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5023 - acc: 0.2688 - val_loss: 1.4311 - val_acc: 0.4500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3172 - acc: 0.4781 - val_loss: 1.2544 - val_acc: 0.4625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1452 - acc: 0.5563 - val_loss: 1.1579 - val_acc: 0.4500\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0089 - acc: 0.6063 - val_loss: 1.0791 - val_acc: 0.5375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8506 - acc: 0.6844 - val_loss: 1.0022 - val_acc: 0.6375\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7395 - acc: 0.7437 - val_loss: 1.0030 - val_acc: 0.5875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5984 - acc: 0.8312 - val_loss: 0.9441 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5104 - acc: 0.8594 - val_loss: 1.0024 - val_acc: 0.6000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4347 - acc: 0.8906 - val_loss: 0.9677 - val_acc: 0.5625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3541 - acc: 0.9344 - val_loss: 0.8982 - val_acc: 0.6375\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2825 - acc: 0.9500 - val_loss: 0.8880 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2362 - acc: 0.9656 - val_loss: 0.9581 - val_acc: 0.6125\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1867 - acc: 0.9812 - val_loss: 0.8865 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1570 - acc: 0.9906 - val_loss: 0.9245 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1277 - acc: 0.9937 - val_loss: 0.9255 - val_acc: 0.6375\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6127 - acc: 0.1969 - val_loss: 1.5821 - val_acc: 0.2000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4904 - acc: 0.2719 - val_loss: 1.4402 - val_acc: 0.3625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2856 - acc: 0.4781 - val_loss: 1.3185 - val_acc: 0.4000\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1210 - acc: 0.5594 - val_loss: 1.1859 - val_acc: 0.4875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9587 - acc: 0.6625 - val_loss: 1.1331 - val_acc: 0.4375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8295 - acc: 0.7344 - val_loss: 1.1141 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7302 - acc: 0.7812 - val_loss: 1.1183 - val_acc: 0.4375\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6207 - acc: 0.7875 - val_loss: 1.1003 - val_acc: 0.4875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5716 - acc: 0.8125 - val_loss: 1.0675 - val_acc: 0.5250\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4678 - acc: 0.8687 - val_loss: 1.0440 - val_acc: 0.5625\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4186 - acc: 0.8937 - val_loss: 1.0836 - val_acc: 0.4875\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3316 - acc: 0.9281 - val_loss: 1.0558 - val_acc: 0.4750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2876 - acc: 0.9500 - val_loss: 1.0579 - val_acc: 0.5375\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2378 - acc: 0.9687 - val_loss: 1.1004 - val_acc: 0.5500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2103 - acc: 0.9687 - val_loss: 1.0901 - val_acc: 0.5250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1741 - acc: 0.9781 - val_loss: 1.0716 - val_acc: 0.5625\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6064 - acc: 0.2031 - val_loss: 1.5828 - val_acc: 0.1750\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4888 - acc: 0.2781 - val_loss: 1.4136 - val_acc: 0.4125\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3059 - acc: 0.4875 - val_loss: 1.2320 - val_acc: 0.5375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1398 - acc: 0.5625 - val_loss: 1.0940 - val_acc: 0.5625\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9911 - acc: 0.6500 - val_loss: 1.0021 - val_acc: 0.6375\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8380 - acc: 0.7313 - val_loss: 0.9851 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7776 - acc: 0.7188 - val_loss: 0.9089 - val_acc: 0.6500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6498 - acc: 0.7844 - val_loss: 0.8583 - val_acc: 0.6625\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5497 - acc: 0.8531 - val_loss: 0.8331 - val_acc: 0.6500\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4666 - acc: 0.9094 - val_loss: 0.8342 - val_acc: 0.6875\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4149 - acc: 0.8937 - val_loss: 0.8749 - val_acc: 0.6250\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3453 - acc: 0.9250 - val_loss: 0.7683 - val_acc: 0.7625\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2877 - acc: 0.9562 - val_loss: 0.7408 - val_acc: 0.7250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2298 - acc: 0.9750 - val_loss: 0.8454 - val_acc: 0.6500\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2039 - acc: 0.9812 - val_loss: 0.7637 - val_acc: 0.6750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1675 - acc: 0.9875 - val_loss: 0.8008 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5977 - acc: 0.2000 - val_loss: 1.5530 - val_acc: 0.2125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4748 - acc: 0.2563 - val_loss: 1.4806 - val_acc: 0.3625\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2904 - acc: 0.5094 - val_loss: 1.3897 - val_acc: 0.4250\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1384 - acc: 0.5375 - val_loss: 1.2971 - val_acc: 0.4375\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9677 - acc: 0.6375 - val_loss: 1.2989 - val_acc: 0.4250\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8634 - acc: 0.6875 - val_loss: 1.1891 - val_acc: 0.4625\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7138 - acc: 0.7625 - val_loss: 1.0915 - val_acc: 0.4875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6107 - acc: 0.8250 - val_loss: 1.0655 - val_acc: 0.5375\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5266 - acc: 0.8531 - val_loss: 1.1188 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4480 - acc: 0.8906 - val_loss: 1.1363 - val_acc: 0.5250\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3748 - acc: 0.9187 - val_loss: 1.1780 - val_acc: 0.4625\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3120 - acc: 0.9531 - val_loss: 1.0099 - val_acc: 0.5375\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2523 - acc: 0.9594 - val_loss: 1.0523 - val_acc: 0.5750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2000 - acc: 0.9844 - val_loss: 1.1271 - val_acc: 0.5625\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1718 - acc: 0.9812 - val_loss: 1.1008 - val_acc: 0.5750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1356 - acc: 0.9969 - val_loss: 1.1468 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5922 - acc: 0.2156 - val_loss: 1.6536 - val_acc: 0.1000\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4672 - acc: 0.2969 - val_loss: 1.5190 - val_acc: 0.2500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.2809 - acc: 0.5281 - val_loss: 1.3158 - val_acc: 0.4625\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.0343 - acc: 0.6125 - val_loss: 1.1305 - val_acc: 0.6000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8601 - acc: 0.7344 - val_loss: 1.0978 - val_acc: 0.4625\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7281 - acc: 0.7750 - val_loss: 1.0622 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6045 - acc: 0.7938 - val_loss: 1.0052 - val_acc: 0.5500\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4993 - acc: 0.8844 - val_loss: 0.9512 - val_acc: 0.5875\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4258 - acc: 0.9062 - val_loss: 0.9267 - val_acc: 0.6875\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3597 - acc: 0.9281 - val_loss: 0.8684 - val_acc: 0.6500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3339 - acc: 0.9156 - val_loss: 0.9530 - val_acc: 0.6500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2658 - acc: 0.9500 - val_loss: 0.8906 - val_acc: 0.6750\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2216 - acc: 0.9562 - val_loss: 0.9415 - val_acc: 0.6750\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1783 - acc: 0.9906 - val_loss: 1.0103 - val_acc: 0.6250\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1527 - acc: 0.9750 - val_loss: 0.9128 - val_acc: 0.6625\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1253 - acc: 0.9937 - val_loss: 0.9228 - val_acc: 0.6750\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.5970 - acc: 0.2156 - val_loss: 1.6058 - val_acc: 0.1875\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4945 - acc: 0.2406 - val_loss: 1.5173 - val_acc: 0.2000\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.3335 - acc: 0.4594 - val_loss: 1.3036 - val_acc: 0.4375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1122 - acc: 0.5875 - val_loss: 1.1912 - val_acc: 0.4875\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9519 - acc: 0.6625 - val_loss: 1.1593 - val_acc: 0.4750\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7979 - acc: 0.7656 - val_loss: 1.1567 - val_acc: 0.5250\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7120 - acc: 0.7719 - val_loss: 1.0663 - val_acc: 0.5125\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6239 - acc: 0.7969 - val_loss: 1.0948 - val_acc: 0.5250\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5181 - acc: 0.8562 - val_loss: 1.1625 - val_acc: 0.5625\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4564 - acc: 0.8687 - val_loss: 1.0333 - val_acc: 0.5500\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3797 - acc: 0.9062 - val_loss: 1.0436 - val_acc: 0.5750\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3200 - acc: 0.9375 - val_loss: 0.9772 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2645 - acc: 0.9531 - val_loss: 1.0206 - val_acc: 0.5875\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2444 - acc: 0.9656 - val_loss: 0.9682 - val_acc: 0.6125\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1921 - acc: 0.9812 - val_loss: 0.9792 - val_acc: 0.5750\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1654 - acc: 0.9844 - val_loss: 1.0013 - val_acc: 0.5875\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Train on 320 samples, validate on 80 samples\n",
            "Epoch 1/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.6015 - acc: 0.1969 - val_loss: 1.5614 - val_acc: 0.2125\n",
            "Epoch 2/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.4405 - acc: 0.3719 - val_loss: 1.4371 - val_acc: 0.3500\n",
            "Epoch 3/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 1.1941 - acc: 0.5094 - val_loss: 1.2836 - val_acc: 0.4375\n",
            "Epoch 4/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.9871 - acc: 0.6344 - val_loss: 1.1774 - val_acc: 0.5000\n",
            "Epoch 5/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.8467 - acc: 0.6750 - val_loss: 1.1697 - val_acc: 0.5875\n",
            "Epoch 6/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.7532 - acc: 0.7469 - val_loss: 1.0733 - val_acc: 0.5750\n",
            "Epoch 7/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.6167 - acc: 0.7687 - val_loss: 1.0193 - val_acc: 0.5875\n",
            "Epoch 8/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.5573 - acc: 0.8531 - val_loss: 1.0804 - val_acc: 0.6125\n",
            "Epoch 9/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.4719 - acc: 0.8562 - val_loss: 0.9715 - val_acc: 0.6375\n",
            "Epoch 10/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3932 - acc: 0.9125 - val_loss: 0.9570 - val_acc: 0.6000\n",
            "Epoch 11/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.3191 - acc: 0.9437 - val_loss: 0.9197 - val_acc: 0.6500\n",
            "Epoch 12/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2680 - acc: 0.9625 - val_loss: 0.9531 - val_acc: 0.6125\n",
            "Epoch 13/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.2225 - acc: 0.9750 - val_loss: 0.9431 - val_acc: 0.6250\n",
            "Epoch 14/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1842 - acc: 0.9875 - val_loss: 0.9671 - val_acc: 0.6375\n",
            "Epoch 15/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1522 - acc: 0.9875 - val_loss: 0.9803 - val_acc: 0.6250\n",
            "Epoch 16/16\n",
            "320/320 [==============================] - 1s 3ms/step - loss: 0.1275 - acc: 0.9969 - val_loss: 0.9701 - val_acc: 0.6500\n",
            "100/100 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS9KJUTgCL3-",
        "colab_type": "code",
        "outputId": "2341d857-7cb4-4da1-be8e-b82baa1d5408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        "plot_results(train_accuracy, train_loss, val_accuracy, val_loss, test_loss, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test loss is: 0.8850611413849725\n",
            "The test accuracy is: 0.65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAGJCAYAAADxMfswAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA3VeifvjDWzYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGJCAYAAACEijpiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8IbvQreCPYP",
        "colab_type": "code",
        "outputId": "2a83849c-a247-4e03-a690-f7bedba363c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "draw_conf_matrix()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXwUVbbA8d/JBoQkEHFhFxcEcQFU\nFBHXGRmV0XmDC26jKMjTQcV9dPQ5II67gIjLICCujDKKI4soioAiIpuICLiiIIigSAhLAsl5f9zb\npAmdpENSqYY+38+nP9213tPV1adv36q6JaqKMcaYPV9K2AEYY4ypGZbwjTEmSVjCN8aYJGEJ3xhj\nkoQlfGOMSRKW8I0xJklYwg+ZiJwiIl+IyDYRURHJquL6evj1TK2mEBOOiPTz73FUgGVU6+eyuxCR\nFv79Bn6+toiM8mX1ixp3vYis9OPn+M9BRWRZgHEEXkaisIRfDhE5QUTGicgvIrJFRL4RkcdFJKMa\ni3kSOBSYDDwGFFZxfV/49fyniuspU3RSEJHfRKRu1LS7oqaNqsQ6I8u0iGP2j3Hv8Z3Kxl4JcX0u\nItJaRF4QkRUiUigiP4vIhyJyVYCxVUkN7dfxeAe3bT/2cTUCBgENgZHAy8AKP8/I6ihQRKb6/axH\n1OhqLSORiV14FZuIXAi8CKQCC4DZQAvgFGAfVf2tmsrZ5ss4SFW/rY51Bs0n5e+iRl2lqsNFJNWP\nb+bHP6eqPeJcZ2RHPEBVl5UzX7qqbq1szJUVz+ciIp1xSasO8AMwFUgHjgY2qOoxAca3S9uhov0a\nqI//bFVVqinceGPrDHwALFfV5gGVMRU4GbhCVUcFUUZCU1V7lHoAmcAvgAIvAClR0w4CMvzrI4FJ\nwFpgDTAOaBU17zK/jtuB+cBGYCKQ66drqccy3JdP3UezfT2j/Lh+fvgo3BcjD8gHPgeu8dN6+Hmn\nRi1/EjAd+A1YCbwENI6aHin/WuBLYAMuKWSUsX1aRC3zKzDXjz8napwCo/z4Rr78tcBWv61eBOqX\nsR0Ul4D6+df/AV4FNvv3Fxk/ChBc0lXgNr++u/zwxDLiF6A3sNB/Jl8D9wK1y/pcyljPYj99GpBZ\natoRUa+bA/8GfvSfwTvA4ZXYT06hZP/oh9s3n/XTOuN+aNb5z3Yk0GBX92ti738v+9gL/L4xpdT7\nuwH4xk9f6+Np5addjPvXudnvFzOBzqX366j3GP0YFf3eo8o7FBjr3+9m4FNg/4pi9XGVLqNfGWVU\n6budqI/QA0jEB3B61A7Rqox5GvkvmQLjKUk6q6K+qJGdYhPwXNSXbYCfPjiqnJHA3WV84bZ/Mfzw\nh5QkwmdwyX+4n9aDqITvd9xCoBiXdGb66Z8B6X6eSAy/+LI2+eGeZbz3FlHLDPLPxwJv4X6EhrNj\nwj8EV5N8FtdU8qWf/nQZ22EwcDAliV2BucAw4Iyo8ZH1N8Elk03AnyhJPA3LiP+vfvnffHmRz+lf\nZX0uMdbRMmqeM8rZlzJxPyjFfvs87z+Pn4G949xPTokqa4XfDjcBh1OS2EbjEpTikpzs4n69/bON\nGjcDV0l4AvfjpsBiP+1gP7wGeBqXcL/1Mdfx73Wj3ydeABYBl5fer/16/uOH8/xncDGlkjGuuWet\nHzcPt/8vANrFEeu1fvsp7vs6GLc/lS6jyt/tRH2EHkAiPoBLor4YtcuY5zY//f2ocfP9uN6ldopb\n/XD/yE4UtUyknBZ+ONYXbvsXww/P8sNX4r706UCqn9aDHRP+k374WT+cDqz247qUiuF8P/ycHx5a\nxntvEbVMG1yt/V2gyH/RIglzVNQy7f02ewRXO1Pgy7K2gx/Xz4/7BkiLMT56/Rf6ccX++bxyPt8v\n/DyX++G2friInWv5LcpYxwlR87T2466OGqd+O51PSaIe7B9f+3FXx7OfUJKQioGDo2J4wo//OGrd\nW6Jj2oX9evtnGzWuCXAd8ADweNQ6GuNq24pLul2Apn6ZVCDLb9MVwB+BAyPTytivI+9zWVTZO4wD\nbqEk2Uf/Q0mrKFY/faof7lFOGdXy3U7ERxomlp+jXu8PLI0xTwv/vDhq3BKgnV8m2nz/HGn3r+wZ\nH6mlhm/CJfLhuOaJfNy/g0EVxamqW0XkW2DfaopzJfAm0M0PPwX0ip5BRC7C1fxK2yeO9QN8oqrb\nKpjnVeB+3PtdBrxezrwt/HPks1vin1Nwxx++iiOm6H2kmV/HZ7ha7tUxymoC9C21joNLDVe0/Ver\n6tcx1n2cf5Re95JS4+LZr3cgIi1xyTXWvrCPqi4QkX8A1wNv+2WW4n5wPxeRa4B/4JpEEJEVwF9w\niXdXHOCfZ6tqcWSkqm6rKFbcvhqPFv65Jr7bNcrO0ontI9xfOoC7RGT7dhKR/UUkHZdUAFpHLdfK\nP39fan2RZKVxlL0xqqwc//LwUvPMUdW2QC6udpIOPCAisX7Ad4jTx35gNcQZ7Sn//KGqfh5jenf/\n/C+gVtRw9EHByJc31j5ZEEcMN+G+qFv8883lzLvMP0c+u8jnVgwsj6MsVPUrShLqrSKSoaofAXeU\nUdZcXI1U1B0MzQX+WWreirZ/6e0QWfegyHr9ug9S1fExlo9nvy6tKy6JfYo7oLtf1DTxB+r/qap7\n45Lhg7jteaOf5zlVbYL7N9AXaAr8XxnvLx7f+ecOpeJPqyhW/1zkn8vLfcv8c3V/t0NnNfwYVHWj\niFyHa2+9FDhCRD7B7bSn43akF4G/A6eKyJu4A17tcc0lu3xKpKqu8bWgpsCLIrIFV7OINs5/0b4B\n6uGS6C+U7MzRhgFXAZeLSB3cl3JfXFvq1F2Ns5T3gN+z45k70Vb757NwP05nxZhnuY9tqIh8CdwZ\nb+EicgTuoOsvuM9nCjBARCap6sIYizwBDAUeE5GTgdP8+BGquiXecoH/xdVqTwc+F5HpQE6peSbi\ntsvRwAwR+Qx3EPcU3HaYWonySot8tteLyAG4tu1DgU7ESGhx7telRT67Q3CnLpbeF5sBs/x7/xnX\n1AUlNd7V/syYlcARpabtihdxB0rbA5+IyFzctu0VR6xQ8oPeV0SOxB1XilVGtX+3E4HV8Mugqi8B\np+K+sM2By3FfpmeATaq60k9/B7eTHwNMAE5V1V+rWHxP3IGvE3G1zv+Wmj4V9yW9BFermQ10V9+Y\nWOp9fIprW52JSzAH4A7enqGqVT3nP1KGqup7WvZppf2B93F/q48G7osxz99wbb1n4GqCdeIp2587\n/gLuR6+vqs73y9cCXijj3PIncQdufwQuwm3j+9m5yaVcqjodd7D6FdwP72W4z2y6X9cqVd2I+0EZ\nTcl+1AqXVCpsUqmg/AW4H9rpuDOxLgSy/Xspa5ly9+sYi7wKjMBVJn4fY915wCe478BVuP3y37gf\nYHDXMRyF26cPw31Hyvv3VS5V/Qm3jd/ANZNdhqu4rosjVoBHcU1vbXCfUcsYZQT53Q6VnYdvjDFJ\nwmr4xhiTJCzhG2NMkrCEb4wxScISvjHGJImEPS3z1Mc+sqPJ3guXHR12CAnjuzWxTiRJTh0OzA07\nhISxqSDWGcnJaa+6qWV2emc1fGOMSRKW8I0xJklYwjfGmCRhCd8YY5KEJXxjjEkSlvCNMSZJWMI3\nxpgkYQnfGGOShCV8Y4xJEpbwjTEmSVjCN8aYJBFowheRh0QkR0TSReQ9EVkjIpcGWaYxxpjYgq7h\nd1HVPOCPuBsDHwzcGnCZxhhjYgg64Ud64+wKjFHV9QGXZ4wxpgxBd488XkSWAJuBa0RkH2BLwGUa\nY4yJIdAavqreDnQCjlHVrcAm4E9BlmmMMSa2QGv4IpIJ/BVoDvQGGgOtgPFBlltZpx7SgP85shEH\n7Z1J7fRUfv/4zO3TjmtRnwuOasJBe2eSIsJ3v2xi+Effs3DlhhAjrjnDhg7i4xnTWbP6J+pkZnJc\npxO5qs+N5NSrF3ZoNWrkoHuYNe1t0tIzto87r0cfTu16XohRhaeoqIjHBj3Cm2+MpaCggOM7deb/\n+vUnN3evsEOrcZPfnshrr7zMV18tpWDLFj6cvTDskMoUdBv+s0AhrpYP8CNwb8BlVlr+liL++9lP\nPDF92U7TsmulMXbBKi4ZNY//GfYJ7y1dw4N/asM+WRk7r2gPlJKawh397mPsO9MZ9sIY1vy8mocG\n3BV2WKE4/rSzeGLM+9sfyZrsAUYOH8b7U6bw4ugxvDNlOgB33n5byFGFIzs7h24XXMQNN98edigV\nCjrhH6SqDwFbAVR1E1Dm7bfCMvuH35jy5VpWrt/58MK7S9fy4Te/srGwiGKFNxeuZvPWIlrvlxVC\npDWv1zV9adnqUNLS0qmfuxfdul/Cgnlzwg7LhOy1Ma9yRc9eNG3WjOzsbG68+VZmfPgBK1f+GHZo\nNa5jp850OaMrTZo2CzuUCgV90LZQROoACiAiBwEFAZcZqAMaZFKvTjrf/pKc91adP2cWB7Y8JOww\nQjHvo6nMmzmN7Jx6tDvuJM6+qCe162SGHVaNy8vLY9WqlbRpc/j2cc2aNycrK4svlyyhceMmIUZn\nyhN0wv8HMAloJiIvAScAPQIuMzD166TTv2srXpn3Iz/+lnwnG02fMplxY8cw8MmRYYdS4047+wLO\n7dGH7Hq5rFq+jGcfu5d1Q++n960Dwg6txm3auBGArOwd/+VmZ+eQvzE/jJBMnII+S2cy0A2X5Efj\nztaZWtb8ItJbROaIyJyVH/03yNAqrUHddAadexhzfviNZ2b8EHY4NW7ae+8w8IH+DHh4CIe0bhN2\nODWuxcGtqZfbgJSUFJrsfyDde/Vl7owpbN1aGHZoNS6zbl0A8jfsmNw3bMgjq25yNHXuroLuWuEk\n4DBgA5AHtPHjYlLVYap6jKoe07hT4py9uV92LR477whmLVvHkKnfhR1OjZs0/g0GPXgP9z78OO2P\nPjbscBJCSor/6qiGG0gIcnJyaNSoMYsXL9o+bsXy5eTn59OyVasQIzMVCbpJJ7obhdrAscBc4LSA\ny62UFIHUFCE91R1PjjxvLVKa5dbh0T+3YdLinxk5c3mYYYbi9Vde4vkRT/PA4KdpHdVmm2w+mT6Z\nw4/qSGZWNqtX/sCrI4bQ9tgTSc+oFXZooTj3/At4dsQzdDj2OOrXz2XwwIfpdEJnmjRpGnZoNa6o\nqIht27axdetWAAoK3GHKjIwMRBLrHBXRGqyhiEgzYLCqnlvRvKc+9lGNBfaHQ/fh9i4tdxp/4ci5\nXN6xGWe22ZfNhUU7TBs45RveXbq2RuJ74bKja6ScWH7X8UhSU9NIz0jfYfyE92eFEs93a8I5WP7Q\nHdewYtk3bNtaSE69XNoffzLnXHwVdTLrhhIPQIcDc0Mru6ioiMEDH+HNN16nsLCQjp1O4O5+94R2\nHv6mgqKKZwrIhDfHcm+/O3ca//r4yTQK4QD2XnVTy/yVqemEL8AiVa2wEbgmE36iCzPhJ5qwEn4i\nCjPhJ5owE36iKS/hB32l7eP4UzJxxwvaAfOCLNMYY0xsQbfhR1+hsw0YraozAi7TGGNMDIEmfFV9\nLsj1G2OMiV8gCV9EFlLSlLPDJEBV9cggyjXGGFO2oGr4fwxovcYYY3ZRIAlfVb8vPU5E9gZ+0Zo8\nLcgYY8x2gVxpKyIdRWSqiLwuIu1F5HPgc2C1iJwRRJnGGGPKF1STzlDg70A9YApwpqp+LCKtcX3q\nTAqoXGOMMWUIqi+dNFV9R1XHAD+p6scAqrokoPKMMcZUIKiEXxz1enOpadaGb4wxIQiqSaetiOTh\nTsOs41/jh2sHVKYxxphyBHWWTmoQ6zXGGLPrgr6nrTHGmARhCd8YY5KEJXxjjEkSlvCNMSZJ1OgN\nUCpjyzY7fTMit8O1YYeQMNbNHhp2CAnDbvpRIrOWnScSUTuNMm+AYjV8Y4xJEpbwjTEmSVjCN8aY\nJGE3QDHGmCRhN0AxxpgkUWM3QDHGGBOuQNvw/Y1QZotIvogUikhRVEdqxhhjalDQB22HAhcBXwF1\ngF7AEwGXaYwxJobAz9JR1a+BVFUtUtVnAbvFoTHGhCCog7YRm0QkA/hURB4CVmGnghpjTCiCTr5/\n8WVcC2wEmgHnBlymMcaYGIKu4a8FClV1C9BfRFKBWgGXaYwxJoaga/jvAZlRw3WAdwMu0xhjTAxB\nJ/zaqpofGfCvM8uZ3xhjTECCTvgbReSoyICIHA1sDrhMY4wxMQTdhn8DMEZEVuL60WkIdA+4TGOM\nMTEEmvBVdbaItAZa+VFLVXVrkGUaY4yJLZAmHRE5zT93A84GDvGPs/24hFZUVMTARx7klM4dOb5D\ne27qex3r1v0adlg14vw/HM27I25g9QcPs2H2YztN73VeZz57427WzHiUmaP/xolHtwwhynAk835R\n2uS3J3L1lZfyuxM70LnDEWGHE6rdab8Iqg3/ZP98doxHwvekOXL4MN6fMoUXR4/hnSnTAbjz9ttC\njqpmrMvbxLAxH3DrI6/tNK3b79tz91+7cultI9jvxFsY8doMxj5+Nc0a5oYQac1L5v2itOzsHLpd\ncBE33Hx72KGEbnfaLwJJ+Kr6D/98RYzHlUGUWZ1eG/MqV/TsRdNmzcjOzubGm29lxocfsHLlj2GH\nFrh3Zy7m1Ulz+W7FLztN63Z6e/49YTafffkjxcXK8P98yJpfN3DpOceFEGnNS+b9orSOnTrT5Yyu\nNGnaLOxQQrc77RdB95bZV0RyxBkuIvNEpEuQZVZVXl4eq1atpE2bw7ePa9a8OVlZWXy5ZEmIkYVP\nBESk1Dih7SFNQ4qo5th+YWLZ3faLoE/LvFJV84AuQANcVwsPBFxmlWzauBGArOysHcZnZ+eQvzE/\n1iJJY+IHi7jwrA4c1aY5aWkpXN39JJo1zCU7q3bYoQXO9gsTy+62XwR9WmakOngW8LyqLpLSVcTo\nmUV6A70Bhj75L3pe1Tvg8HaWWbcuAPkbdvywNmzII6tuVqxFksZL42bRsEE2z/7zchrUz2Lc1AVM\nmbWUdXmbwg4tcLZfmFh2t/0i6IQ/V0TeAQ4A7hCRbKC4rJlVdRgwDGDLtpj3xA1cTk4OjRo1ZvHi\nRbQ+9FAAVixfTn5+Pi1btapg6T3fo6Pe5dFRrneM9LRUlkzoz/3PTAo5quDZfmFi2d32i6CbdHoC\ntwMdVHUTkA5cEXCZVXbu+Rfw7IhnWLHCfXCDBz5MpxM606TJnt9WnZIi1MpIIyM9FYBaGWnUynD1\ngpys2rQ6YD8A9s7NYsid3Vmfv5kXx80KLd6alMz7RWlFRUUUFBSwdau7rKagoICCggJUQ6mnhWp3\n2i+CruEfD3yqqhtF5FLgKGDnk7sTzJW9epOXl8cl3c+jsLCQjp1O4L4HHw47rBpxcddjeeaev2wf\n/m3WYABanXU3xcXFvPRQT/Zv3IDCrduY9MEizrhqCFsKkuNaumTeL0qbNOFN7u135/bhU45vD8Dr\n4yfTqHGTsMIKxe60X0iQv8gi8hnQFjgSGAUMBy5Q1ZPLWw7Ca9JJRLkdrg07hISxbvbQsENIGJsK\nisIOIWFk1koNO4SEUTuNMo+TBt2ks03dL8qfgKGq+gSQHXCZxhhjYgi6SWeDiNwBXAqcJCIpuHZ8\nY4wxNSzoGn53oADoqao/AU2BxGzcMsaYPVxcNXwR6Qqcjjtl8ihgoaouqGg5n+QHRg3/ADy/a6Ea\nY4ypigpr+CJyAzAOuA7Xn3034qyli0hHEZktIvkiUigiRSKyvkoRG2OM2SXxNOncAIyJGn4XV8uP\nx1DgIuAr3P1sewFPViZAY4wx1SOehJ8LRDffZAJxnwOlql8DqapapKrPAmdULkRjjDHVIZ42/E+A\na/zrW4DOwIw4179JRDKAT0XkIWAVwR8oNsYYE0M8yfc63I3HBVc7X4Vr5onHX3D/Bq4FNgLNgHMr\nH6YxxpiqKreGLyKpuFsTdqOk07OlqhrXJX6q+r1/uRnov6tBGmOMqbpyE76qFonICOBWVR0V70pF\nZCGU3TWCqh4Zd4TGGGOqRTxt+C8BPURkNq45BwBVLe8uvd2A/YDlpcY3A36qbJDGGGOqLp6Efz2u\ntv5Z1DitYNlBwB1RTToAiEiOn3Z2JeM0xhhTRfEk/OmU0zxThv1UdWHpkaq6UERaVHJdxhhjqkGF\nCV9VT9mF9dYvZ1qdXVifMcaYKqow4YvIvsBVQAtKLrhSVe1ZzmJzROQqVX2m1Lp6AXN3MVZjjDFV\nUOENUETkE+CYUqNVVcu82lZE9gPGAoWUJPhjgAzgz75TtXKtWFdgN0DxMjOC7sV693Hb+MVhh5Aw\n+nTcP+wQEobdAKVEq4aZZd4AJZ5MchDwAq4PnG3xFKiqq4FOInIqcLgfPUFVp8SzvDHGmOoXT8J/\nAXeXqnmqWqmbl6rq+8D7uxKYMcaY6hVPwu+FO9B6mYhs9uNUVesFF5YxxpjqFk/CX0vlT8s0xhiT\nYOI5LbNFDcRhjDEmYPHc8UpEpI+IjBWRo0XkdhE5rSaCM8YYU33i6R75PuBx4BygHnAo1vOlMcbs\nduJJ+JcB/4oa/hA4Ip6Vi0htEblJRF4XkddE5EYRqb0rgRpjjKmaeA7a1iGql0ygCRDv6ZnPAxtw\n/xAALsad5nl+vAEaY4ypHvEk/PeBm/zrR3C1+9fjXP/hqtomel0i8kUl4jPGGFNN4r3F4Xz/uh3w\nAfHf4nCeiHSMDIjIccCcSkVojDGmWsRzWuZK4FQRqeuHN1Zi/UcDH4nID364ObA0ckcsu/OVMcbU\nnDITvu8H5zjcDUtqAW/48Qo8rapj4lj/GdURpDHGmKorr4Z/D7BKVQtEJAs4JWqaAhUmfFX9XkTa\nAif6UR+o6oJdDdYYY8yuK68Nvw0wtdS4c3EHcA/fae4YRKQv7p64+/rHiyJyXeXDNMYYU1Xl1fDr\nAun+9TqgPfA1cAXuAqx49ASOi7T7i8iDwExKTtM0xhhTQ8pL+F8C14nIa6q6AlggIo2APsA3ca5f\ngKKo4SI/LqENGzqIj2dMZ83qn6iTmclxnU7kqj43klMv+ToInfz2RF575WW++mopBVu28OHsnW5V\nvMfq0Kwep7bci2b1a5ORmsL/jlm0w/TDGmZxQbuG7FM3gzUbC3ll/k98sTo/pGjDUVxczD9u6sVX\nX3zGEy9NoME++4UdUo174ZmhTHv3LTbkrScjI4PD2h5Fzz43s89+jcIObSflNek8BRwIfCUi80Rk\nLi7RH4K7GUo8ngVmiUg/EekHfAyMqEK8NSIlNYU7+t3H2HemM+yFMaz5eTUPDbgr7LBCkZ2dQ7cL\nLuKGm28PO5Qat2lrEVO//pV/z1+107S966bz1xOa89biNVw3djETF6+hT+fmNMhMj7GmPdfE11+m\nVq3kvnj+1C5deWzEv3nlrQ8Z/soE9tm3IQ/3T8zvS5kJX1WfAgbgDtC2wzXpANyjqnElfFUdCFwJ\n/OofV6jq4CpFXAN6XdOXlq0OJS0tnfq5e9Gt+yUsmJeclw907NSZLmd0pUnTZmGHUuMW/ZTPJz+s\nZ23+zheWd2qRy/frNvPx9+spKlZmfb+e79dtptMB9UOINBwrV3zPO+PGcGnvvmGHEqqm+x9A3axs\nAFRBUlL4cfn3IUcVW7nn4avqP3y7+2G4xP+Fqm6qZBmf4rpmSAMQkeaq+kP5iySW+XNmcWDLQ8IO\nwySQZvVr8/26zTuM+2HdZprVT47abnFxMf969B4uveoGMutmhx1O6KZNfounBt3Hpo35pKam0bPP\nTRUvFIJ4LrzaBMzelZX7M3L+AaympP1egd3mgqvpUyYzbuwYBj45MuxQTAKpnZ7C5sLiHcZtKiym\ncU5y3Ez7rbGjqZfbgGM7n8rPP60MO5zQnXz6mZx8+pms+2Utkye+wf4Htgw7pJji6VqhKvoCrVT1\nMFU9UlWPKO/qWhHpLSJzRGTOS6OGBxxaxaa99w4DH+jPgIeHcEjrNhUvYJLGlq3F1MnY8euTmZHC\nlm1FZSyx5/jpx+VMeO0lrrz2trBDSTi5Dfamyx+7MeCO69mQtz7scHYST+dpVbEciPtdq+owYBjA\ninUFod5WcdL4N3h6yCPc+/DjHN62fcULmKSy/LcttN637g7jmtevw+Kf9/yzdJYs+pS89eu4tXd3\nAIrVfVVvu/oiul9+DV3OSe7OcIuKtrFl82Z+XbuG7JzEOrMvkIQvIpEGrG+BqSIyASiITPcHcxPW\n66+8xPMjnuaBwU/Tuk1c15jtsYqKiti2bRtbt7oDlwUF7mPMyMhAJOHPsK0SEUgVITXFvc80/7yt\nWJm57Df+0Hpvjm1ej7nL13N0s3rsv1cdRsxaEWbINeL4k07niPbHbh/+de3P/F/fK/j7/UNp0qxF\neIGFoLi4mIlvvErnU7tQP3cv1v68mmGPPci+DRvTtHmLsMPbSXl96eSVs5yqank/XZGjOD/4R4Z/\n7BaeGPQgqalp3Nyn5w7jJ7w/K6SIwjNpwpvc2+/O7cOnHO/+7bw+fjKNGjcJK6wacfz+9bnyuKbb\nh58+/zAA/jZuKWs2FvLkjB+4oF1DenRowpqNhTzx4Q/8sineW0XsvmrVrk2t2iUHp4uKXDNW/dwG\n1K6TGVZYoZn78Ye88twwtmzZTN2sbI5odwwDBj5NalrQDSiVJ6qxW05EZBnuAGtMqnpA3IWI5LhF\ndEO8y4TdpJNIMjMSb8cJy23jF4cdQsLo03H/sENIGJm1kuNgeTxaNcws8693mZlEVVtUtWAROQZ3\n8VW2H14PXKmqc6u6bmOMMZUTV9VRRI7H3ekq8j9OVTWe/nBGAn9V1Q/8ejrjfgB2m9MyjTFmT1Fh\nwheRu3Hn0pcWT8IviiR7AFX9UES2VSI+Y4wx1SSeGv5VwCTczUzuB/4IvB3n+qeJyL+A0bjjAd1x\nZ+0cBaCq8yodsTHGmF0ST8LfFxiPS/izcGfd/M0/KtLWP5f+h9Ae9wNwWnxhGmOMqap4Ev5aoBj4\nDdeMU8s/KqSqp+56aMYYY6pTPAl/MO5q2XuAgbjkX+411SJyqaq+GHUB1g4S/cIrY4zZE8XTedrD\nkdci8gzu3P2NFSwWuebcutEzxpgEEc9ZOjt1Eykiqqo9Y80PoKr/8s/9qxaeMcaY6hJPk06PGOMU\nd7/amERkSHkrVNXr4yjXGHMagkYAABjBSURBVGNMNYon4XeIep2La79fUsEy0VfS9if2efzGGGNq\nUDxt+Dt0gyAiBwN3AWXW0lX1uaj5b4geNsYYE4542vCje81MxXWvUJk+YK0TNGOMSQDxNOn8SknS\nLgKWAf0CiscYY0xA4kn4JwFrK3PzchHZQMmPRGbUvwTBdbyWU7kwjTHGVFU897T9DugaGRCR80Wk\nsLwFVDVbVXP8Iy3qdbYle2OMCUd5d7w6EmiHq5WfIiJ1/KSzaiKwjQV7/s2g42U3QCnRr0vLsENI\nGEM+WhZ2CAnj7Jb7hh1CwmjVsOy7jpWXSf6MO51Sgav9A9wPwJzqCs4YY0zNKC/hvwNsBB4CXgI+\nxSX/dcCbwYdmjDGmOpV3i8OZwEwRmQ0sUtW1NReWMcaY6hbPQdv+wN8jAyIySETeDy4kY4wxQYgn\n4R8LLIwa/gw4LphwjDHGBCWehP8z0E1EMkWkLnCeH2eMMWY3Es/5fqNxtzOMvnjqgcAiMsYYE4h4\nEv7dwGbczcsBxuFuZm6MMWY3UmGTjqpuVdV7VPVYVT0WGIv7ETDGGLMbiesSThFpDXQHLgBa+9GW\n9I0xZjdSXtcKLXEJvjtwGL7jM2AC8EKNRGeMMabalFfDX4pL8KuAJ4BPgOeB4apa7pW2IjKOcvrB\nV9VzKh+qMcaYqqioSacYmAZMwf0AxOuRXY7IGGNMIMpL+NdR0qRzIVCIq7V3EJEZqvpLWQuq6rRq\njdIYY0yVlXmWjqo+oaonA82Am4B5ftKdwE/xrFxEWorIf0TkCxH5NvKoctTGGGMqLZ7TMlep6mOq\negKwP3ALMLeCxSKeBZ4CtgGn4o4BvLiLsRpjjKmCeLpW2E5VV6jqQFXtGOcidVT1PUBU9XtV7UfU\n3bOMMcbUnKBvpVQgIinAVyJyLfAjkBVwmdXihWeGMu3dt9iQt56MjAwOa3sUPfvczD77NQo7tBo1\n+e2JvPbKy3z11VIKtmzhw9kLK15oDzRs6CA+njGdNat/ok5mJsd1OpGr+txITr16YYcWisKNeXz+\n3xH8vHQ+RVsL2e/QYzjy3KvJyNwtvt7VZuSge5g17W3S0jO2jzuvRx9O7XpeiFGVTVTLPHuy6isX\n6QAsBuoDA4Ac4CFVnVXRskt/2hRcYHFY8f135DbYm7pZ2RRs2cyLw59g6RcLeejJ52o8ln2ya9V4\nmREff/QheXnrKdiyhQf/2S/0hL+pcFso5Q5/6jFOPq0LBxx0MPkbNvBA/ztJS0vj3kceDyUeCPcW\nhx8/cw8paem0v6gvWlTEnBcfISU1lY69wrkeM6xbHI4cdA8pqan0uP7OUMqP5cRDcqWsaZVq0tkF\nLVQ13zcFXaGq5wLNAy6zWjTd/wDqZmUDoAqSksKPy78POaqa17FTZ7qc0ZUmTZuFHUqoel3Tl5at\nDiUtLZ36uXvRrfslLJiXnHf63FawhdVL5tKqy4Wk184ko242h/zufFZ/MYdN69aEHZ4pR9BNOncA\nY+IYl5CmTX6Lpwbdx6aN+aSmptGzz01hh2QSxPw5sziw5SFhhxESdbWgqGsrVYsBWP/jt2Tm7hNS\nXOGY99FU5s2cRnZOPdoddxJnX9ST2nXKvpF4mAJJ+CJyJnAW0EREhkRNysGdsbNbOPn0Mzn59DNZ\n98taJk98g/0PbBl2SCYBTJ8ymXFjxzDwyZFhhxKKtFp12PugI1jy9miOuqgvxUVFfPWeq8Nt27Ip\n5Ohq1mlnX8C5PfqQXS+XVcuX8exj97Ju6P30vnVA2KHFFFSTzkpgDrAFdwpn5PEm8IeyFhKR3iIy\nR0TmvPJC4nyZchvsTZc/dmPAHdezIW992OGYEE177x0GPtCfAQ8P4ZDWbcIOJzRHXXITKWnpvPdA\nH6YPvpmGh7mb4GXUzQk5sprV4uDW1MttQEpKCk32P5Duvfoyd8YUtm4tDDu0mAKp4avqAmCBiLzs\ny2iuqhV2zaCqw4BhEP5B29KKiraxZfNmfl27huyc5DwzI9lNGv8GTw95hHsffpzD27YPO5xQ1anf\ngA6X3bZ9+KcvZpOSlsFeLVqFGFX4UlJ8HTrAk2GqIuiDtmcAnwKTAESknYiU2/FaIiguLmb86//m\nt3W/ArD259X8a9AD7NuwMU2btwg3uBpWVFREQUEBW7duBaCgoICCggKCPLsrEb3+yks8PeRRHhj8\ndNIne4ANP6+gcOMGtLiYdT98xedvDKfl784lvU5ynZb5yfTJbMrfAMDqlT/w6oghtD32RNIzwjuz\nrjxBn5Y5FzgNmKqq7f24hap6REXLhlnDLy4uZsDt1/P10i/YsmUzdbOyOaLdMVx85TU0alLzZ6uE\neVrmhDfHcm+/nU85e338ZBo1blLj8YR1WubvOh5Jamoa6RnpO4yf8H6FZxgHJszTMpfNfJslk15m\n25aN1K7XgAM6d+Wgk8LrBDes0zIfuuMaViz7hm1bC8mpl0v740/mnIuvok5m3VDigfJPyww64X+s\nqh1FZH5Uwv9MVY+saNlEa9IJU5gJP9GElfATUZgJP9GElfATUXkJP+jTMheJyMVAqr+hyvXARwGX\naYwxJoag2/Cvw90tqwAYDeQBNwRcpjHGmBgCreGr6iZcd8qJc92xMcYkqaAuvCr3TBy7xaExxtS8\noGr4xwPLcc04s3A3QDfGGBOioBJ+Q+B04CLgYmACMFpVFwVUnjHGmAoEctBWVYtUdZKqXg50BL4G\npvo+8Y0xxoQgsIO2IlILd3eri4AWwBBgbFDlGWOMKV9QB22fBw4HJgL9VfXzIMoxxhgTv6Bq+JcC\nG4G+wPUi24/ZCqCqmlxd6hljTAIIqrfMoC/oMsYYU0mWmI0xJklYwjfGmCRhCd8YY5KEJXxjjEkS\nlvCNMSZJBHoDlKrYso3EDMyEalNBUdghJIzMWqlhh5AwcjvYRfwRm+cPLbPvMqvhG2NMkrCEb4wx\nScISvjHGJAlL+MYYkyQs4RtjTJKwhG+MMUnCEr4xxiQJS/jGGJMkLOEbY0ySsIRvjDFJwhK+McYk\niUATvojUE5FBIjLHPx4VkXpBlmmMMSa2oGv4I4E84AL/yAOeDbhMY4wxMQR1E/OIg1T13Kjh/iLy\nacBlGmOMiSHoGv5mEekcGRCRE4DNAZdpjDEmhqBr+NcAz0W1268DegRcpjHGmBgCreGr6qeq2hY4\nEjhSVdur6oIgy6wORUVFDHzkQU7p3JHjO7Tnpr7XsW7dr2GHFQrbFiUmvz2Rq6+8lN+d2IHOHY4I\nO5xQJfN+cf4fjubdETew+oOH2TD7sZ2m9zqvM5+9cTdrZjzKzNF/48SjW4YQZWxBn6Vzn4jUV9U8\nVc0TkVwRuTfIMqvDyOHDeH/KFF4cPYZ3pkwH4M7bbws5qnDYtiiRnZ1Dtwsu4oabbw87lNAl836x\nLm8Tw8Z8wK2PvLbTtG6/b8/df+3KpbeNYL8Tb2HEazMY+/jVNGuYG0KkOwu6Df9MVf0tMqCq64Cz\nAi6zyl4b8ypX9OxF02bNyM7O5sabb2XGhx+wcuWPYYdW42xblOjYqTNdzuhKk6bNwg4ldMm8X7w7\nczGvTprLdyt+2Wlat9Pb8+8Js/nsyx8pLlaG/+dD1vy6gUvPOS6ESHcWdMJPFZFakQERqQPUKmf+\n0OXl5bFq1UratDl8+7hmzZuTlZXFl0uWhBhZzbNtYWKx/aJsIiAipcYJbQ9pGlJEOwo64b8EvCci\nPUWkJzAZeC7gMqtk08aNAGRlZ+0wPjs7h/yN+WGEFBrbFiYW2y/KNvGDRVx4VgeOatOctLQUru5+\nEs0a5pKdVTvs0ICAz9JR1QdFZAHwez9qgKq+Xdb8ItIb6A0w9Ml/0fOq3kGGF1Nm3boA5G/Yccfd\nsCGPrLpZsRbZY9m2MLHYflG2l8bNomGDbJ795+U0qJ/FuKkLmDJrKevyNoUdGhBwwheRusA7qjpJ\nRFoBrUQkXVW3xppfVYcBwwC2bEODjK0sOTk5NGrUmMWLF9H60EMBWLF8Ofn5+bRs1SqMkEJj28LE\nYvtF+R4d9S6PjnoXgPS0VJZM6M/9z0wKOSon6Cad6UBtEWkCTAL+AowKuMwqO/f8C3h2xDOsWOF2\n4sEDH6bTCZ1p0iQx2uFqkm2LEkVFRRQUFLB1q6uvFBQUUFBQgGoodZNQJfN+kZIi1MpIIyM9FYBa\nGWnUynB155ys2rQ6YD8A9s7NYsid3Vmfv5kXx80KLd5oQV94Jaq6ybffP6WqD+0OXStc2as3eXl5\nXNL9PAoLC+nY6QTue/DhsMMKhW2LEpMmvMm9/e7cPnzK8e0BeH38ZBo1bhJWWKFI5v3i4q7H8sw9\nf9k+/NuswQC0OutuiouLeemhnuzfuAGFW7cx6YNFnHHVELYUxGzUqHESZO1EROYDfwUGAT1VdZGI\nLFTVCq9aCatJxyS2TQVFYYeQMDJrpYYdQsLI7XBt2CEkjM3zh0pZ04Ju0rkBuAMY65P9gcD7AZdp\njDEmhqDP0pkGTIsa/ha4PsgyjTHGxBZIwheRwap6g4iMg52bZlT1nCDKNcYYU7agavgv+OdHAlq/\nMcaYSgok4avqXP88TUT28a/XBFGWMcaY+AR20FZE+onIWmAp8KWIrBGRu4MqzxhjTPkCSfgichNw\nAtBBVfdS1VzgOOAEEbkxiDKNMcaUL6ga/l+Ai1T1u8gIf4bOpcBlAZVpjDGmHEEl/HRVXVt6pG/H\nTw+oTGOMMeUIKuEX7uI0Y4wxAQnqtMy2IpIXY7wAidExtDHGJJmgTsu0Tj6MMSbBBN2XjjHGmARh\nCd8YY5KEJXxjjEkSlvCNMSZJWMI3xpgkEegdr/YEItLb31w96dm2KGHbooRtixKJvi2shl+x3mEH\nkEBsW5SwbVHCtkWJhN4WlvCNMSZJWMI3xpgkYQm/YgnbHhcC2xYlbFuUsG1RIqG3hR20NcaYJGE1\nfGOMSRKW8I0xJkkkVcIXkSIR+VREFojIPBHp5Me3EJHPw46vOolIQxH5t4h8IyJzRWSiiBxSne9T\nRO4Rkd/vwnKhbm8RyS813ENEhvrXV4tIuXdl8/drviXIGMMiIioiL0YNp/n7UY+vYLl2InJWHOs/\npaJ1JYqofLHI54ybRSTFTztGRIaEHWNlBdUffqLarKrtAETkD8D9wMnhhlT9RESAscBzqnqhH9cW\n2K86y1HVPe6m9Kr6dNgxhGwjcLiI1FHVzcDpwI9xLNcOOAaYGGRwNSw6X+wLvAzkAP9Q1TnAnDCD\n2xVJVcMvJQdYV3pkdG3PD48XkVP86y4iMtP/OxgjIll+/AMi8oWIfCYij9TUGyjHqcDW6OSlqguA\n5ZFhX8v+wL+X6H87jURkuq/ZfC4iJ4pIqoiM8sMLIzei9+PO8687iMhHvib0iYhkl1VGIouuvYvI\nVBF5LGpbHBs1axs//VsRuT5q+Zv8vJ+LyA1+XAsRWSIiL4nIYhH5j4hk1vBbq4yJQFf/+iJgdGSC\niNQVkZH+M54vIn8SkQzgHqC731bdReRY/12Z7/eLViG8j2qjqj/jLqq6Vpzt/1RE5GT/vj/17zfb\nj/+b/74sEJEH/Lh2IvKxzxVjRSS3pt9I0jyAIuBTYAmwHjjaj28BfO5f9wCGRi0zHjgF2BuYDtT1\n4/8G3A00AJZScsZT/QR4n9cDg2KMj36fmUBt/7olMMe/vhm4079OBbKBo4HJUeup759HAecBGcC3\nQAc/Pgf377GsMrbHEfJ+EHn8EPnMgX7ALf71VOAZ//qkqG3XD/gIqOX3i19w92o+GlgI1AWygEVA\ne/9+FTjBLz8yUkaiPYB84EjgP7i7033q9//xfvp9wKWR/QD40r/f0t+bHCDNv/498Jp/vX1dif4A\n8mOM+w33Tzl6m4yL+myz/L5/pt9HMv34vfzzZ8DJ/vU9wOCafE/J3KRzPPC8iBwe57IdgTbADNdi\nQgYwE/fDsQUY4X/xd4v2SVyCGioi7XAJ8BA/fjYwUkTSgTdU9VMR+RY4UEQeByYA75RaVytglarO\nBlDVPHC1wTLKCNv2/QDcvzpcc0QsowFUdbqI5IhIfT9+gqoWAAUi8jMuCXQGxqrqRr/e14ETgTeB\n5ao6wy/7Iu5HORH+De5EVT8TkRa42n3pJpouwDlScgyjNtA8xmrqAc+JSEvcj116MNEmhBnAQBF5\nCXhdVVeIO7b1rKpuAlDVX0WkHq6yNM0v9xwwpiYDTdomHVWdiaud7VNq0jZ23C6Re/AKrpbbzj/a\nqGpPVd0GHIurEf0RmBRw6PFYhKttludGYDXQFpfsMsAlNlxt9kdglIhcpqrr/HxTgauB4XHGEbOM\n3UzpC1UiwwVR44qo+HhYWetJVG/ifpBGlxovwLlR34Pmqro4xvIDgPdV9XDgbPaAe1mLyIG4z/rn\n6PGq+gDQC6iDqxC2DiG8uCRtwvcfSiru73i0ZUA7EUkRkWa4ZA7wMXCCiBzsl68r7qyXLKCeqk7E\nJbi2NfIGyjcFqCUi2ztyEpEjgWZR89TD1cqLgb/gtgUisj+wWlWfwSX2o0RkbyBFVV8D7gKOKlXe\nUqCRiHTw68gWkbSyytjNdAcQkc7AelVdX868HwD/IyKZ/t/Nn/04gOb+XyXAxcCHQQVcTUYC/VV1\nYanxbwPXif+bKyLt/fgNuOa/iHqUHOztEWCcNUJE9gGexjVbaalpB6nqQlV9EPcPuTUwGbgicqxG\nRPby+846ETnRL/oXYBo1KNmadOqIyKf+tQCXq2qR33cjZgDfAV8Ai4F5AKq6xv/1Hy0itfy8d+F2\n9P+KSG2/zpsCfxcVUFUVkT8Dg0Xkb7gmp2XADVGzPQm8Ju4UxEm4szPAtU3eKiJbce25lwFNgGfF\nn5IG3FGqvEIR6Q48LiJ1gM24dtuyytidbBGR+bgmiSvLm1FV54nIKOATP2q4qs73zSNLgT4iMhK3\nbz0VWMTVQFVXALFOOxwADAY+8/vDd7h/tu8Dt/vv1/3AQ7gmnbtwzYC7o0i+SMf9838BGBhjvhtE\n5FSgGPfv+i1VLfBNmXNEpBDXNPZ34HLgaf9D8C1wRQ28j+2sawVjyiAiU3EHV6t0+p1P+ON984Yx\noUnaJh1jjEk2VsM3xpgkYTV8Y4xJEpbwjTEmSVjCN8aYJGEJ34TK9zOjUY9fxfXy2aAa1n2LX2cP\nP7xMSvWUGWOZTuL602lX3nxlLHueL69fGdP3EZHhIrJKRApEZLmIjI70vWJM0JLtPHyTuOYDD+P6\n5umOO2e/Z+mZRCRVVYt2sYzrqPhq307AP3DXLXxa/qzx89cnTMddlDMWeAtoBFyIu0hpQzWVk+av\n/jZmJ1bDN4lipaqOxl3MBnAcbK+VbxSRJ0VkPXCEiBwvrifGfBH5UkQuiqzE1+rXisgXwBGlyngc\n138JIpIhIveLyPcisllcD6Gn4H50wF1opv4fyKEiMllE8vz8N0aVd7GvsX+P66W0LBfjkv07qtpN\nVZ9R1XtwHZWt9uv6o7ieFTf659P9+FN8LBNEZIaIrBeRh/20yD+kj0TkXfzVrSJypYgs9ev6SERK\nXx1tkpAlfJMo0v3l6//jh3+ImpYJNAZuwfVjMh7XU+M/cTXxF8V1O9sWl7B/wl0NWt7NWW73j0XA\ntbgrqr8AXvLTn8Z1HrYO+C+u47yHgFm4jrLOFpH9gBG4Kyz/Sfn3Voj0bfQWbO+aY2//PlJE5BDg\nNdxVygNwffWMFZFGUes4GXgV1x3ILSIS3WnZ8cBc4P/8D9cIv23uxfXoOs5fDW6SmDXpmETRhZJO\nqX7EXYYe7XJVXS8iXYG9/OO+qOmn4Tq2Atc19AhxfSHdRWxn4zow666q25tT/KX0lwCzVPXfInIY\nrmtncIk44nRchak2MFJVh4lIEWV3LKelnv8J9PWvr8B1MZyB+2dzXNRyxwO/+tdvqupjInIo8L/A\n/pTc42C+qv7Nv4fIv5Qu/hHRBt9ViElOlvBNopgF3IlLbl/4rocjNsbotOx5XN8mEcsouWmHlHqu\njLKuRHybHbsz/gk4qBLlzfXPpwOP4foZqoO7qUa0h3Adb0UspuQHJ5L4I2300Z3RrYxR5s24/tfB\n/Th9V058JglYk45JFGtV9T1VnV8q2Zc2E5f4zsC1iR+Oa5ppguu+GVxnVr0pv2OqcbgE/Ypv7x7s\nx0fugnamiFyA6/TsK1xf9+1xff/3wfUY+jGuY7orfHnRndOVNhp3452uIvIycAI7ds09GSgEugEH\n+LLuZ9f6kY90VnYRrq/644Ahvptrk8Qs4Zvdiqr+iuud8WvgAdy/gk3AMnW3cbwVaIg7I6e8rmcf\n8I/DcbXtyEHNN3G18XOBl/0ZL3/C9aJ6F65ZJxtYqKqrcWcSpeDugPZxOXFvxrXBP4s7tvA0Lqk/\nB8xQ1S9xyT4f9w/gRuAbYtyGsyKqOhX3Y5cFPIH7F/FRZddj9jzWl44xxiQJq+EbY0ySsIRvjDFJ\nwhK+McYkCUv4xhiTJCzhG2NMkrCEb4wxScISvjHGJIn/B1ZiX0WudyrZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}